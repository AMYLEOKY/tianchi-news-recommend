{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2519c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "from tqdm import tqdm  # 其实没必要，但是看进度条有底\n",
    "from collections import defaultdict  \n",
    "import collections\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine # 余弦相似度\n",
    "import os, math, warnings, math, pickle\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de474066",
   "metadata": {},
   "source": [
    "### 目录：\n",
    "- 序章：\n",
    "> 压缩内存的函数&定义数据存储的路径：\n",
    "- C1. 获取相应数据集：\n",
    "- C2. 召回准备前的工作——前期：\n",
    "> 1. 用户UserCF协同过滤使用的用户-（物品，时间）字典；\n",
    "> 2. 物品ItemCF协同过滤使用的物品-（用户，时间）字典；\n",
    "> 3. 评判和特征工程要用的最后一次点击-记录到每个用户的所有历史点击&最后一次点击记录——预处理算是；\n",
    "> 4. 冷启动要用的字典特征——为了冷启动阶段召回用，基于文章/物品特性的召回；\n",
    "> 5. 获取用户对应的历史点击的文章信息，以字典形式存储：\n",
    "> 6. 最近点击次数最多的topK个文章的索引；召回不足时使用；\n",
    "- C3. 召回准备前的工作——后期：\n",
    "> 1. P0.建立多方法召回的信息储存池；user_multi_recall_dict_info  =  {'itemcf_sim_item_recall': {},'usercf_sim_item_recall': {},'cold_start_recall': {}...} \n",
    "> 2. P1.基于ItemCF计算文章相似度矩阵：itemcf_sim() ——得到本地缓存结果：itemcf_i2i_sim.pkl，基于ItemCF得到的协同过滤结果；\n",
    "> 3. P2.基于UserCF计算用户相似度矩阵：usercf_sim() ——得到本地缓存结果：usercf_u2u_sim.pkl，基于UserCF得到的协同过滤结果；\n",
    "> 4. P3.Item embedding召回——计算Embedding相似度；——得到本地缓存结果：emb_i2i_sim.pkl，基于物品embedding相似性，为了冷启动；\n",
    "- C4. 召回工作正式启动阶段：\n",
    "> 1. P1.itemCF 召回：\n",
    ">> 1. S1.itemCF召回函数：item_based_recommend()；需要之前计算好的itemcf_i2i_sim.pkl\n",
    ">> 2. S2.进行ItemCF物品召回，并保存结果评估；\n",
    "user_multi_recall_dict_info['itemcf_sim_item_recall'] = ItemCF_user_recall_items_dict\n",
    "将ItemCF_user_recall_items_dict ——得到本地缓存结果：itemcf_recall_dict.pkl\n",
    "> 2. P2.userCF 召回\n",
    ">> 1. S1.userCF召回函数：user_based_recommend()；需要之前计算好的usercf_u2u_sim.pkl\n",
    ">> 2. S2.进行userCF物品召回，并保存结果评估；\n",
    "user_multi_recall_dict_info['usercf_sim_item_recall'] = UserCF_user_recall_items_dict\n",
    "将UserCF_user_recall_items_dict ——得到本地缓存结果：usercf_u2u2i_recall.pkl\n",
    "> 3. P3.冷启动召回——先计算Embedding相似度，为了冷启动使用；\n",
    ">> 1. S1.定义冷启动函数；\n",
    ">> 2. S2.添加冷启动召回信息；\n",
    "user_multi_recall_dict_info['cold_start_recall'] = \n",
    "将UserCF_user_recall_items_dict ——得到本地缓存结果：cold_start_user_items_dict.pkl\n",
    "- C5. 多路召回合并！——这里主要是ItemCF召回\n",
    "> 定义各路权重字典：weight_dict = {'itemcf_sim_item_recall': 2.0,'usercf_sim_item_recall': 1.0}   \n",
    "> 1. 函数combine_recall_results()\n",
    "> 2. 基于已有条件只能选取ItemCF召回\n",
    "> 3. 最终找回结果保存到本地——得到本地缓存结果：final_recall_items_dict.pkl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5affe505",
   "metadata": {},
   "source": [
    "### 序章——压缩内存的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b947387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 节约内存的一个标配函数，一种数据压缩技术\n",
    "def reduce_mem(df):\n",
    "    starttime = time.time()\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if pd.isnull(c_min) or pd.isnull(c_max):\n",
    "                continue\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('-- Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction),time spend:{:2.2f} min'.format(end_mem,\n",
    "                                                                                                           100*(start_mem-end_mem)/start_mem,\n",
    "                                                                                                           (time.time()-starttime)/60))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fa7f80",
   "metadata": {},
   "source": [
    "### 序章：定义数据存储的路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e48351",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_path/' \n",
    "save_path = './recall_save_path/'  #保存一些计算结果的文件，比如物品、用户相似度\n",
    "# 做召回评估的一个标志, 如果不进行评估就是直接使用全量数据进行召回\n",
    "metric_recall = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84a6170",
   "metadata": {},
   "source": [
    "# C1.获取相应数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385af97",
   "metadata": {},
   "source": [
    "- 这里因为是线下，所以只能用训练集\n",
    "- 函数1：get_all_click_df——获取训练集就是，丢弃掉重复值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0678cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_click_df(data_path = data_path, offline=True):\n",
    "    if offline:\n",
    "        all_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "    else:\n",
    "        trn_click = pd.read_csv(data_path + 'train_click_log.csv')\n",
    "        tst_click = pd.read_csv(data_path + 'testA_click_log.csv')\n",
    "\n",
    "        all_click = trn_click.append(tst_click)\n",
    "    \n",
    "    all_click = all_click.drop_duplicates((['user_id', 'click_article_id', 'click_timestamp']))\n",
    "    return all_click"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e495bc5",
   "metadata": {},
   "source": [
    "- 函数2：get_item_info_df——获取文章的基本属性：修改字段名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b0a05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取文章的基本属性\n",
    "def get_item_info_df(data_path):\n",
    "    item_info_df = pd.read_csv(data_path + 'articles.csv')\n",
    "    # 为了方便与训练集中的click_article_id拼接，需要把article_id修改成click_article_id\n",
    "    item_info_df = item_info_df.rename(columns={'article_id': 'click_article_id'})\n",
    "    return item_info_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f616089b",
   "metadata": {},
   "source": [
    "- 函数3：get_item_emb_dict——获取文章的向量属性\n",
    "> 需要注意，这里面是把文章信息里面的每一片的对应向量都以字典的形式存储；\n",
    "> 保存在本地存储路径的文件；item_content_emb.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eadb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_emb_dict(data_path):\n",
    "    item_emb_df = pd.read_csv(data_path + '/articles_emb.csv')\n",
    "    item_emb_cols = [x for x in item_emb_df.columns if 'emb' in x]\n",
    "    item_emb_np = np.ascontiguousarray(item_emb_df[item_emb_cols])\n",
    "    # 进行归一化\n",
    "    item_emb_np = item_emb_np / np.linalg.norm(item_emb_np, axis=1, keepdims=True)\n",
    "    item_emb_dict = dict(zip(item_emb_df['article_id'], item_emb_np))\n",
    "    pickle.dump(item_emb_dict, open(save_path + 'item_content_emb.pkl', 'wb'))\n",
    "    return item_emb_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3956f6",
   "metadata": {},
   "source": [
    "- 函数4.：min-max 归一化函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acf3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75682abc",
   "metadata": {},
   "source": [
    "### 开始处理数据\n",
    "- P1.获取全量的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762f8c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_click_df = get_all_click_df(offline=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37585c92",
   "metadata": {},
   "source": [
    "- P2.对时间戳进行归一化,用于在关联规则的时候计算所谓的时间权重；\n",
    "> 用户的下一次点击文章/物品很受前一次的影响，所谓的时间就近效应；所以方便处理权重问题；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea2e6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199999</td>\n",
       "      <td>160417</td>\n",
       "      <td>0.019350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199999</td>\n",
       "      <td>5408</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199999</td>\n",
       "      <td>50823</td>\n",
       "      <td>0.019359</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199998</td>\n",
       "      <td>157770</td>\n",
       "      <td>0.019340</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199998</td>\n",
       "      <td>96613</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518005</th>\n",
       "      <td>221924</td>\n",
       "      <td>70758</td>\n",
       "      <td>0.343615</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518006</th>\n",
       "      <td>207823</td>\n",
       "      <td>331116</td>\n",
       "      <td>0.343675</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518007</th>\n",
       "      <td>207823</td>\n",
       "      <td>234481</td>\n",
       "      <td>0.343760</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518008</th>\n",
       "      <td>207823</td>\n",
       "      <td>211442</td>\n",
       "      <td>0.343853</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518009</th>\n",
       "      <td>207823</td>\n",
       "      <td>211401</td>\n",
       "      <td>0.343888</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1630633 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id  click_timestamp  click_environment  \\\n",
       "0        199999            160417         0.019350                  4   \n",
       "1        199999              5408         0.019351                  4   \n",
       "2        199999             50823         0.019359                  4   \n",
       "3        199998            157770         0.019340                  4   \n",
       "4        199998             96613         0.019378                  4   \n",
       "...         ...               ...              ...                ...   \n",
       "518005   221924             70758         0.343615                  4   \n",
       "518006   207823            331116         0.343675                  4   \n",
       "518007   207823            234481         0.343760                  4   \n",
       "518008   207823            211442         0.343853                  4   \n",
       "518009   207823            211401         0.343888                  4   \n",
       "\n",
       "        click_deviceGroup  click_os  click_country  click_region  \\\n",
       "0                       1        17              1            13   \n",
       "1                       1        17              1            13   \n",
       "2                       1        17              1            13   \n",
       "3                       1        17              1            25   \n",
       "4                       1        17              1            25   \n",
       "...                   ...       ...            ...           ...   \n",
       "518005                  3         2              1            25   \n",
       "518006                  3         2              1            25   \n",
       "518007                  3         2              1            25   \n",
       "518008                  3         2              1            25   \n",
       "518009                  3         2              1            25   \n",
       "\n",
       "        click_referrer_type  \n",
       "0                         1  \n",
       "1                         1  \n",
       "2                         1  \n",
       "3                         5  \n",
       "4                         5  \n",
       "...                     ...  \n",
       "518005                    2  \n",
       "518006                    1  \n",
       "518007                    1  \n",
       "518008                    1  \n",
       "518009                    1  \n",
       "\n",
       "[1630633 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_click_df['click_timestamp'] = all_click_df[['click_timestamp']].apply(max_min_scaler)\n",
    "all_click_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d2e76",
   "metadata": {},
   "source": [
    "- P3.获取文章信息和文章向量；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14fe66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_info_df = get_item_info_df(data_path)\n",
    "item_emb_dict = get_item_emb_dict(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29abab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "316ec62d",
   "metadata": {},
   "source": [
    "- 得到的变量：\n",
    "> 1. all_click_df：获取全量训练集，用户点击日志，如时间，环境系统地区等；将原click_timestamp标准化，并且文章信息item_info_df关联上；\n",
    "> 2. item_info_df：文章的基本信息，ID，品类，创建时间，词数；\n",
    "> 3. item_emb_dict：文章的向量信息：已经降维处理；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec9c162",
   "metadata": {},
   "source": [
    "# C2.召回准备的工作——前期；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1966be8",
   "metadata": {},
   "source": [
    "### S1.用户UserCF协同过滤使用的用户-（物品，时间）字典\n",
    "- 函数1：get_user_item_time_dict()\n",
    "- 根据 点击时间 获取用户文章，形成字典 {user1: [(item1, time1), (item2, time2)..]...} —— UserCF\n",
    "- 基于用户协同过滤使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1a4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n",
    "def get_user_item_time_dict(click_df):\n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    # 定义一个打包函数\n",
    "    def make_item_time_pair(df):  \n",
    "        return list(zip(df['click_article_id'], df['click_timestamp']))\n",
    "    user_item_time_df = click_df.groupby('user_id')['click_article_id', 'click_timestamp'].apply(lambda x: make_item_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'item_time_list'})\n",
    "    user_item_time_dict = dict(zip(user_item_time_df['user_id'], user_item_time_df['item_time_list']))\n",
    "    return user_item_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a95ea",
   "metadata": {},
   "source": [
    "### S2.物品ItemCF协同过滤使用的物品-（用户，时间）字典\n",
    "- 函数2.get_item_user_time_dict()\n",
    "- 根据 点击时间 获取商品被点击的用户序列 {item1: [(user1, time1), (user2, time2)...]...} —— ItemCF\n",
    "- 文章协同过滤时使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c919d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据时间获取商品被点击的用户序列  {item1: [(user1, time1), (user2, time2)...]...}\n",
    "def get_item_user_time_dict(click_df):\n",
    "    # 定义一个打包函数\n",
    "    def make_user_time_pair(df):\n",
    "        return list(zip(df['user_id'], df['click_timestamp']))\n",
    "    click_df = click_df.sort_values('click_timestamp')\n",
    "    item_user_time_df = click_df.groupby('click_article_id')['user_id', 'click_timestamp'].apply(lambda x: make_user_time_pair(x))\\\n",
    "                                                            .reset_index().rename(columns={0: 'user_time_list'})\n",
    "    item_user_time_dict = dict(zip(item_user_time_df['click_article_id'], item_user_time_df['user_time_list']))\n",
    "    return item_user_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3dbe66",
   "metadata": {},
   "source": [
    "### S3.评判和特征工程要用的最后一次点击-记录到每个用户的所有历史点击&最后一次点击记录\n",
    "- 函数：get_hist_and_last_click()\n",
    "- 获取当前数据的历史点击和最后一次点击；\n",
    "- 因为这次项目的评判就是最后一次点击；所以后续特征工程，评判也会用到；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4287f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hist_and_last_click(all_click):\n",
    "    all_click = all_click.sort_values(by=['user_id', 'click_timestamp'])\n",
    "    click_last_df = all_click.groupby('user_id').tail(1)\n",
    "    # 如果用户只有一个点击，hist为空了，会导致训练的时候这个用户不可见，此时默认泄露一下\n",
    "    def hist_func(user_df):\n",
    "        if len(user_df) == 1:\n",
    "            return user_df\n",
    "        else:\n",
    "            return user_df[:-1]\n",
    "    click_hist_df = all_click.groupby('user_id').apply(hist_func).reset_index(drop=True)\n",
    "    return click_hist_df, click_last_df\n",
    "# 提取最后一次点击作为召回评估，如果不需要做召回评估直接使用全量的训练集进行召回(线下验证模型)\n",
    "# 如果不是召回评估，直接使用全量数据进行召回，不用将最后一次提取出来\n",
    "trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b50eeb",
   "metadata": {},
   "source": [
    "### S4.冷启动要用的字典特征——为了冷启动阶段召回用，基于文章/物品特性的召回；\n",
    "- 函数：get_item_info_dict()\n",
    "- 获取文章id对应的基本属性，保存成字典的形式，方便后面召回阶段，冷启动阶段直接使用；\n",
    "- 返回三个对象，一个是文章——类型字典；一个是文章——词数字典；一个是文章——创建时间字典\n",
    "- 必须基于文章属性获取的情况下才能运行；——这句话看似是废话，但是确实是废话，文章属性没有冷启动启动毛？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91d6f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_info_dict(item_info_df):\n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    item_info_df['created_at_ts'] = item_info_df[['created_at_ts']].apply(max_min_scaler)\n",
    "    item_type_dict = dict(zip(item_info_df['click_article_id'], item_info_df['category_id']))\n",
    "    item_words_dict = dict(zip(item_info_df['click_article_id'], item_info_df['words_count']))\n",
    "    item_created_time_dict = dict(zip(item_info_df['click_article_id'], item_info_df['created_at_ts']))\n",
    "    return item_type_dict, item_words_dict, item_created_time_dict\n",
    "item_type_dict, item_words_dict, item_created_time_dict = get_item_info_dict(item_info_df)\n",
    "# item_type_dict：每一篇文章的类型字典；\n",
    "# item_words_dict：每一篇文章的字数字典；\n",
    "# item_created_time_dict：创建时间信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b848b2",
   "metadata": {},
   "source": [
    "### S5.获取用户对应的历史点击的文章信息，以字典形式存储：\n",
    "- 函数：get_user_hist_item_info_dict()\n",
    "- 返回四个字典：一是用户和点击文章的类型字典；二是用户和点击文章的字典；三是用户和点击文章平均词语数字典；四是用户和最后一次点击文章时间字典\n",
    "- 相当于间接做一个简略版的用户画像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "febcb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_hist_item_info_dict(all_click):\n",
    "    # 获取user_id对应的用户历史点击文章类型的集合字典\n",
    "    user_hist_item_typs = all_click.groupby('user_id')['category_id'].agg(set).reset_index()\n",
    "    user_hist_item_typs_dict = dict(zip(user_hist_item_typs['user_id'], user_hist_item_typs['category_id']))\n",
    "    # 获取user_id对应的用户点击文章的集合\n",
    "    user_hist_item_ids_dict = all_click.groupby('user_id')['click_article_id'].agg(set).reset_index()\n",
    "    user_hist_item_ids_dict = dict(zip(user_hist_item_ids_dict['user_id'], user_hist_item_ids_dict['click_article_id']))\n",
    "    # 获取user_id对应的用户历史点击的文章的平均字数字典\n",
    "    user_hist_item_words = all_click.groupby('user_id')['words_count'].agg('mean').reset_index()\n",
    "    user_hist_item_words_dict = dict(zip(user_hist_item_words['user_id'], user_hist_item_words['words_count']))\n",
    "    # 获取user_id对应的用户最后一次点击的文章的创建时间\n",
    "    all_click_ = all_click.sort_values('click_timestamp')\n",
    "    user_last_item_created_time = all_click_.groupby('user_id')['created_at_ts'].apply(lambda x: x.iloc[-1]).reset_index()\n",
    "    max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))\n",
    "    user_last_item_created_time['created_at_ts'] = user_last_item_created_time[['created_at_ts']].apply(max_min_scaler)\n",
    "    user_last_item_created_time_dict = dict(zip(user_last_item_created_time['user_id'], \\\n",
    "                                                user_last_item_created_time['created_at_ts']))\n",
    "    return user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158cb73",
   "metadata": {},
   "source": [
    "### S6.最近点击次数最多的topK个文章的索引；召回不足时使用；\n",
    "- 函数：get_item_topk_click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79d5ae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_topk_click(click_df, k):\n",
    "    topk_click = click_df['click_article_id'].value_counts().index[:k]\n",
    "    return topk_click"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2198dd8",
   "metadata": {},
   "source": [
    "- 得到的变量：\n",
    "> 1. item_type_dict：每一篇文章的类型字典；\n",
    "> 2. item_words_dict：每一篇文章的字数字典；\n",
    "> 3. item_created_time_dict：创建时间信息\n",
    "> 4. trn_hist_click_df：用户历史点击信息\n",
    "> 5. trn_last_click_df：用户最后一次点击信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af196ca4",
   "metadata": {},
   "source": [
    "# C3.召回准备的工作——后期"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508a982",
   "metadata": {},
   "source": [
    "- S1.建立多方法召回的信息储存池；user_multi_recall_info_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40901ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个多路召回的字典，将各路召回的结果都保存在这个字典当中\n",
    "# user_multi_recall_dict_info =  {'itemcf_sim_item_recall': {}, 'usercf_sim_item_recall': {}}    \n",
    "user_multi_recall_dict_info =  {'itemcf_sim_item_recall': {},\n",
    "                                'usercf_sim_item_recall': {},\n",
    "                           'embedding_sim_item_recall': {},\n",
    "                           'cold_start_recall': {}}            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc24da3",
   "metadata": {},
   "source": [
    "- S2.召回效果评估函数：metrics_recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ddd2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 依次评估召回的前10, 20, 30, 40, 50个文章中的击中率可以\n",
    "# def metrics_recall(user_recall_items_dict, trn_last_click_df, topk=5):\n",
    "def metrics_recall(user_recall_items_dict, trn_last_click_df, topk=20):\n",
    "    last_click_item_dict = dict(zip(trn_last_click_df['user_id'], trn_last_click_df['click_article_id']))\n",
    "    user_num = len(user_recall_items_dict)\n",
    "    for k in range(10, topk+1, 10):\n",
    "        hit_num = 0\n",
    "        for user, item_list in user_recall_items_dict.items():\n",
    "            # 获取前k个召回的结果\n",
    "            tmp_recall_items = [x[0] for x in user_recall_items_dict[user][:k]]\n",
    "            if last_click_item_dict[user] in set(tmp_recall_items):\n",
    "                hit_num += 1\n",
    "        hit_rate = round(hit_num * 1.0 / user_num, 5)\n",
    "        print(' topk: ', k, ' : ', 'hit_num: ', hit_num, 'hit_rate: ', hit_rate, 'user_num : ', user_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2d073c",
   "metadata": {},
   "source": [
    "### P1.基于ItemCF计算文章相似度矩阵：\n",
    "KDD2020论坛中有关于修正商品偏好修正推荐的逻辑，在计算item2item相似性矩阵时，使用关联规则，使得计算的文章相似性同时需要考虑:\n",
    "> 1. 用户点击的时间权重\n",
    "> 2. 文章创建的时间权重\n",
    "- 两次点击时间差得少，1/exp(0.6 * (1 - 1)) = 1；两次点击时间差得多，1/exp(0.6 * (1 - 0.5)) = 1.34\n",
    "- 因此需要传入训练数据 all_click_df + item_created_time_dict，后者是为了在文章创建时间上进行权重修正；\n",
    "- 计算好的文章之间相似度保存在i2i_sim变量，同时生成字典存在本地itemcf_i2i_sim.pkl，可以后续加载\n",
    "- 函数：itemcf_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52fd6a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemcf_sim(all_click_df, item_created_time_dict):\n",
    "    \"\"\"\n",
    "        文章与文章之间的相似性矩阵计算\n",
    "        :param df: 数据表\n",
    "        :item_created_time_dict:  文章创建时间的字典\n",
    "        return : 文章与文章的相似性矩阵\n",
    "        思路: 基于物品的协同过滤(详细请参考上一期推荐系统基础的组队学习)， 在多路召回部分会加上关联规则的召回策略\n",
    "    \"\"\"\n",
    "    # S1.先获取用户的每一篇文章，以及点击的时间，以字典形式\n",
    "    user_item_time_dict = get_user_item_time_dict(all_click_df)\n",
    "    # 计算物品相似度\n",
    "    #---下面为余弦相似度计算公式的分子部分；这里是点没点，也就是0-1所以可以用余弦相似度/杰卡德相似度\n",
    "    i2i_sim = {} #记录物品之间的相似度字典——准确来说是相似度的分子部分\n",
    "    item_cnt = defaultdict(int) # 记录相似物品数量的字典；defaultdict可以应对key值不存在的情形，不然的话还得用if else来判断它是否存在，不存在新建，存在才在下面+=1\n",
    "    for user, item_time_list in tqdm(user_item_time_dict.items()):\n",
    "        # 在基于商品的协同过滤优化的时候可以考虑时间 + 物品流行度等因素；这里暂时没有考虑流行度；\n",
    "        # 还要遍历每个用户所有的点击文章和时间，其实就是所有的物品和时间，i是物品，click_time是触发时间\n",
    "        for loc1, (i, i_click_time) in enumerate(item_time_list):\n",
    "            item_cnt[i] += 1\n",
    "            i2i_sim.setdefault(i, {})#setdefault其实就是初始化，如果已经存在了i就保持不变，如果不存在就初始化一个出来\n",
    "            for loc2, (j, j_click_time) in enumerate(item_time_list): # 物品与物品的相似度，当然还得遍历一遍物品 \n",
    "                if(i == j):   # 物品与物品之间相同，直接跳过\n",
    "                    continue      \n",
    "                # 考虑文章的正向顺序点击和反向顺序点击    \n",
    "                loc_alpha = 1.0 if loc2 > loc1 else 0.7 \n",
    "                # 位置信息权重，其中的参数可以调节\n",
    "                loc_weight = loc_alpha * (0.8 ** (np.abs(loc2 - loc1) - 1))\n",
    "                # 点击时间权重，其中的参数可以调节\n",
    "                click_time_weight = np.exp(0.8 ** np.abs(i_click_time - j_click_time))\n",
    "                # 两篇文章创建时间的权重，其中的参数可以调节\n",
    "                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                i2i_sim[i].setdefault(j, 0)\n",
    "                # 考虑多种因素的权重计算最终的文章之间的相似度\n",
    "                i2i_sim[i][j] += loc_weight * click_time_weight * created_time_weight / math.log(len(item_time_list) + 1) \n",
    "#                 i2i_sim[i][j] += click_time_weight * created_time_weight / math.log(len(item_time_list) + 1) \n",
    "    i2i_sim_ = i2i_sim.copy()\n",
    "    for i, related_items in i2i_sim.items():\n",
    "        for j, wij in related_items.items():\n",
    "            i2i_sim_[i][j] = wij / math.sqrt(item_cnt[i] * item_cnt[j])\n",
    "    # 将得到的相似性矩阵保存到本地，保存到指定路径的itemcf_i2i_sim.pkl\n",
    "    # 也可以保存成csv吧？\n",
    "    pickle.dump(i2i_sim_, open(save_path + 'itemcf_i2i_sim.pkl', 'wb'))\n",
    "    return i2i_sim_\n",
    "# i2i_sim = itemcf_sim(all_click_df, item_created_time_dict)\n",
    "# 已经计算完成的话可以直接读取本地的存储文件\n",
    "i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597fddb",
   "metadata": {},
   "source": [
    "## P2.基于UserCF计算用户相似度矩阵：\n",
    "- 在计算用户之间的相似度的时候，也可以使用一些简单的关联规则，\n",
    "- 比如用户活跃度权重，这里将用户的点击次数作为用户活跃度的指标；这里就是记录条数；\n",
    "- 用二人之间活跃度作权重修正；\n",
    "- 函数1：get_user_activate_degree_dict()计算活跃度；——但是这种活跃度计算效率不敢恭维。。。谨慎运行，本人已崩N次。。。\n",
    "- 函数2：usercf_sim()计算用户相似性\n",
    "> 1. 先用get_user_activate_degree_dict通过用户的点击次数标准化所谓的活跃度；得到一个字典；{用户i:活跃度i。。。。}\n",
    "> 2. 再用usercf_sim通过用户的点击次数标准化所谓的活跃度；\n",
    "- 这里由于是采用了采样的办法，所以有一部分用户字典中没有键值，只有键；\n",
    "- 计算好的用户相似型信息保存在本地存储路径文件：usercf_u2u_sim.pkl\n",
    "- 切记：：：：\n",
    "- 该段代码如果你没有顶级内存CPU，必然炸球，这里的结果是用户采样的结果，全数据必炸球！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c39ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_activate_degree_dict(all_click_df):\n",
    "    all_click_df_ = all_click_df.groupby('user_id')['click_article_id'].count().reset_index()\n",
    "    # 用户活跃度归一化\n",
    "    mm = MinMaxScaler()\n",
    "    all_click_df_['click_article_id'] = mm.fit_transform(all_click_df_[['click_article_id']])\n",
    "    user_activate_degree_dict = dict(zip(all_click_df_['user_id'], all_click_df_['click_article_id']))\n",
    "    return user_activate_degree_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3305137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def usercf_sim(all_click_df, user_activate_degree_dict):\n",
    "    \"\"\"\n",
    "        用户相似性矩阵计算\n",
    "        :param all_click_df: 数据表\n",
    "        :param user_activate_degree_dict: 用户活跃度的字典\n",
    "        return 用户相似性矩阵\n",
    "        \n",
    "        思路: 基于用户的协同过滤(详细请参考上一期推荐系统基础的组队学习) + 关联规则\n",
    "    \"\"\"\n",
    "    item_user_time_dict = get_item_user_time_dict(all_click_df)\n",
    "    \n",
    "    u2u_sim = {}\n",
    "    user_cnt = defaultdict(int)\n",
    "    for item, user_time_list in tqdm(item_user_time_dict.items()):\n",
    "        for u, click_time in user_time_list:\n",
    "            user_cnt[u] += 1\n",
    "            u2u_sim.setdefault(u, {})\n",
    "            for v, click_time in user_time_list:\n",
    "                u2u_sim[u].setdefault(v, 0)\n",
    "                # 自己和自己没必要；\n",
    "                if u == v:\n",
    "                    continue\n",
    "                # 用户平均活跃度作为活跃度的权重，这里的式子也可以改善\n",
    "                activate_weight = 100 * 0.5 * (user_activate_degree_dict[u] + user_activate_degree_dict[v])   \n",
    "                u2u_sim[u][v] += activate_weight / math.log(len(user_time_list) + 1)\n",
    "    u2u_sim_ = u2u_sim.copy()\n",
    "    for u, related_users in u2u_sim.items():\n",
    "        for v, wij in related_users.items():\n",
    "            u2u_sim_[u][v] = wij / math.sqrt(user_cnt[u] * user_cnt[v])\n",
    "    # 将得到的相似性矩阵保存到本地\n",
    "    pickle.dump(u2u_sim_, open(save_path + 'usercf_u2u_sim.pkl', 'wb'))\n",
    "    return u2u_sim_\n",
    "user_activate_degree_dict = get_user_activate_degree_dict(all_click_df)\n",
    "# u2u_sim = usercf_sim(all_click_df, user_activate_degree_dict)\n",
    "# 已经计算好的可以直接读取本地文件\n",
    "u2u_sim = pickle.load(open(save_path + 'usercf_u2u_sim.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a37542",
   "metadata": {},
   "source": [
    "## P3.Item embedding召回——计算Embedding相似度；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0d86b",
   "metadata": {},
   "source": [
    "### S1.事前准备\n",
    "- 有个思路：\n",
    "> 1. 结合用户的行为，比如他点击最多的品类；—因为还是从物品的角度考虑，所以叫ItemEmbedding基于计算好的emb相似度，去召回；\n",
    "> 2. 拼接上topN点击数最多的文章\n",
    "- 以下代码慎重运行；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cosine_similarity_def(x,y):\n",
    "#     num = x.dot(y.T)\n",
    "#     denom = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "#     return num / denom\n",
    "# i2i_emb_sim = {}\n",
    "# for item_i in tqdm(list(item_emb_dict.keys())):\n",
    "#     i2i_emb_sim.setdefault(item_i, {})\n",
    "#     for item_j in item_emb_dict:\n",
    "#         if item_i == item_j :\n",
    "#             continue\n",
    "#         i2i_emb_sim[item_i].setdefault(item_j, 0)\n",
    "#         similarity_ij = cosine_similarity_def(item_emb_dict[item_i], item_emb_dict[item_j])\n",
    "#         if similarity_ij>=0.8:\n",
    "#             i2i_emb_sim[item_i][item_j] = similarity_ij\n",
    "#         else:\n",
    "#             continue\n",
    "# pickle.dump(i2i_emb_sim, open(save_path + 'emb_i2i_sim.pkl', 'wb'))\n",
    "# 如果有直接计算好的可以直接读取\n",
    "emb_i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6dfa65",
   "metadata": {},
   "source": [
    "# C4.召回正式流程启动！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7199dd01",
   "metadata": {},
   "source": [
    "## P1.itemCF 召回"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d2ca3b",
   "metadata": {},
   "source": [
    "### S1.定义Item召回函数\n",
    "- 函数：item_based_recommend()\n",
    "- 需要\n",
    "> 1. 指定用户；                      ——需要遍历：\n",
    "> 2. 用户的点击物品-时间字典；            ——函数get_user_item_time_dict得到，user_item_time_dict\n",
    "> 3. 物品相似度矩阵：                  ——函数itemcf_sim得到，i2i_sim\n",
    "> 4. 返回的相似物品数目；               ——需要指定sim_item_topk\n",
    "> 5. 需要召回的物品数目；               ——需要指定recall_item_num              \n",
    "> 6. 最热门的点击物品（补足用）；          ——通过函数get_item_topk_click()得到，\n",
    "> 7. 物品创建时间字典 ；                ——item_created_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c199194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommend(user_id, user_item_time_dict, i2i_sim, sim_item_topk, recall_item_num, item_topk_click, item_created_time_dict):    \n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        : user_id: 用户id\n",
    "        : user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列  {user1: [(item1, time1), (item2, time2)..]...}\n",
    "        : i2i_sim: 字典，物品文章相似性矩阵\n",
    "        : sim_item_topk: 整数， 选择与当前文章物品最相似的前k篇文章\n",
    "        : recall_item_num: 整数， 最后的召回文章数量\n",
    "        : item_topk_click: 列表，点击次数最多的文章列表，用户召回补全\n",
    "        : emb_i2i_sim: 字典基于内容embedding算的文章相似矩阵\n",
    "        return: 召回的文章列表 [(item1, score1), (item2, score2)...]\n",
    "    \"\"\"\n",
    "    # 获取用户历史交互的文章\n",
    "    user_hist_items = user_item_time_dict[user_id]\n",
    "    user_hist_items_ = {user_id for user_id, _ in user_hist_items }\n",
    "    item_rank = {}\n",
    "    for loc, (i, click_time) in enumerate(user_hist_items):\n",
    "        try:\n",
    "            for j, wij in sorted(i2i_sim[i].items(), key=lambda x: x[1], reverse=True)[:sim_item_topk]:\n",
    "                if j in user_hist_items_:\n",
    "                    continue\n",
    "                # 文章创建时间差权重加入到其中尝试\n",
    "                created_time_weight = np.exp(0.8 ** np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "                # 相似文章和历史点击文章序列中历史文章所在的位置权重\n",
    "                loc_weight = (0.9 ** (len(user_hist_items) - loc))\n",
    "                content_weight = 1.0\n",
    "                item_rank.setdefault(j, 0)\n",
    "                item_rank[j] += created_time_weight * content_weight * wij\n",
    "        except:\n",
    "            continue\n",
    "    # 不足10个，用热门商品补全\n",
    "    if len(item_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in item_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            item_rank[item] = - i - 100 # 随便给个负数就行\n",
    "            if len(item_rank) == recall_item_num:\n",
    "                break    \n",
    "    item_rank = sorted(item_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]\n",
    "    return item_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350c63b9",
   "metadata": {},
   "source": [
    "## S2.进行ItemCF物品召回，并保存结果评估；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aea4bfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先进行itemcf召回, 为了召回评估，所以提取最后一次点击\n",
    "# 这里走的是下面这一条，就是历史点击信息，也就是全训练数据\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "# 默认生成一个字典，保存后续每一种召回方式召回的结果\n",
    "# user_recall_items_dict = collections.defaultdict(dict)\n",
    "ItemCF_user_recall_items_dict = collections.defaultdict(dict)\n",
    "# 得到用户点击历史：即用户u:([物品i,点击时间i]...)字典\n",
    "user_item_time_dict = get_user_item_time_dict(trn_hist_click_df)\n",
    "# 得到物品间的相似度，加载本地得到的结果，是一个字典\n",
    "i2i_sim = pickle.load(open(save_path + 'itemcf_i2i_sim.pkl', 'rb'))\n",
    "# 用30个点击数最多的文章做备用填充\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=30)\n",
    "# 指定相似物品数30,召回物品数20\n",
    "sim_item_topk = 35\n",
    "recall_item_num = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf71fb",
   "metadata": {},
   "source": [
    "#### WARNING：如果物品召回数据信息ItemCF_user_recall_items_dict，已经计算好的话，下面这段代码要跳过，太吃内存；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "050c2230",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 250000/250000 [1:22:28<00:00, 50.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# 遍历训练集中所有的去重用户：\n",
    "# 参数是指定的用户id，用户点击物品时间字典，物品相似度，需要返回的相似物品数目，需要召回的物品数，做备用的50个点击数最多的文章物品，文章物品创建时间\n",
    "for user_id in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "#     user_recall_items_dict[user_id] = item_based_recommend(user_id, user_item_time_dict, \\\n",
    "#                                                         i2i_sim, sim_item_topk, recall_item_num, \\\n",
    "#                                                         item_topk_click, item_created_time_dict)\n",
    "    ItemCF_user_recall_items_dict[user_id] = item_based_recommend(user_id, user_item_time_dict, \\\n",
    "                                                        i2i_sim, sim_item_topk, recall_item_num, \\\n",
    "                                                        item_topk_click, item_created_time_dict)\n",
    "user_multi_recall_dict_info['itemcf_sim_item_recall'] = ItemCF_user_recall_items_dict\n",
    "# 基于用户ItemCF的召回结果保存到本地指定路径文件名为itemcf_recall_dict.pkl\n",
    "pickle.dump(user_multi_recall_dict_info['itemcf_sim_item_recall'], open(save_path + 'itemcf_recall_dict.pkl', 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d6bfc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 如果已经保存好可以直接读取！\n",
    "# ItemCF_user_recall_items_dict = pickle.load(open(save_path +'itemcf_recall_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3be3c46",
   "metadata": {},
   "source": [
    "### 已经计算好的ItemCF召回结果可以直接读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc7f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已经计算好的ItemCF召回结果可以直接读取\n",
    "ItemCF_user_recall_items_dict = pickle.load(open(save_path + 'itemcf_recall_dict.pkl', 'rb'))\n",
    "user_multi_recall_dict_info['itemcf_sim_item_recall'] = ItemCF_user_recall_items_dict\n",
    "# # # 如果需要评估：\n",
    "# if True:\n",
    "#     # 召回效果评估\n",
    "#     metrics_recall(user_multi_recall_dict_info['itemcf_sim_item_recall'], all_click_df, topk=100)\n",
    "# #     metrics_recall(user_multi_recall_dict_info['itemcf_sim_item_recall'], all_click_df, topk=recall_item_num)\n",
    "# # recall_item_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2e555",
   "metadata": {},
   "source": [
    "## P2.基于userCF召回；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d3cc44",
   "metadata": {},
   "source": [
    "### S1.定义User召回函数\n",
    "- 函数：user_based_recommend()\n",
    "- 需要\n",
    "> 1. 指定用户；                      ——需要遍历：\n",
    "> 2. 用户的点击物品-时间字典；            ——函数get_user_item_time_dict得到，user_item_time_dict\n",
    "> 3. 用户相似度矩阵：                  ——函数usercf_sim得到或者加载本地储存结果，u2u_sim\n",
    "> 4. 返回的相似用户数目；               ——需要指定sim_user_topk\n",
    "> 5. 需要召回的物品数目；               ——需要指定recall_item_num              \n",
    "> 6. 最热门的点击物品（补足用）；          ——通过函数get_item_topk_click()得到，\n",
    "> 7. 物品创建时间字典 ；                ——item_created_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于用户的召回 u2u2i\n",
    "def user_based_recommend(user_id, user_item_time_dict, u2u_sim, sim_user_topk, recall_item_num, item_topk_click, item_created_time_dict):\n",
    "    \"\"\"\n",
    "        基于文章协同过滤的召回\n",
    "        :param user_id: 用户id\n",
    "        :param user_item_time_dict: 字典, 根据点击时间获取用户的点击文章序列   {user1: [(item1, time1), (item2, time2)..]...}\n",
    "        :param u2u_sim: 字典，用户间相似度矩阵\n",
    "        :param sim_user_topk: 整数， 选择与当前用户最相似的前k个用户\n",
    "        :param recall_item_num: 整数， 最后的召回文章数量\n",
    "        :param item_topk_click: 列表，点击次数最多的文章列表，召回补全\n",
    "        :param item_created_time_dict: 文章创建时间列表\n",
    "        return: 召回的文章列表 [(item1, score1), (item2, score2)...]\n",
    "    \"\"\"\n",
    "    # 历史交互\n",
    "    user_item_time_list = user_item_time_dict[user_id]    # {item1: time1, item2: time2...}\n",
    "    user_hist_items = set([i for i, t in user_item_time_list])   # 存在一个用户与某篇文章的多次交互， 这里得去重\n",
    "    items_rank = {}\n",
    "    for sim_u, wuv in sorted(u2u_sim[user_id].items(), key=lambda x: x[1], reverse=True)[:sim_user_topk]:\n",
    "        for i, click_time in user_item_time_dict[sim_u]:\n",
    "            if i in user_hist_items:\n",
    "                continue\n",
    "            items_rank.setdefault(i, 0)\n",
    "#             loc_weight = 1.0\n",
    "            content_weight = 1.0\n",
    "            created_time_weight = 1.0\n",
    "            # 当前文章与该用户看的历史文章进行一个权重交互\n",
    "            for loc, (j, click_time) in enumerate(user_item_time_list):\n",
    "                # 点击时的相对位置权重\n",
    "#                 loc_weight += 0.6 ** (len(user_item_time_list) - loc)\n",
    "                # 内容相似性权重，还是省略掉\n",
    "#                 if emb_i2i_sim.get(i, {}).get(j, None) is not None:\n",
    "#                     content_weight += emb_i2i_sim[i][j]\n",
    "#                 if emb_i2i_sim.get(j, {}).get(i, None) is not None:\n",
    "#                     content_weight += emb_i2i_sim[j][i]\n",
    "                # 创建时间差权重\n",
    "                created_time_weight += np.exp(0.8 * np.abs(item_created_time_dict[i] - item_created_time_dict[j]))\n",
    "            items_rank[i] += content_weight * created_time_weight * wuv\n",
    "    # 热度补全\n",
    "    if len(items_rank) < recall_item_num:\n",
    "        for i, item in enumerate(item_topk_click):\n",
    "            if item in items_rank.items(): # 填充的item应该不在原来的列表中\n",
    "                continue\n",
    "            items_rank[item] = - i - 100 # 随便给个复数就行\n",
    "            if len(items_rank) == recall_item_num:\n",
    "                break\n",
    "    items_rank = sorted(items_rank.items(), key=lambda x: x[1], reverse=True)[:recall_item_num]    \n",
    "    return items_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4b96fd",
   "metadata": {},
   "source": [
    "### S2.进行UserCF物品召回，并保存结果评估；\n",
    "—— 其实也要慎重运行；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d6ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里是为了召回评估，所以提取最后一次点击\n",
    "# 由于usercf中计算user之间的相似度的过程太费内存了，全量数据这里就没有跑，跑了一个采样之后的数据\n",
    "if metric_recall:\n",
    "    trn_hist_click_df, trn_last_click_df = get_hist_and_last_click(all_click_df)\n",
    "else:\n",
    "    trn_hist_click_df = all_click_df\n",
    "# 生成召回字典\n",
    "UserCF_user_recall_items_dict = collections.defaultdict(dict)\n",
    "# 获取用户行为数据字典\n",
    "user_item_time_dict = get_user_item_time_dict(trn_hist_click_df)\n",
    "# 加载计算好的用户相似度\n",
    "u2u_sim = pickle.load(open(save_path + 'usercf_u2u_sim.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user_topk = 15\n",
    "recall_item_num = 10\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "# 遍历用户，因为有空的用户，所以遍历时按照异常处理\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    try:\n",
    "        UserCF_user_recall_items_dict[user] = user_based_recommend(user, user_item_time_dict, u2u_sim, sim_user_topk, \\\n",
    "                                                            recall_item_num, item_topk_click, item_created_time_dict)  \n",
    "    except:\n",
    "        UserCF_user_recall_items_dict[user] = None\n",
    "# 用户的召回结果保存到本地指定临时存储路径文件 usercf_u2u2i_recall.pkl\n",
    "pickle.dump(UserCF_user_recall_items_dict, open(save_path + 'usercf_u2u2i_recall.pkl', 'wb'))\n",
    "user_multi_recall_dict_info['usercf_sim_item_recall'] = UserCF_user_recall_items_dict\n",
    "if metric_recall:\n",
    "    # 召回效果评估\n",
    "    metrics_recall(user_multi_recall_dict_info, trn_last_click_df, topk=recall_item_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26ab7d0",
   "metadata": {},
   "source": [
    "### 已经计算好的UserCF召回结果可以直接读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81e7592",
   "metadata": {},
   "outputs": [],
   "source": [
    "UserCF_user_recall_items_dict = pickle.load(open(save_path + 'usercf_u2u2i_recall.pkl', 'rb'))\n",
    "user_multi_recall_dict_info['usercf_sim_item_recall'] = UserCF_user_recall_items_dict\n",
    "# # 如果需要评估：\n",
    "# if metric_recall:\n",
    "#     # 召回效果评估\n",
    "#     metrics_recall(user_multi_recall_dict_info['itemcf_sim_itemcf_recall'], trn_last_click_df, topk=recall_item_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13607103",
   "metadata": {},
   "source": [
    "## P3.冷启动召回——尝试篇\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a3986c",
   "metadata": {},
   "source": [
    "- 基于规则进行文章过滤\n",
    "- 保留文章主题与用户历史浏览主题相似的文章\n",
    "- 保留文章字数与用户历史浏览文章字数相差不大的文章\n",
    "- 保留最后一次点击当天的文章\n",
    "- 按照相似度返回最终的结果\n",
    "- 鉴于用户冷启动的相似度计算有缺失数据，所以这里逼不得已使用物品冷启动；就是文章冷启动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86f2281",
   "metadata": {},
   "source": [
    "### S1.定义冷启动召回函数\n",
    "- 物品没有曝被该用户点击过，但是和用户的行为接触过的很相像的，基于embedding\n",
    "> 1. user_article_click_prefer ：用户点击行为拼接文章属性信息；\n",
    "> 2. user_article_click_prefer_count：用户对文章类别点击的次数统计；——按照用户和点击时间排序；\n",
    "> 3. user_article_click_prefer_wordsmean：用户对文章类别点击的词语数平均值统计；\n",
    "> 4. user_article_click_prefer_cold_system：用户对文章类别点击次数统计 + 平均词语数，作为冷启动标准；用于判定用户是否对该类别、词数的文章更有偏爱性；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a409672",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_article_click_prefer = all_click_df.merge(item_info_df,left_on=\"click_article_id\",right_on=\"click_article_id\",how=\"left\")\n",
    "user_article_click_prefer_count = user_article_click_prefer.groupby([\"user_id\",\"category_id\"])[\"click_timestamp\"].count().reset_index().sort_values([\"user_id\",\"click_timestamp\"])\n",
    "user_article_click_prefer_wordsmean = user_article_click_prefer.groupby([\"user_id\",\"category_id\"])[\"words_count\"].mean().reset_index()\n",
    "user_article_click_prefer_cold_system = user_article_click_prefer_count.merge(user_article_click_prefer_wordsmean,left_on=[\"user_id\",\"category_id\"],right_on=[\"user_id\",\"category_id\"],how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f0abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先进行itemcf召回，这里不需要做召回评估，这里只是一种策略\n",
    "trn_hist_click_df = all_click_df\n",
    "user_recall_items_dict = collections.defaultdict(dict)\n",
    "user_item_time_dict = get_user_item_time_dict(trn_hist_click_df)\n",
    "i2i_sim = pickle.load(open(save_path + 'emb_i2i_sim.pkl','rb'))\n",
    "\n",
    "sim_item_topk = 150\n",
    "recall_item_num = 100 # 稍微召回多一点文章，便于后续的规则筛选\n",
    "\n",
    "item_topk_click = get_item_topk_click(trn_hist_click_df, k=50)\n",
    "# for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "#     user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "#                                                         recall_item_num, item_topk_click,item_created_time_dict, emb_i2i_sim)\n",
    "for user in tqdm(trn_hist_click_df['user_id'].unique()):\n",
    "    user_recall_items_dict[user] = item_based_recommend(user, user_item_time_dict, i2i_sim, sim_item_topk, \n",
    "                                                        recall_item_num, item_topk_click,item_created_time_dict)\n",
    "pickle.dump(user_recall_items_dict, open(save_path + 'cold_start_items_raw_dict.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00194606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于规则进行文章过滤\n",
    "# 保留文章主题与用户历史浏览主题相似的文章\n",
    "# 保留文章字数与用户历史浏览文章字数相差不大的文章\n",
    "# 保留最后一次点击当天的文章\n",
    "# 按照相似度返回最终的结果\n",
    "def get_click_article_ids_set(all_click_df):\n",
    "    return set(all_click_df.click_article_id.values)\n",
    "\n",
    "def cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \\\n",
    "                     user_last_item_created_time_dict, item_type_dict, item_words_dict, \n",
    "                     item_created_time_dict, click_article_ids_set, recall_item_num):\n",
    "    \"\"\"\n",
    "        冷启动的情况下召回一些文章\n",
    "        :param user_recall_items_dict: 基于内容embedding相似性召回来的很多文章， 字典， {user1: [item1, item2, ..], }\n",
    "        :param user_hist_item_typs_dict: 字典， 用户点击的文章的类别字典\n",
    "        :param user_hist_item_words_dict: 字典， 用户点击的历史文章的词语数\n",
    "        :param user_last_item_created_time_idct: 字典，用户点击的历史文章创建时间\n",
    "        :param item_tpye_idct: 字典，文章类别\n",
    "        :param item_words_dict: 字典，文章词语数\n",
    "        :param item_created_time_dict: 字典， 文章创建时间\n",
    "        :param click_article_ids_set: 集合，用户点击过得文章, 也就是日志里面出现过的文章\n",
    "        :param recall_item_num: 召回文章的数量， 这个指的是没有出现在日志里面的文章数量\n",
    "    \"\"\"\n",
    "    cold_start_user_items_dict = {}\n",
    "    for user, item_list in tqdm(user_recall_items_dict.items()):\n",
    "        cold_start_user_items_dict.setdefault(user, [])\n",
    "        for item, score in item_list:\n",
    "            # 获取历史文章信息部分\n",
    "            # hist_item_type_set：获取该用户的点击过的文章类别；\n",
    "            hist_item_type_set = user_hist_item_typs_dict[user]\n",
    "            # hist_mean_words：获取该用户的点击过的文章词数；\n",
    "            hist_mean_words = user_hist_item_words_dict[user]\n",
    "            # hist_last_item_created_time 获取该用户点击过的文章的创建时间，时间戳解析\n",
    "            hist_last_item_created_time = user_last_item_created_time_dict[user]\n",
    "            hist_last_item_created_time = datetime.fromtimestamp(hist_last_item_created_time)\n",
    "            \n",
    "            # 获取当前召回文章的信息\n",
    "            # curr_item_type：获取该文章物品的类别\n",
    "            curr_item_type = item_type_dict[item]\n",
    "            # curr_item_words；获取该文章的词语数\n",
    "            curr_item_words = item_words_dict[item]\n",
    "            # 获取该文章的创建时间，解析时间戳\n",
    "            curr_item_created_time = item_created_time_dict[item]\n",
    "            curr_item_created_time = datetime.fromtimestamp(curr_item_created_time)\n",
    "\n",
    "            # 首先，文章不能出现在用户的历史点击中， 然后根据文章主题，文章单词数，文章创建时间进行筛选\n",
    "            # 该文章物品的类别不在用户点击过得历史类别中 或      ————————因为要帮用户在其点击过的类别中寻找相似者，不在就刨除；\n",
    "            # 该文章物品在用户点击过得物品中 或                  ————————点击过得就不要了\n",
    "            # 该文章物品词语数超过用户历史点击过得文章平均词语数200个           ——————————超过历史平均值的200词语以上\n",
    "            # 该文章物品创建时间超过用户历史点击过得文章创建时间90天            ——————————太久了自然不感兴趣\n",
    "            if curr_item_type not in hist_item_type_set or \\\n",
    "                item in click_article_ids_set or \\\n",
    "                abs(curr_item_words - hist_mean_words) > 200 or \\\n",
    "                abs((curr_item_created_time - hist_last_item_created_time).days) > 90: \n",
    "                continue\n",
    "            ###### 剩下的都拿来，很多关键；\n",
    "            cold_start_user_items_dict[user].append((item, score))      # {user1: [(item1, score1), (item2, score2)..]...}\n",
    "    \n",
    "    # 控制一下冷启动召回的数量\n",
    "    cold_start_user_items_dict = {k: sorted(v, key=lambda x:x[1], reverse=True)[:recall_item_num] \\\n",
    "                                  for k, v in cold_start_user_items_dict.items()}\n",
    "    pickle.dump(cold_start_user_items_dict, open(save_path + 'cold_start_user_items_dict.pkl', 'wb'))\n",
    "    return cold_start_user_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9d3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_click_df_ = all_click_df.copy()\n",
    "all_click_df_ = all_click_df_.merge(item_info_df, how='left', on='click_article_id')\n",
    "user_hist_item_typs_dict, user_hist_item_ids_dict, user_hist_item_words_dict, user_last_item_created_time_dict = get_user_hist_item_info_dict(all_click_df_)\n",
    "click_article_ids_set = get_click_article_ids_set(all_click_df)\n",
    "# 这里使用了很多规则来筛选冷启动的文章，所以前面再召回的阶段就应该尽可能的多召回一些文章，否则很容易被删掉\n",
    "cold_start_user_items_dict = cold_start_items(user_recall_items_dict, user_hist_item_typs_dict, user_hist_item_words_dict, \n",
    "                                              user_last_item_created_time_dict, item_type_dict, item_words_dict, \n",
    "                                              item_created_time_dict, click_article_ids_set, recall_item_num)\n",
    "\n",
    "user_multi_recall_dict_info['cold_start_recall'] = cold_start_user_items_dict \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef2cc46",
   "metadata": {},
   "source": [
    "# C5.多路召回合并！——这里主要是ItemCF召回\n",
    " - user部分总是炸球。。。蛋疼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f97947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_recall_results(user_multi_recall_dict, weight_dict=None, topk=25):\n",
    "    final_recall_items_dict = {}\n",
    "    # 对每一种召回结果按照用户进行归一化，方便后面多种召回结果，相同用户的物品之间权重相加\n",
    "    def norm_user_recall_items_sim(sorted_item_list):\n",
    "        # 如果冷启动中没有文章或者只有一篇文章，直接返回，出现这种情况的原因可能是冷启动召回的文章数量太少了，\n",
    "        # 基于规则筛选之后就没有文章了, 这里还可以做一些其他的策略性的筛选\n",
    "        if len(sorted_item_list) < 2:\n",
    "            return sorted_item_list\n",
    "        min_sim = sorted_item_list[-1][1]\n",
    "        max_sim = sorted_item_list[0][1]\n",
    "        norm_sorted_item_list = []\n",
    "        for item, score in sorted_item_list:\n",
    "            if max_sim > 0:\n",
    "                norm_score = 1.0 * (score - min_sim) / (max_sim - min_sim) if max_sim > min_sim else 1.0\n",
    "            else:\n",
    "                norm_score = 0.0\n",
    "            norm_sorted_item_list.append((item, norm_score))\n",
    "        return norm_sorted_item_list\n",
    "    print('多路召回合并...')\n",
    "    for method, user_recall_items in tqdm(user_multi_recall_dict.items()):\n",
    "        print(method + '...')\n",
    "        # 在计算最终召回结果的时候，也可以为每一种召回结果设置一个权重\n",
    "        try:\n",
    "            if weight_dict == None:\n",
    "                recall_method_weight = 1\n",
    "            else:\n",
    "                recall_method_weight = weight_dict[method]\n",
    "            for user_id, sorted_item_list in user_recall_items.items(): # 进行归一化\n",
    "                user_recall_items[user_id] = norm_user_recall_items_sim(sorted_item_list)\n",
    "            for user_id, sorted_item_list in user_recall_items.items():\n",
    "                # print('user_id')\n",
    "                final_recall_items_dict.setdefault(user_id, {})\n",
    "                for item, score in sorted_item_list:\n",
    "                    final_recall_items_dict[user_id].setdefault(item, 0)\n",
    "                    final_recall_items_dict[user_id][item] += recall_method_weight * score  \n",
    "        except:\n",
    "            continue\n",
    "    final_recall_items_dict_rank = {}\n",
    "    # 多路召回时也可以控制最终的召回数量\n",
    "    for user, recall_item_dict in final_recall_items_dict.items():\n",
    "        final_recall_items_dict_rank[user] = sorted(recall_item_dict.items(), key=lambda x: x[1], reverse=True)[:topk]\n",
    "    # 将多路召回后的最终结果字典保存到本地指定路径final_recall_items_dict.pkl\n",
    "    pickle.dump(final_recall_items_dict, open(os.path.join(save_path, 'final_recall_items_dict.pkl'),'wb'))\n",
    "    return final_recall_items_dict_rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df9ffe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多路召回合并...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itemcf_sim_item_recall...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:18<00:00,  6.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding_sim_item_recall...\n",
      "cold_start_recall...\n"
     ]
    }
   ],
   "source": [
    "# 这里直接对多路召回的权重给了一个相同的值，其实可以根据前面召回的情况来调整参数的值；电商往往更偏爱于用ItemCF，所以权重加大一些；\n",
    "# 保存到本地final_recall_items_dict.pkl\n",
    "# weight_dict = {'itemcf_sim_item_recall': 3.0 ,'usercf_sim_item_recall': 0.5}   \n",
    "#防止炸球,先只使用itemCF召回 \n",
    "weight_dict = {'itemcf_sim_item_recall': 3.0}   \n",
    "# weight_dict = {'itemcf_sim_itemcf_recall': 2.0,'embedding_sim_item_recall': 1.0,'cold_start_recall': 1.0}    \n",
    "# 最终合并之后每个用户召回20个商品进行排序\n",
    "final_recall_items_dict_rank = combine_recall_results(user_multi_recall_dict_info, weight_dict, topk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e1225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027654b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d62d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51cc469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4505c9df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c727f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335a439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
