{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d77a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False #中文\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x) #避免显示问题，设置不显示科学计数法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfeb271",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0839051",
   "metadata": {},
   "source": [
    "- 目录：\n",
    "- 序章：文件相关路径定义&读取源自特征工程后的结果：\n",
    ">  trn_user_item_feats_df——训练用 + tst_user_item_feats_df——测试用；\n",
    "- 预备流程：\n",
    "> 1. 将排序结果处理成规定格式的函数；submit_sequence_result()；\n",
    "——即将user_id,article_id,score返回成user_id,article_id12345的格式；\n",
    "> 2. 将得分score标准化的函数；norm_sim()；\n",
    "——即将ranker的score归一化到0-1区间，以便和classifier预测得到的proba可以融合；\n",
    "- C1.LightGBM-Ranker做排序：——关键环节；\n",
    "> 1. P1.数据准备：——拷一份儿保险；特征列要先制定好，不包含user_id,article_id；\n",
    ">> 1. trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()；\n",
    ">> 2. tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()；\n",
    "> 2. P2.排序模型分组流程：\n",
    ">> 1. trn_user_item_feats_df_rank_model：按照用户排序；其实是针对每一个用户的点击数据信息分组，组内就只包含该用户的几条数据信息；\n",
    ">> 2.group_train每个用户有几条数据变成np.array——其实就是count(label)也就是数据条数；此参数，lgb_ranker里面要用一般都叫做g_train,g_val,g_test；这里为了强化记忆先这么写；\n",
    "> 3. P3. 定义排序器lgb_ranker；\n",
    "> 4. P4. 模型训练；\n",
    ">> 1. 再解释一下ranker里面,fit时参数group的含义：就是该场景下因为是对每一个用户最后点击的一个物品进行预测，基础单位是用户，所以这个时候，每一个用户可以视为一个组；\n",
    "> 5. P5.对测试集tst_user_item_feats_df_rank_model相关部分进行预测得分；\n",
    "> 6. P6.将这里Ranker排序结果保存于本地； 在原始数据集tst_user_item_feats_df上增加predict_score字段；保存到指定路径；lgb_ranker_score.csv——后续模型融合会用；\n",
    "> 7. P7.预测结果按照pred_score重新排序, 调用之前的submit_sequence_result()函数；生成模型标准推荐排序结果保留到本地相应路径；也可以将此结果命名为rank_results_seq_uncross，经过排序处理函数处理成要求格式，保存到本地指定：lgb_ranker_未交叉验证_日期.csv，可以参考结果；\n",
    "> 8. P8.交叉验证看分数；——关键步骤：\n",
    ">> 1. 将用户分为k_fold个样本群体，一份单独用来做验证集，另外k_fold-1份用来做训练；\n",
    ">> 2. 建立模型后，每一轮的训练都会将其中当成验证集的那一部分——这里是按用户分组，所以就是对应用户的点击行为数据，模型根据这一部分会预测出这一部分用户对于每个文章物品的点击分数，排名；\n",
    ">> 3. 最终所有的训练集用户相关都会得到自己的'user_id', 'click_article_id', 'pred_score', 'pred_rank'DF信息，拼接到一起，最终就是训练集+pred_score,rank；将[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']]信息保存到本地指定路径：trn_lgb_ranker_feats_result.csv；后续模型融合要使用；\n",
    ">> 4. 与此同时，交叉验证过程中，每一轮都会模型再预测一下测试及对应数据的分数，最终所有次训练取平均值，最终得到一个测试集上pred_score，\n",
    "保存到本地指定路径：tst_lgb_ranker_feats_result.csv，后续模型融合要使用；相比于上面得到的结果只少了一列label（废话。。。）；\n",
    "> 9. P9.交叉验证后推荐排序结果也可以生成一份文件；保存到指定路径：lgb_ranker_交叉验证后_日期.csv\n",
    "- C2.LightGBM-Classsifier做分类；从预测最终发生点击的概率大小角度来进行一个所谓的排序；\n",
    "> 1. P1.定义一个LGBM分类器；\n",
    "> 2. P2.训练模型；trn_user_item_feats_df_rank_model；\n",
    "> 3. P3.分类器预测结果：对测试集tst_user_item_feats_df_rank_model相关部分进行预测得分；\n",
    "> 4. P4.将分类0-1概率结果保存到本地指定路径；分别取属于正样本1类的概率；\n",
    "> 5. P5.交叉验证使用！思路过程同上面的Ranker环节；\n",
    "本地生成训练集结果：trn_lgb_classifier_feats_result.csv\n",
    "本地生成测试集结果：tst_lgb_classifier_feats_result.csv\n",
    "> 6. P6.交叉验证后推荐排序结果也可以生成一份文件；保存到指定路径：lgb_classifier_交叉验证后_日期.csv\n",
    "- C3. 建设一个DNN神经网络试试；\n",
    "> 1. P1.从训练集中拿出一部分作为验证用；\n",
    "> 2. P2.建立DNN网络；\n",
    ">> \n",
    "### S1.输入层和中间层；\n",
    "- C4.模型融合；\n",
    "> 1. P1.读取多个模型的排序结果文件；\n",
    "> 2. P2.融合模型；\n",
    "> 3. P3.神经网络特征标准化；\n",
    "> 4. P4.重新定义一个DNN；生成新的预测结果保存到本地；\n",
    "- C5.模型得分叠加处理；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb7081",
   "metadata": {},
   "source": [
    "# 序章.文件相关路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6252ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_path/'            # 其实无用\n",
    "save_path = './feature_project_path/' # 源于上次特征工程结果\n",
    "save_dir = './sequence_result_path/'    # 最终排序结果存放位置\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c8974",
   "metadata": {},
   "source": [
    "# 序章.读取特征工程后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d39978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df_final_sample.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df_final_sample.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be61b55",
   "metadata": {},
   "source": [
    "# 预备工具I.定义排序结果的函数：\n",
    "- 后面交叉验证用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4bf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回排序结果处理函数\n",
    "def submit_sequence_result(recall_df, filename, topk=5, model_name=None):\n",
    "    '''\n",
    "    recall_df:已经取出来的user_id,article_id,pred_score数据表df格式；\n",
    "    filename：指定文件叫啥名，比如，未验证的排序，验证好的排序等；\n",
    "    topk；得分前几名；\n",
    "    model_name：用那个模型跑的；\n",
    "    '''\n",
    "    # 按照user_id,score排好序；\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    # 按照score值生成排序字段rank的值；\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 判断是不是每个用户都有5篇文章及以上，就是看每个用户下，rank值最大是多少；\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    # 保证判断结果为True的时候正常执行；\n",
    "    assert tmp.min() >= topk\n",
    "    # 分数拿掉；\n",
    "    del recall_df['pred_score']\n",
    "    # 把每个用户前五名的文章物品id拿出来设置用户id和rank排序值为联合索引；\n",
    "    # 再使用unstack(-1)将rank排序rank转换成列，reset_index()，恢复索引\n",
    "    submit_df = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    # 取消联合索引user_id、click_article_id、pred_score，MultiIndex形式，改为只留下1，2，3，4，5排序的信息\n",
    "    submit_df.columns = [int(col) if isinstance(col, int) else col for col in submit_df.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit_df = submit_df.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', 3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    save_name = save_dir + model_name + '_' + filename + '_'+ datetime.today().strftime('%Y-%m-%d') + '.csv'\n",
    "    submit_df.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1e177",
   "metadata": {},
   "source": [
    "# 预备工具II.排序结果分数归一化函数\n",
    "- 后面模型融合时要用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba4fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序结果分数归一化函数\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    # print(sim_df.head())\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a8263",
   "metadata": {},
   "source": [
    "# C1.LightGBM-Ranker做排序！\n",
    "- 1.得到根据召回分数，模型训练预测出的分数score进行排序；\n",
    "- 2.根据分数最终对测试集返回对应的排序结果；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2106a",
   "metadata": {},
   "source": [
    "## P1.数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c03898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制一份训练测试的数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy() \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bc92239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要用到的特征列；\n",
    "lgb_ranker_need_cols = ['sim0', 'time_diff0', 'word_diff0',\n",
    "       'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'sim_median', 'score',\n",
    "       'rank', 'click_size', 'time_diff_mean', 'active_level_parameter',\n",
    "       'click_environment', 'click_deviceGroup', 'click_os', 'click_country',\n",
    "       'click_region', 'click_referrer_type', 'click_weekday', 'click_hour',\n",
    "       'article_crt_weekday', 'article_crt_hour', 'words_hbo', 'category_id',\n",
    "       'words_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03dd66",
   "metadata": {},
   "source": [
    "## P2.排序模型分组流程：\n",
    "- 1.trn_user_item_feats_df_rank_model：按照用户排序；\n",
    "- 2.group_train每个用户有几条数据变成np.array——其实就是count(label)也就是数据条数；此参数，lgb_ranker里面要用\n",
    "- 一般都叫做g_train,g_val,g_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfccf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "group_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f74c8408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>sim_median</th>\n",
       "      <th>...</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>click_weekday</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>article_crt_weekday</th>\n",
       "      <th>article_crt_hour</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>157507</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>51854000</td>\n",
       "      <td>208</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>266.000</td>\n",
       "      <td>281</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>112945</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>57924456000</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>266.000</td>\n",
       "      <td>237</td>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>166297</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>5226913000</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>266.000</td>\n",
       "      <td>289</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>79851</td>\n",
       "      <td>0.225</td>\n",
       "      <td>15121000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>169.000</td>\n",
       "      <td>173</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>63746</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>37324000</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>169.000</td>\n",
       "      <td>133</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304851</th>\n",
       "      <td>199998</td>\n",
       "      <td>236635</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>4515451000</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>189.475</td>\n",
       "      <td>375</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206196</th>\n",
       "      <td>199998</td>\n",
       "      <td>86386</td>\n",
       "      <td>0.044</td>\n",
       "      <td>51372656000</td>\n",
       "      <td>45</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.044</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>189.475</td>\n",
       "      <td>186</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135885</th>\n",
       "      <td>199998</td>\n",
       "      <td>236648</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>31230000</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>189.475</td>\n",
       "      <td>375</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104234</th>\n",
       "      <td>199999</td>\n",
       "      <td>218355</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>259000</td>\n",
       "      <td>111</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>200.273</td>\n",
       "      <td>352</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334116</th>\n",
       "      <td>199999</td>\n",
       "      <td>168798</td>\n",
       "      <td>0.374</td>\n",
       "      <td>1469734000</td>\n",
       "      <td>198</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.374</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>200.273</td>\n",
       "      <td>297</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>429623 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id   sim0   time_diff0  word_diff0  sim_max  \\\n",
       "0             0            157507 -0.104     51854000         208   -0.104   \n",
       "16            0            112945 -0.005  57924456000          23   -0.005   \n",
       "14            0            166297 -0.027   5226913000          49   -0.027   \n",
       "33            1             79851  0.225     15121000           7    0.225   \n",
       "19            1             63746 -0.099     37324000          14   -0.099   \n",
       "...         ...               ...    ...          ...         ...      ...   \n",
       "304851   199998            236635 -0.026   4515451000          15   -0.026   \n",
       "206196   199998             86386  0.044  51372656000          45    0.044   \n",
       "135885   199998            236648 -0.058     31230000          11   -0.058   \n",
       "104234   199999            218355 -0.020       259000         111   -0.020   \n",
       "334116   199999            168798  0.374   1469734000         198    0.374   \n",
       "\n",
       "        sim_min  sim_sum  sim_mean  sim_median  ...  click_referrer_type  \\\n",
       "0        -0.104   -0.104    -0.104      -0.104  ...                    2   \n",
       "16       -0.005   -0.005    -0.005      -0.005  ...                    2   \n",
       "14       -0.027   -0.027    -0.027      -0.027  ...                    2   \n",
       "33        0.225    0.225     0.225       0.225  ...                    6   \n",
       "19       -0.099   -0.099    -0.099      -0.099  ...                    6   \n",
       "...         ...      ...       ...         ...  ...                  ...   \n",
       "304851   -0.026   -0.026    -0.026      -0.026  ...                    5   \n",
       "206196    0.044    0.044     0.044       0.044  ...                    5   \n",
       "135885   -0.058   -0.058    -0.058      -0.058  ...                    5   \n",
       "104234   -0.020   -0.020    -0.020      -0.020  ...                    1   \n",
       "334116    0.374    0.374     0.374       0.374  ...                    1   \n",
       "\n",
       "        click_weekday  click_hour  article_crt_weekday  article_crt_hour  \\\n",
       "0                   2           3                    2                10   \n",
       "16                  2           3                    2                10   \n",
       "14                  2           3                    2                10   \n",
       "33                  2           3                    1                 8   \n",
       "19                  2           3                    1                 8   \n",
       "...               ...         ...                  ...               ...   \n",
       "304851              2          10                    1                 5   \n",
       "206196              2          10                    1                 5   \n",
       "135885              2          10                    1                 5   \n",
       "104234              2          11                    2                 6   \n",
       "334116              2          11                    2                 6   \n",
       "\n",
       "        words_hbo  category_id  words_count  is_cat_hab  label  \n",
       "0         266.000          281          370           1  1.000  \n",
       "16        266.000          237          185           0  0.000  \n",
       "14        266.000          289          211           0  0.000  \n",
       "33        169.000          173          183           0  0.000  \n",
       "19        169.000          133          162           1  1.000  \n",
       "...           ...          ...          ...         ...    ...  \n",
       "304851    189.475          375          158           1  0.000  \n",
       "206196    189.475          186          128           0  0.000  \n",
       "135885    189.475          375          184           1  1.000  \n",
       "104234    200.273          352          202           1  1.000  \n",
       "334116    200.273          297          289           1  0.000  \n",
       "\n",
       "[429623 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "trn_user_item_feats_df_rank_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a52e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 2, ..., 3, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e70f3",
   "metadata": {},
   "source": [
    "## P3.定义LGBM排序器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c080f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1, max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=0, n_jobs= -1) \n",
    "# min_child_weight代表的意思是，儅一個節點下的樣本數小於給定的閾值时，停止生长，会被剪枝；太高会欠拟合，太低容易过拟合；\n",
    "# 这个值定的高，则每个叶子节点越容易被剪枝掉，过高就产生欠拟合状态；过低，好多叶子结点就不会被剪掉，叶子生长过多，容易过拟合；\n",
    "# 树的生长，越浅，叶子包含样本越不纯，被剪枝得厉害，越欠拟合；越深，叶子包含样本越纯，剪枝少，容易过拟合；\n",
    "# colsample_bytree：构建每一弱评估器的子采样比例；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd97a75",
   "metadata": {},
   "source": [
    "## P4.初次训练\n",
    "- 实例化保存结果；lgb_ranker_re\n",
    "- 解释一下参数group的含义：\n",
    "> 1. 就是该场景下因为是对每一个用户最后点击的一个物品进行预测，基础单位是用户，所以这个时候，每一个用户可以视为一个组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31a6dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分测试集和训练集\n",
    "X_train = trn_user_item_feats_df_rank_model[lgb_ranker_need_cols]\n",
    "y_train = trn_user_item_feats_df_rank_model['label']\n",
    "X_test  = tst_user_item_feats_df_rank_model[lgb_ranker_need_cols]# 不推荐这么写，后面你就知道了；还得往回重新粘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "888b8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ranker_re = lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_ranker_need_cols], trn_user_item_feats_df_rank_model['label'], group=group_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02aff26",
   "metadata": {},
   "source": [
    "## P5.模型预测得分；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be798da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测，\n",
    "# X_test['pred_score'] = lgb_ranker_re.predict(X_test, num_iteration=lgb_ranker_re.best_iteration_) # 省得还得重新网上拼接\n",
    "# 这个pred_score字段名不要瞎改！\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker_re.predict(tst_user_item_feats_df[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "531003cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>sim_median</th>\n",
       "      <th>...</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>click_weekday</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>article_crt_weekday</th>\n",
       "      <th>article_crt_hour</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>194197</td>\n",
       "      <td>0.850</td>\n",
       "      <td>579686000</td>\n",
       "      <td>70</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>200.333</td>\n",
       "      <td>317</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200642</td>\n",
       "      <td>194197</td>\n",
       "      <td>0.861</td>\n",
       "      <td>45076000</td>\n",
       "      <td>95</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>177.000</td>\n",
       "      <td>317</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>201816</td>\n",
       "      <td>194197</td>\n",
       "      <td>0.765</td>\n",
       "      <td>88406000</td>\n",
       "      <td>19</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.765</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>291.000</td>\n",
       "      <td>317</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203147</td>\n",
       "      <td>194197</td>\n",
       "      <td>0.748</td>\n",
       "      <td>99580000</td>\n",
       "      <td>70</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>194.000</td>\n",
       "      <td>317</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203448</td>\n",
       "      <td>194197</td>\n",
       "      <td>0.861</td>\n",
       "      <td>45076000</td>\n",
       "      <td>95</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.861</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>177.000</td>\n",
       "      <td>317</td>\n",
       "      <td>272</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499995</th>\n",
       "      <td>249960</td>\n",
       "      <td>206546</td>\n",
       "      <td>0.460</td>\n",
       "      <td>12096973000</td>\n",
       "      <td>22</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.460</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>222.909</td>\n",
       "      <td>331</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499996</th>\n",
       "      <td>249961</td>\n",
       "      <td>326992</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>1094791000</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201.333</td>\n",
       "      <td>435</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499997</th>\n",
       "      <td>249961</td>\n",
       "      <td>327401</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>1441887000</td>\n",
       "      <td>29</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>-0.274</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>201.333</td>\n",
       "      <td>435</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499998</th>\n",
       "      <td>249978</td>\n",
       "      <td>94912</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>24554361000</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>223.000</td>\n",
       "      <td>209</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499999</th>\n",
       "      <td>249983</td>\n",
       "      <td>276783</td>\n",
       "      <td>0.885</td>\n",
       "      <td>132641000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.885</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>184.500</td>\n",
       "      <td>409</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  click_article_id   sim0   time_diff0  word_diff0  sim_max  \\\n",
       "0         200000            194197  0.850    579686000          70    0.850   \n",
       "1         200642            194197  0.861     45076000          95    0.861   \n",
       "2         201816            194197  0.765     88406000          19    0.765   \n",
       "3         203147            194197  0.748     99580000          70    0.748   \n",
       "4         203448            194197  0.861     45076000          95    0.861   \n",
       "...          ...               ...    ...          ...         ...      ...   \n",
       "1499995   249960            206546  0.460  12096973000          22    0.460   \n",
       "1499996   249961            326992 -0.199   1094791000          14   -0.199   \n",
       "1499997   249961            327401 -0.274   1441887000          29   -0.274   \n",
       "1499998   249978             94912 -0.352  24554361000          24   -0.352   \n",
       "1499999   249983            276783  0.885    132641000          15    0.885   \n",
       "\n",
       "         sim_min  sim_sum  sim_mean  sim_median  ...  click_referrer_type  \\\n",
       "0          0.850    0.850     0.850       0.850  ...                    1   \n",
       "1          0.861    0.861     0.861       0.861  ...                    1   \n",
       "2          0.765    0.765     0.765       0.765  ...                    1   \n",
       "3          0.748    0.748     0.748       0.748  ...                    1   \n",
       "4          0.861    0.861     0.861       0.861  ...                    1   \n",
       "...          ...      ...       ...         ...  ...                  ...   \n",
       "1499995    0.460    0.460     0.460       0.460  ...                    1   \n",
       "1499996   -0.199   -0.199    -0.199      -0.199  ...                    1   \n",
       "1499997   -0.274   -0.274    -0.274      -0.274  ...                    1   \n",
       "1499998   -0.352   -0.352    -0.352      -0.352  ...                    1   \n",
       "1499999    0.885    0.885     0.885       0.885  ...                    1   \n",
       "\n",
       "         click_weekday  click_hour  article_crt_weekday  article_crt_hour  \\\n",
       "0                    2          11                    2                 6   \n",
       "1                    2          11                    2                 6   \n",
       "2                    2          10                    1                18   \n",
       "3                    2           9                    1                15   \n",
       "4                    2           9                    2                 6   \n",
       "...                ...         ...                  ...               ...   \n",
       "1499995              2          12                    2                 8   \n",
       "1499996              1          15                    1                12   \n",
       "1499997              1          15                    1                12   \n",
       "1499998              1          15                    1                 2   \n",
       "1499999              1          15                    4                11   \n",
       "\n",
       "         words_hbo  category_id  words_count  is_cat_hab  pred_score  \n",
       "0          200.333          317          272           1       0.950  \n",
       "1          177.000          317          272           1      -1.796  \n",
       "2          291.000          317          272           1      -1.808  \n",
       "3          194.000          317          272           1      -1.808  \n",
       "4          177.000          317          272           1      -1.796  \n",
       "...            ...          ...          ...         ...         ...  \n",
       "1499995    222.909          331          238           1      -1.869  \n",
       "1499996    201.333          435          148           1      -1.912  \n",
       "1499997    201.333          435          191           1      -1.893  \n",
       "1499998    223.000          209          194           0       0.866  \n",
       "1499999    184.500          409          156           1      -1.817  \n",
       "\n",
       "[1500000 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_user_item_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66d50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_user_item_feats_df[tst_user_item_feats_df[\"user_id\"]==200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374df965",
   "metadata": {},
   "source": [
    "## P6.将这里Ranker排序结果保存于本地；——后续模型融合要用到；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90d3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_dir + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4935ba",
   "metadata": {},
   "source": [
    "## P7.预测结果按照pred_score重新排序, 调用之前的submit 函数；生成模型标准排序结果保留到本地相应路径；\n",
    "- 1.模型预测出的结果pred_score和user,article_id,pred_score取出单独拿出来；\n",
    "- 2.文章id字段需要转换成整数型；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7a76814",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results_seq_uncross = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_seq_uncross['click_article_id'] = rank_results_seq_uncross['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_seq_uncross,'未交叉验证', topk=5, model_name='lgb_ranker') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c66e7f",
   "metadata": {},
   "source": [
    "## P8.使用交叉验证看分数；——关键步骤；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1dd1d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.032365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3704\n",
      "[LightGBM] [Info] Number of data points in the train set: 358044, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3703\n",
      "[LightGBM] [Info] Number of data points in the train set: 358068, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040302 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3703\n",
      "[LightGBM] [Info] Number of data points in the train set: 357949, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3707\n",
      "[LightGBM] [Info] Number of data points in the train set: 358013, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3699\n",
      "[LightGBM] [Info] Number of data points in the train set: 358076, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033993 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3701\n",
      "[LightGBM] [Info] Number of data points in the train set: 357965, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    }
   ],
   "source": [
    "# 原版五折交叉验证，这里的六折交叉是以用户为目标进行六折划分\n",
    "# 这一部分与前面的单独训练和验证是分开的\n",
    "# 交叉验证次数6；k_fold\n",
    "k_fold = 6\n",
    "# 一份训练用的数据copy一下；trn_df\n",
    "trn_df_ranker = trn_user_item_feats_df_rank_model\n",
    "# 把训练集用户单独拿出来；user_ids\n",
    "user_ids_ranker = trn_df_ranker['user_id'].unique()\n",
    "# 定义用户训练分组函数，思想就是每隔n个取一个，[0,6,12......]，[1,7,13......]\n",
    "def get_kfold_users(trn_df_ranker, n = 6):\n",
    "    user_ids_ranker = trn_df_ranker['user_id'].unique()\n",
    "    user_set_ranker = [user_ids_ranker[i::n] for i in range(n)]\n",
    "    return user_set_ranker\n",
    "# 使用分组函数得到几组用户；\n",
    "user_set_ranker = get_kfold_users(trn_df_ranker, n=k_fold)\n",
    "# 生成空列表，为了储存训练集的交叉验证分数、排序结果；\n",
    "score_list_ranker = []\n",
    "# 目标三列拿来，所有user_id,click_article_id,label\n",
    "score_df_ranker = trn_df_ranker[['user_id', 'click_article_id','label']]\n",
    "# 最终测试集分数准备，先都默认用np.zeros打0；sub_preds_points_ranker\n",
    "sub_preds_points_ranker = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "# n折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set_ranker):\n",
    "    '''\n",
    "    n_fold：交叉验证划分用户组的组序号；\n",
    "    valid_user：每组的用户列表array；\n",
    "    '''\n",
    "    # 遍历该组用户时，该组用户的相关数据信息作为测试集用来验证分数，剩下的都是训练集；再啰嗦一遍；\n",
    "    train_idx = trn_df_ranker[~trn_df_ranker['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df_ranker[trn_df_ranker['user_id'].isin(valid_user)]\n",
    "    # 训练集与验证集的用户分组排序：\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    # 验证集：\n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    # 定义模型，简单设置一下框架先；\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,max_depth=-1, n_estimators=163, \n",
    "                                subsample=0.8, colsample_bytree=0.7, subsample_freq=1,learning_rate=0.01, min_child_weight=50, \n",
    "                                random_state=0, n_jobs= -1, silent = False) \n",
    "    # 训练模型\n",
    "    lgb_ranker_re = lgb_ranker.fit(train_idx[lgb_ranker_need_cols], train_idx['label'], group=g_train,\n",
    "                                   eval_set=[(valid_idx[lgb_ranker_need_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50)\n",
    "    # 对验证集预测结果\n",
    "    # 留一行注释警示作用——为什么pred_score不要重新命名了；\n",
    "    # valid_idx['pred_score_ranker'] = lgb_ranker_re.predict(valid_idx[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)\n",
    "    valid_idx['pred_score'] = lgb_ranker_re.predict(valid_idx[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)\n",
    "    # num_iteration参数：如果在训练期间启用了早期停止，可以通过best_iteration方式从最佳迭代中获得预测\n",
    "    # 对验证集按照用户，分数排序，并生成排序结果字段rank；\n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接叠加；每一次得到的都是用户平均分组的群体信息\n",
    "    score_list_ranker.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    # 验证集的分数每一条数据，就是user_id-article_id-label-得到一个predict_score，一共k_fold轮，每一轮进行自叠加运算\n",
    "    # k_fold轮以后添加到sub_preds_points：\n",
    "    # 实际记录的是所有k_fold轮交叉验证以后,验证集中每一条就是每一个用户对于一个文章物品的分数（类似于概率），\n",
    "    # 所有轮加起来，最终就是所有训练集所包含的所有每个用户user_id,article_id的pred_score,pred_rank信息；\n",
    "    if not offline:\n",
    "        sub_preds_points_ranker += lgb_ranker_re.predict(tst_user_item_feats_df_rank_model[lgb_ranker_need_cols], lgb_ranker_re.best_iteration_)\n",
    "# k_fold次划分的用户，这回都有了得分信息，把所有的纵向叠加起来合并形成score_df；\n",
    "score_df_ranker_ = pd.concat(score_list_ranker, axis=0)\n",
    "score_df_ranker = score_df_ranker.merge(score_df_ranker_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新信息——pred_score，pred_rank保存，后续会有用\n",
    "# 将交叉验证对于训练集的结果保存下来；——后续模型融合要用；\n",
    "score_df_ranker[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_dir + 'trn_lgb_ranker_feats_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c3878",
   "metadata": {},
   "source": [
    "## P9.测试集，基于先前交叉验证的多次结果进行平均化；本保存到本地一份结果；\n",
    "- 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于模型融合后面的操作。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "284563a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刚才交叉验证环节中，对于最终测试集预测的分数取平均值；为什么要取平均值？——废话再说一遍，泛化验证的思想；\n",
    "# 再按照user_id,分数排序；再按照分数高低，生成排序字段pred_rank；\n",
    "# 测试集由于数据要提交，保持和前面submit_sequence_result函数要求的字段一致；\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds_points_ranker/k_fold\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_dir + 'tst_lgb_ranker_feats_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f65727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "# 与P7提交的结果相比有差别！\n",
    "rank_results_seq_crossed = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_seq_crossed['click_article_id'] = rank_results_seq_crossed['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_seq_crossed,'交叉验证后', topk=5, model_name='lgb_ranker') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31301dd3",
   "metadata": {},
   "source": [
    "# C2.LightGBM-Classsifier做分类！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb102fa",
   "metadata": {},
   "source": [
    "## P1.定义一个LGBM分类器；\n",
    "- 1.得到根据召回分数等特征，模型训练预测出的概率proba进行排序；\n",
    "- 2.根据概率大小最终对测试集返回对应的排序结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7680d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义，随便定义一个\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=63, random_state=0, n_jobs= -1, verbose=10, silent=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46057f",
   "metadata": {},
   "source": [
    "## P2.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1b47b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 200000, number of negative: 229623\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058332\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000013 seconds, init for row-wise cost 0.031152 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3706\n",
      "[LightGBM] [Info] Number of data points in the train set: 429623, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465524 -> initscore=-0.138121\n",
      "[LightGBM] [Info] Start training from score -0.138121\n",
      "[LightGBM] [Debug] Re-bagging, using 343854 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343358 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 343827 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343565 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343654 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 343807 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343749 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343678 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343581 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343845 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 343644 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343608 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343506 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343530 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343323 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343496 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343850 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 343704 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343692 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344036 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343572 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343936 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 344023 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343978 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343415 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343430 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343881 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343521 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343325 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344075 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343317 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343856 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343904 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343791 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343550 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343668 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343482 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343627 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343517 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343877 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343602 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344094 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343638 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343814 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344017 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 343492 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 343906 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343773 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343710 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 344087 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343706 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343680 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343648 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 343755 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343558 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343993 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343646 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343845 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343784 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 342978 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343983 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343787 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343916 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343541 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 343566 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343600 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343610 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344000 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343911 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 342877 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344222 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343709 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343657 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343768 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343999 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343847 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343673 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 343780 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343048 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343509 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 343471 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343888 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343593 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343643 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343883 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343759 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343889 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 344058 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343794 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 343876 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343955 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343903 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343984 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343700 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343844 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343859 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343322 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344113 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343625 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 343607 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343686 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343287 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343759 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343990 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343416 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343969 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343749 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343870 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343991 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344133 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343768 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344040 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343498 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 343483 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343780 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343818 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343471 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343714 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 343787 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343470 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343607 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343512 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343538 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343400 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343500 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343820 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343571 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343669 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343656 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343530 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343038 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343848 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343765 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343611 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343787 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 343912 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 343699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344122 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 344083 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
      "[LightGBM] [Debug] Re-bagging, using 343705 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343845 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 343175 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343960 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343849 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 343852 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n"
     ]
    }
   ],
   "source": [
    "lgb_Classfication_re = lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_ranker_need_cols], trn_user_item_feats_df_rank_model['label']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dea825",
   "metadata": {},
   "source": [
    "## P3.分类器预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc8552c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测，返回概率；\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication_re.predict_proba(tst_user_item_feats_df[lgb_ranker_need_cols])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a9c91",
   "metadata": {},
   "source": [
    "## P4.将分类0-1概率结果保存到本地指定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32fd518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这里的按照分类概率结果结果保存一份\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_dir + 'lgb_classfier_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73cd5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果；\n",
    "rank_results_classifier_uncross = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_classifier_uncross['click_article_id'] = rank_results_classifier_uncross['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_classifier_uncross,'未交叉验证', topk=5, model_name='lgb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a57c",
   "metadata": {},
   "source": [
    "## P5.交叉验证仍然！同时处理测试集的交叉验证分数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6781fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 166666, number of negative: 191378\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058323\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000011 seconds, init for row-wise cost 0.029278 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3706\n",
      "[LightGBM] [Info] Number of data points in the train set: 358044, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465490 -> initscore=-0.138259\n",
      "[LightGBM] [Info] Start training from score -0.138259\n",
      "[LightGBM] [Debug] Re-bagging, using 286526 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.680841\n",
      "[LightGBM] [Debug] Re-bagging, using 286073 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678899\n",
      "[LightGBM] [Debug] Re-bagging, using 286552 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669187\n",
      "[LightGBM] [Debug] Re-bagging, using 286259 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659734\n",
      "[LightGBM] [Debug] Re-bagging, using 286613 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659168\n",
      "[LightGBM] [Debug] Re-bagging, using 286487 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.6499\n",
      "[LightGBM] [Debug] Re-bagging, using 286534 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640754\n",
      "[LightGBM] [Debug] Re-bagging, using 286426 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631784\n",
      "[LightGBM] [Debug] Re-bagging, using 286370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622984\n",
      "[LightGBM] [Debug] Re-bagging, using 286508 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614404\n",
      "[LightGBM] [Debug] Re-bagging, using 286489 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605984\n",
      "[LightGBM] [Debug] Re-bagging, using 286560 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.597719\n",
      "[LightGBM] [Debug] Re-bagging, using 286209 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589552\n",
      "[LightGBM] [Debug] Re-bagging, using 286276 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.581586\n",
      "[LightGBM] [Debug] Re-bagging, using 286069 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.57371\n",
      "[LightGBM] [Debug] Re-bagging, using 286161 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.565975\n",
      "[LightGBM] [Debug] Re-bagging, using 286474 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564572\n",
      "[LightGBM] [Debug] Re-bagging, using 286391 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556999\n",
      "[LightGBM] [Debug] Re-bagging, using 285880 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549559\n",
      "[LightGBM] [Debug] Re-bagging, using 286405 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.54225\n",
      "[LightGBM] [Debug] Re-bagging, using 286449 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.535066\n",
      "[LightGBM] [Debug] Re-bagging, using 286562 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.528006\n",
      "[LightGBM] [Debug] Re-bagging, using 286333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.521066\n",
      "[LightGBM] [Debug] Re-bagging, using 286652 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.514243\n",
      "[LightGBM] [Debug] Re-bagging, using 286534 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.507589\n",
      "[LightGBM] [Debug] Re-bagging, using 286797 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500992\n",
      "[LightGBM] [Debug] Re-bagging, using 286613 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.494505\n",
      "[LightGBM] [Debug] Re-bagging, using 286343 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.488124\n",
      "[LightGBM] [Debug] Re-bagging, using 286279 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481896\n",
      "[LightGBM] [Debug] Re-bagging, using 286184 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475721\n",
      "[LightGBM] [Debug] Re-bagging, using 286381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.469645\n",
      "[LightGBM] [Debug] Re-bagging, using 286543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 286305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457785\n",
      "[LightGBM] [Debug] Re-bagging, using 286457 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 6\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.452037\n",
      "[LightGBM] [Debug] Re-bagging, using 286297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.446382\n",
      "[LightGBM] [Debug] Re-bagging, using 286003 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440772\n",
      "[LightGBM] [Debug] Re-bagging, using 286770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.435293\n",
      "[LightGBM] [Debug] Re-bagging, using 286292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429856\n",
      "[LightGBM] [Debug] Re-bagging, using 286642 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424502\n",
      "[LightGBM] [Debug] Re-bagging, using 286515 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.41923\n",
      "[LightGBM] [Debug] Re-bagging, using 286785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.414038\n",
      "[LightGBM] [Debug] Re-bagging, using 286094 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408925\n",
      "[LightGBM] [Debug] Re-bagging, using 286434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.40389\n",
      "[LightGBM] [Debug] Re-bagging, using 286071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.39893\n",
      "[LightGBM] [Debug] Re-bagging, using 286453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.394081\n",
      "[LightGBM] [Debug] Re-bagging, using 286188 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.389267\n",
      "[LightGBM] [Debug] Re-bagging, using 286629 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384523\n",
      "[LightGBM] [Debug] Re-bagging, using 286439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.37985\n",
      "[LightGBM] [Debug] Re-bagging, using 286849 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.375245\n",
      "[LightGBM] [Debug] Re-bagging, using 286473 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370707\n",
      "[LightGBM] [Debug] Re-bagging, using 286395 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.366235\n",
      "[LightGBM] [Info] Number of positive: 166666, number of negative: 191402\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058339\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000010 seconds, init for row-wise cost 0.022211 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.028081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3703\n",
      "[LightGBM] [Info] Number of data points in the train set: 358068, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465459 -> initscore=-0.138384\n",
      "[LightGBM] [Info] Start training from score -0.138384\n",
      "[LightGBM] [Debug] Re-bagging, using 286545 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.680863\n",
      "[LightGBM] [Debug] Re-bagging, using 286089 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678894\n",
      "[LightGBM] [Debug] Re-bagging, using 286579 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669181\n",
      "[LightGBM] [Debug] Re-bagging, using 286272 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659702\n",
      "[LightGBM] [Debug] Re-bagging, using 286625 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659096\n",
      "[LightGBM] [Debug] Re-bagging, using 286511 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.649809\n",
      "[LightGBM] [Debug] Re-bagging, using 286566 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640665\n",
      "[LightGBM] [Debug] Re-bagging, using 286438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631696\n",
      "[LightGBM] [Debug] Re-bagging, using 286378 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622897\n",
      "[LightGBM] [Debug] Re-bagging, using 286528 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614299\n",
      "[LightGBM] [Debug] Re-bagging, using 286517 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605861\n",
      "[LightGBM] [Debug] Re-bagging, using 286585 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.597578\n",
      "[LightGBM] [Debug] Re-bagging, using 286232 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589413\n",
      "[LightGBM] [Debug] Re-bagging, using 286294 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.58143\n",
      "[LightGBM] [Debug] Re-bagging, using 286065 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.573557\n",
      "[LightGBM] [Debug] Re-bagging, using 286201 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.565825\n",
      "[LightGBM] [Debug] Re-bagging, using 286487 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564406\n",
      "[LightGBM] [Debug] Re-bagging, using 286411 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556836\n",
      "[LightGBM] [Debug] Re-bagging, using 285901 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549399\n",
      "[LightGBM] [Debug] Re-bagging, using 286397 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.542092\n",
      "[LightGBM] [Debug] Re-bagging, using 286489 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.534911\n",
      "[LightGBM] [Debug] Re-bagging, using 286585 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.527853\n",
      "[LightGBM] [Debug] Re-bagging, using 286356 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.520916\n",
      "[LightGBM] [Debug] Re-bagging, using 286670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.514095\n",
      "[LightGBM] [Debug] Re-bagging, using 286540 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.507423\n",
      "[LightGBM] [Debug] Re-bagging, using 286823 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 286634 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.494344\n",
      "[LightGBM] [Debug] Re-bagging, using 286389 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.487966\n",
      "[LightGBM] [Debug] Re-bagging, using 286277 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481723\n",
      "[LightGBM] [Debug] Re-bagging, using 286200 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475551\n",
      "[LightGBM] [Debug] Re-bagging, using 286381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.469478\n",
      "[LightGBM] [Debug] Re-bagging, using 286596 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463503\n",
      "[LightGBM] [Debug] Re-bagging, using 286297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457623\n",
      "[LightGBM] [Debug] Re-bagging, using 286507 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.451866\n",
      "[LightGBM] [Debug] Re-bagging, using 286300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 6\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.446195\n",
      "[LightGBM] [Debug] Re-bagging, using 286006 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440588\n",
      "[LightGBM] [Debug] Re-bagging, using 286798 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.435097\n",
      "[LightGBM] [Debug] Re-bagging, using 286312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429662\n",
      "[LightGBM] [Debug] Re-bagging, using 286650 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424312\n",
      "[LightGBM] [Debug] Re-bagging, using 286547 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.419043\n",
      "[LightGBM] [Debug] Re-bagging, using 286812 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.413854\n",
      "[LightGBM] [Debug] Re-bagging, using 286107 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408744\n",
      "[LightGBM] [Debug] Re-bagging, using 286438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.403711\n",
      "[LightGBM] [Debug] Re-bagging, using 286090 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.398753\n",
      "[LightGBM] [Debug] Re-bagging, using 286491 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 3\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.393896\n",
      "[LightGBM] [Debug] Re-bagging, using 286211 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.389084\n",
      "[LightGBM] [Debug] Re-bagging, using 286629 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384344\n",
      "[LightGBM] [Debug] Re-bagging, using 286477 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.379673\n",
      "[LightGBM] [Debug] Re-bagging, using 286859 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.375071\n",
      "[LightGBM] [Debug] Re-bagging, using 286505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370536\n",
      "[LightGBM] [Debug] Re-bagging, using 286406 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.366066\n",
      "[LightGBM] [Info] Number of positive: 166667, number of negative: 191282\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058358\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000017 seconds, init for row-wise cost 0.028449 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035474 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3703\n",
      "[LightGBM] [Info] Number of data points in the train set: 357949, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465617 -> initscore=-0.137751\n",
      "[LightGBM] [Info] Start training from score -0.137751\n",
      "[LightGBM] [Debug] Re-bagging, using 286447 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.680757\n",
      "[LightGBM] [Debug] Re-bagging, using 285997 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678781\n",
      "[LightGBM] [Debug] Re-bagging, using 286479 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.66907\n",
      "[LightGBM] [Debug] Re-bagging, using 286166 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.6596\n",
      "[LightGBM] [Debug] Re-bagging, using 286548 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.65898\n",
      "[LightGBM] [Debug] Re-bagging, using 286407 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.649703\n",
      "[LightGBM] [Debug] Re-bagging, using 286472 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640561\n",
      "[LightGBM] [Debug] Re-bagging, using 286346 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631594\n",
      "[LightGBM] [Debug] Re-bagging, using 286279 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622797\n",
      "[LightGBM] [Debug] Re-bagging, using 286439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614207\n",
      "[LightGBM] [Debug] Re-bagging, using 286406 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605778\n",
      "[LightGBM] [Debug] Re-bagging, using 286489 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.597505\n",
      "[LightGBM] [Debug] Re-bagging, using 286138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589341\n",
      "[LightGBM] [Debug] Re-bagging, using 286179 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.581366\n",
      "[LightGBM] [Debug] Re-bagging, using 285983 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.573495\n",
      "[LightGBM] [Debug] Re-bagging, using 286111 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.565763\n",
      "[LightGBM] [Debug] Re-bagging, using 286401 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564334\n",
      "[LightGBM] [Debug] Re-bagging, using 286302 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 285809 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549329\n",
      "[LightGBM] [Debug] Re-bagging, using 286349 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.542022\n",
      "[LightGBM] [Debug] Re-bagging, using 286396 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.534842\n",
      "[LightGBM] [Debug] Re-bagging, using 286486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.527785\n",
      "[LightGBM] [Debug] Re-bagging, using 286257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.520849\n",
      "[LightGBM] [Debug] Re-bagging, using 286550 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.51403\n",
      "[LightGBM] [Debug] Re-bagging, using 286458 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.507363\n",
      "[LightGBM] [Debug] Re-bagging, using 286716 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500769\n",
      "[LightGBM] [Debug] Re-bagging, using 286549 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.494285\n",
      "[LightGBM] [Debug] Re-bagging, using 286267 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.487908\n",
      "[LightGBM] [Debug] Re-bagging, using 286181 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481671\n",
      "[LightGBM] [Debug] Re-bagging, using 286097 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475499\n",
      "[LightGBM] [Debug] Re-bagging, using 286306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.469427\n",
      "[LightGBM] [Debug] Re-bagging, using 286483 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463452\n",
      "[LightGBM] [Debug] Re-bagging, using 286221 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457573\n",
      "[LightGBM] [Debug] Re-bagging, using 286409 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.451818\n",
      "[LightGBM] [Debug] Re-bagging, using 286214 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.446153\n",
      "[LightGBM] [Debug] Re-bagging, using 285929 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440547\n",
      "[LightGBM] [Debug] Re-bagging, using 286699 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.435058\n",
      "[LightGBM] [Debug] Re-bagging, using 286215 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429624\n",
      "[LightGBM] [Debug] Re-bagging, using 286583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424273\n",
      "[LightGBM] [Debug] Re-bagging, using 286432 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.419004\n",
      "[LightGBM] [Debug] Re-bagging, using 286720 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.413816\n",
      "[LightGBM] [Debug] Re-bagging, using 286004 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408706\n",
      "[LightGBM] [Debug] Re-bagging, using 286342 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.403673\n",
      "[LightGBM] [Debug] Re-bagging, using 285997 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.398716\n",
      "[LightGBM] [Debug] Re-bagging, using 286384 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.39386\n",
      "[LightGBM] [Debug] Re-bagging, using 286114 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.389049\n",
      "[LightGBM] [Debug] Re-bagging, using 286532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384309\n",
      "[LightGBM] [Debug] Re-bagging, using 286381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.379639\n",
      "[LightGBM] [Debug] Re-bagging, using 286778 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.375037\n",
      "[LightGBM] [Debug] Re-bagging, using 286408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370502\n",
      "[LightGBM] [Debug] Re-bagging, using 286312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.366032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 166667, number of negative: 191346\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058321\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000012 seconds, init for row-wise cost 0.027632 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034594 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3707\n",
      "[LightGBM] [Info] Number of data points in the train set: 358013, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465533 -> initscore=-0.138085\n",
      "[LightGBM] [Info] Start training from score -0.138085\n",
      "[LightGBM] [Debug] Re-bagging, using 286499 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.680812\n",
      "[LightGBM] [Debug] Re-bagging, using 286051 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678855\n",
      "[LightGBM] [Debug] Re-bagging, using 286527 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669143\n",
      "[LightGBM] [Debug] Re-bagging, using 286227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659679\n",
      "[LightGBM] [Debug] Re-bagging, using 286592 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659047\n",
      "[LightGBM] [Debug] Re-bagging, using 286458 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.649776\n",
      "[LightGBM] [Debug] Re-bagging, using 286522 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640632\n",
      "[LightGBM] [Debug] Re-bagging, using 286394 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631664\n",
      "[LightGBM] [Debug] Re-bagging, using 286335 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622866\n",
      "[LightGBM] [Debug] Re-bagging, using 286488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614282\n",
      "[LightGBM] [Debug] Re-bagging, using 286467 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605858\n",
      "[LightGBM] [Debug] Re-bagging, using 286545 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.59759\n",
      "[LightGBM] [Debug] Re-bagging, using 286176 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589424\n",
      "[LightGBM] [Debug] Re-bagging, using 286247 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.581456\n",
      "[LightGBM] [Debug] Re-bagging, using 286042 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.573582\n",
      "[LightGBM] [Debug] Re-bagging, using 286148 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.56585\n",
      "[LightGBM] [Debug] Re-bagging, using 286435 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564425\n",
      "[LightGBM] [Debug] Re-bagging, using 286375 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556855\n",
      "[LightGBM] [Debug] Re-bagging, using 285860 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549418\n",
      "[LightGBM] [Debug] Re-bagging, using 286388 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.54211\n",
      "[LightGBM] [Debug] Re-bagging, using 286434 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.534928\n",
      "[LightGBM] [Debug] Re-bagging, using 286526 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.52787\n",
      "[LightGBM] [Debug] Re-bagging, using 286299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.520932\n",
      "[LightGBM] [Debug] Re-bagging, using 286625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.514112\n",
      "[LightGBM] [Debug] Re-bagging, using 286514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.50745\n",
      "[LightGBM] [Debug] Re-bagging, using 286779 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500855\n",
      "[LightGBM] [Debug] Re-bagging, using 286582 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.49437\n",
      "[LightGBM] [Debug] Re-bagging, using 286320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.487991\n",
      "[LightGBM] [Debug] Re-bagging, using 286232 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481756\n",
      "[LightGBM] [Debug] Re-bagging, using 286162 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475583\n",
      "[LightGBM] [Debug] Re-bagging, using 286373 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.46951\n",
      "[LightGBM] [Debug] Re-bagging, using 286531 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463534\n",
      "[LightGBM] [Debug] Re-bagging, using 286262 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457653\n",
      "[LightGBM] [Debug] Re-bagging, using 286438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.451903\n",
      "[LightGBM] [Debug] Re-bagging, using 286277 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.446242\n",
      "[LightGBM] [Debug] Re-bagging, using 285969 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440635\n",
      "[LightGBM] [Debug] Re-bagging, using 286768 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.43515\n",
      "[LightGBM] [Debug] Re-bagging, using 286268 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429714\n",
      "[LightGBM] [Debug] Re-bagging, using 286599 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424363\n",
      "[LightGBM] [Debug] Re-bagging, using 286487 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.419093\n",
      "[LightGBM] [Debug] Re-bagging, using 286760 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.413903\n",
      "[LightGBM] [Debug] Re-bagging, using 286060 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408792\n",
      "[LightGBM] [Debug] Re-bagging, using 286411 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.403758\n",
      "[LightGBM] [Debug] Re-bagging, using 286054 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.3988\n",
      "[LightGBM] [Debug] Re-bagging, using 286455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.393948\n",
      "[LightGBM] [Debug] Re-bagging, using 286153 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.389136\n",
      "[LightGBM] [Debug] Re-bagging, using 286583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384395\n",
      "[LightGBM] [Debug] Re-bagging, using 286416 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.379723\n",
      "[LightGBM] [Debug] Re-bagging, using 286829 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.37512\n",
      "[LightGBM] [Debug] Re-bagging, using 286448 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370584\n",
      "[LightGBM] [Debug] Re-bagging, using 286368 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.366114\n",
      "[LightGBM] [Info] Number of positive: 166667, number of negative: 191409\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058394\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000015 seconds, init for row-wise cost 0.027014 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.034148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3700\n",
      "[LightGBM] [Info] Number of data points in the train set: 358076, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465451 -> initscore=-0.138415\n",
      "[LightGBM] [Info] Start training from score -0.138415\n",
      "[LightGBM] [Debug] Re-bagging, using 286550 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.680868\n",
      "[LightGBM] [Debug] Re-bagging, using 286096 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 7\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678923\n",
      "[LightGBM] [Debug] Re-bagging, using 286585 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.66921\n",
      "[LightGBM] [Debug] Re-bagging, using 286281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659707\n",
      "[LightGBM] [Debug] Re-bagging, using 286631 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659095\n",
      "[LightGBM] [Debug] Re-bagging, using 286516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.649789\n",
      "[LightGBM] [Debug] Re-bagging, using 286572 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640645\n",
      "[LightGBM] [Debug] Re-bagging, using 286444 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631677\n",
      "[LightGBM] [Debug] Re-bagging, using 286383 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622879\n",
      "[LightGBM] [Debug] Re-bagging, using 286547 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614263\n",
      "[LightGBM] [Debug] Re-bagging, using 286514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605808\n",
      "[LightGBM] [Debug] Re-bagging, using 286588 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.59751\n",
      "[LightGBM] [Debug] Re-bagging, using 286244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589346\n",
      "[LightGBM] [Debug] Re-bagging, using 286303 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.581348\n",
      "[LightGBM] [Debug] Re-bagging, using 286074 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.573477\n",
      "[LightGBM] [Debug] Re-bagging, using 286199 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.565746\n",
      "[LightGBM] [Debug] Re-bagging, using 286493 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564328\n",
      "[LightGBM] [Debug] Re-bagging, using 286410 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556759\n",
      "[LightGBM] [Debug] Re-bagging, using 285917 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549323\n",
      "[LightGBM] [Debug] Re-bagging, using 286406 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.542017\n",
      "[LightGBM] [Debug] Re-bagging, using 286488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.534837\n",
      "[LightGBM] [Debug] Re-bagging, using 286600 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.527781\n",
      "[LightGBM] [Debug] Re-bagging, using 286355 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.520844\n",
      "[LightGBM] [Debug] Re-bagging, using 286672 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.514025\n",
      "[LightGBM] [Debug] Re-bagging, using 286559 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.507336\n",
      "[LightGBM] [Debug] Re-bagging, using 286828 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500743\n",
      "[LightGBM] [Debug] Re-bagging, using 286645 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.49426\n",
      "[LightGBM] [Debug] Re-bagging, using 286386 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.487883\n",
      "[LightGBM] [Debug] Re-bagging, using 286286 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481625\n",
      "[LightGBM] [Debug] Re-bagging, using 286198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475454\n",
      "[LightGBM] [Debug] Re-bagging, using 286397 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.469383\n",
      "[LightGBM] [Debug] Re-bagging, using 286601 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463409\n",
      "[LightGBM] [Debug] Re-bagging, using 286309 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457531\n",
      "[LightGBM] [Debug] Re-bagging, using 286503 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.451758\n",
      "[LightGBM] [Debug] Re-bagging, using 286298 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.446077\n",
      "[LightGBM] [Debug] Re-bagging, using 286020 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440472\n",
      "[LightGBM] [Debug] Re-bagging, using 286812 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.434967\n",
      "[LightGBM] [Debug] Re-bagging, using 286312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429534\n",
      "[LightGBM] [Debug] Re-bagging, using 286670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424185\n",
      "[LightGBM] [Debug] Re-bagging, using 286550 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.418918\n",
      "[LightGBM] [Debug] Re-bagging, using 286817 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.413731\n",
      "[LightGBM] [Debug] Re-bagging, using 286103 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408623\n",
      "[LightGBM] [Debug] Re-bagging, using 286442 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.403592\n",
      "[LightGBM] [Debug] Re-bagging, using 286110 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.398636\n",
      "[LightGBM] [Debug] Re-bagging, using 286495 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 4 and depth = 2\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.393766\n",
      "[LightGBM] [Debug] Re-bagging, using 286214 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.388957\n",
      "[LightGBM] [Debug] Re-bagging, using 286637 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384218\n",
      "[LightGBM] [Debug] Re-bagging, using 286475 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.379549\n",
      "[LightGBM] [Debug] Re-bagging, using 286870 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.374949\n",
      "[LightGBM] [Debug] Re-bagging, using 286502 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370415\n",
      "[LightGBM] [Debug] Re-bagging, using 286430 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.365947\n",
      "[LightGBM] [Info] Number of positive: 166667, number of negative: 191298\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.058436\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000015 seconds, init for row-wise cost 0.027180 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3699\n",
      "[LightGBM] [Info] Number of data points in the train set: 357965, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.465596 -> initscore=-0.137835\n",
      "[LightGBM] [Info] Start training from score -0.137835\n",
      "[LightGBM] [Debug] Re-bagging, using 286461 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.68077\n",
      "[LightGBM] [Debug] Re-bagging, using 286014 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.678791\n",
      "[LightGBM] [Debug] Re-bagging, using 286488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669081\n",
      "[LightGBM] [Debug] Re-bagging, using 286174 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.659569\n",
      "[LightGBM] [Debug] Re-bagging, using 286565 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.658968\n",
      "[LightGBM] [Debug] Re-bagging, using 286416 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.649654\n",
      "[LightGBM] [Debug] Re-bagging, using 286483 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.640513\n",
      "[LightGBM] [Debug] Re-bagging, using 286359 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.631547\n",
      "[LightGBM] [Debug] Re-bagging, using 286296 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.622752\n",
      "[LightGBM] [Debug] Re-bagging, using 286455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.614128\n",
      "[LightGBM] [Debug] Re-bagging, using 286419 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.605665\n",
      "[LightGBM] [Debug] Re-bagging, using 286505 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.597358\n",
      "[LightGBM] [Debug] Re-bagging, using 286148 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.589197\n",
      "[LightGBM] [Debug] Re-bagging, using 286196 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.581191\n",
      "[LightGBM] [Debug] Re-bagging, using 285995 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.573322\n",
      "[LightGBM] [Debug] Re-bagging, using 286124 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.565595\n",
      "[LightGBM] [Debug] Re-bagging, using 286412 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564175\n",
      "[LightGBM] [Debug] Re-bagging, using 286314 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.556609\n",
      "[LightGBM] [Debug] Re-bagging, using 285822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.549176\n",
      "[LightGBM] [Debug] Re-bagging, using 286353 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.541873\n",
      "[LightGBM] [Debug] Re-bagging, using 286413 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.534695\n",
      "[LightGBM] [Debug] Re-bagging, using 286508 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.527641\n",
      "[LightGBM] [Debug] Re-bagging, using 286245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.520707\n",
      "[LightGBM] [Debug] Re-bagging, using 286583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.513891\n",
      "[LightGBM] [Debug] Re-bagging, using 286462 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.507194\n",
      "[LightGBM] [Debug] Re-bagging, using 286739 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.500604\n",
      "[LightGBM] [Debug] Re-bagging, using 286558 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.494123\n",
      "[LightGBM] [Debug] Re-bagging, using 286280 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.487749\n",
      "[LightGBM] [Debug] Re-bagging, using 286187 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.481484\n",
      "[LightGBM] [Debug] Re-bagging, using 286117 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.475315\n",
      "[LightGBM] [Debug] Re-bagging, using 286310 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.469246\n",
      "[LightGBM] [Debug] Re-bagging, using 286500 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.463275\n",
      "[LightGBM] [Debug] Re-bagging, using 286249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.457399\n",
      "[LightGBM] [Debug] Re-bagging, using 286413 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.451621\n",
      "[LightGBM] [Debug] Re-bagging, using 286224 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.445934\n",
      "[LightGBM] [Debug] Re-bagging, using 285931 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.440331\n",
      "[LightGBM] [Debug] Re-bagging, using 286713 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.43482\n",
      "[LightGBM] [Debug] Re-bagging, using 286254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.429389\n",
      "[LightGBM] [Debug] Re-bagging, using 286564 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.424043\n",
      "[LightGBM] [Debug] Re-bagging, using 286468 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.418778\n",
      "[LightGBM] [Debug] Re-bagging, using 286713 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.413593\n",
      "[LightGBM] [Debug] Re-bagging, using 286013 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.408487\n",
      "[LightGBM] [Debug] Re-bagging, using 286364 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.403458\n",
      "[LightGBM] [Debug] Re-bagging, using 286017 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.398504\n",
      "[LightGBM] [Debug] Re-bagging, using 286392 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.393629\n",
      "[LightGBM] [Debug] Re-bagging, using 286121 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.388821\n",
      "[LightGBM] [Debug] Re-bagging, using 286559 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.384085\n",
      "[LightGBM] [Debug] Re-bagging, using 286394 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.379418\n",
      "[LightGBM] [Debug] Re-bagging, using 286785 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.374819\n",
      "[LightGBM] [Debug] Re-bagging, using 286402 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.370288\n",
      "[LightGBM] [Debug] Re-bagging, using 286326 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.365822\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证次数6；k_fold\n",
    "k_fold = 6\n",
    "# 一份训练用的数据copy一下；\n",
    "trn_df_classifier = trn_user_item_feats_df_rank_model\n",
    "# 把训练集用户单独拿出来；user_ids\n",
    "user_ids_classifier = trn_df_classifier['user_id'].unique()\n",
    "#  与前面排序阶段是类似的，这里函数不再重新说明\n",
    "def get_kfold_users(trn_df, n = 6):\n",
    "    user_ids_classifier = trn_df_classifier['user_id'].unique()\n",
    "    user_set_classifier = [user_ids_classifier[i::n] for i in range(n)]\n",
    "    return user_set_classifier\n",
    "user_set_classifier = get_kfold_users(trn_df_classifier, n=k_fold)\n",
    "# 生成空列表，为了储存交叉验证分数；\n",
    "score_list_classifier = []\n",
    "score_df_classifier = trn_df_classifier[['user_id', 'click_article_id', 'label']]\n",
    "# 定义测试集分类器分数收集数组\n",
    "sub_preds_points_classifier = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set_classifier):\n",
    "    train_idx = trn_df_classifier[~trn_df_classifier['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df_classifier[trn_df_classifier['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=52, random_state=0, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication_re = lgb_Classfication.fit(train_idx[lgb_ranker_need_cols], train_idx['label'],eval_set=[(valid_idx[lgb_ranker_need_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication_re.predict_proba(valid_idx[lgb_ranker_need_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list_classifier.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds_points_classifier += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_ranker_need_cols], \n",
    "                                                     num_iteration=lgb_Classfication_re.best_iteration_)[:,1]\n",
    "score_df_classifier_ = pd.concat(score_list_classifier, axis=0)\n",
    "score_df_classifier = score_df_classifier.merge(score_df_classifier_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df_classifier[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_dir + 'trn_lgb_classifier_feats_result.csv', index=False)\n",
    "\n",
    "\n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds_points_classifier / k_fold\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_dir + 'tst_lgb_classifier_feats_result.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68e3cf",
   "metadata": {},
   "source": [
    "## P6.再生成结果到本地！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2f91d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次预测结果重新排序, 及生成提交结果\n",
    "rank_results_classifier_crossed = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_classifier_crossed['click_article_id'] = rank_results_classifier_crossed['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_classifier_crossed,'交叉验证后', topk=5, model_name='lgb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b48cd7",
   "metadata": {},
   "source": [
    "# C3.建设一个DNN神经网络试试；\n",
    "利用keras中的DNN建立一个神经网络看一下结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "726a5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f07dd2",
   "metadata": {},
   "source": [
    "## P1.从训练集中拿出一部分作为验证用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf284090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300736, 26), (300736,), (128887, 26), (128887,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_need_train = trn_user_item_feats_df_rank_model[lgb_ranker_need_cols]\n",
    "y_need_train = trn_user_item_feats_df_rank_model['label']\n",
    "# y_need_train = to_categorical(trn_user_item_feats_df_rank_model['label'])# Tensor要转一下\n",
    "X_train_dnn, X_val_dnn, y_train_dnn, y_val_dnn = train_test_split(X_need_train,y_need_train,test_size=0.3,random_state=0)\n",
    "X_train_dnn.shape,y_train_dnn.shape,X_val_dnn.shape,y_val_dnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80bef1",
   "metadata": {},
   "source": [
    "## P2.建立DNN网络；\n",
    "### S1.输入层和中间层；\n",
    "- 先设置三层隐藏层，每一层10个神经元；激活函数选用relu；\n",
    "- 每一层隐藏层后面加一个标准化层；\n",
    "- 最终加一个Alpha正则化层；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55851fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个DNN\n",
    "model_DNN = keras.models.Sequential()\n",
    "model_DNN.add(keras.layers.Flatten(input_shape = [26, 1]))  # flatten层的作用是将28*28维度的输入数据展平成一层，输入层；虽然本就是一维\n",
    "for _ in range(4):\n",
    "    # 隐藏层的激活函数都选用relu，如果选用selu自带归一化功能；\n",
    "    model_DNN.add(keras.layers.Dense(30, activation = \"relu\"))\n",
    "    # 隐藏层加入标准化模块加速训练速度，将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1；\n",
    "    model_DNN.add(keras.layers.BatchNormalization()) \n",
    "model_DNN.add(keras.layers.AlphaDropout(rate=0.5))  # 正则化层；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1cd26",
   "metadata": {},
   "source": [
    "### S2.输出层；\n",
    "- len(pd.Series(y_val_dnn).unique())这样写就不用了写2了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a20ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                810       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 4,142\n",
      "Trainable params: 3,902\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_DNN.add(keras.layers.Dense(len(pd.Series(y_val_dnn).unique()), activation = \"softmax\")) \n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7b52a",
   "metadata": {},
   "source": [
    "## P2.定义模型训练器，训练数据；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b6c498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "101/101 [==============================] - 4s 10ms/step - loss: 0.8624 - accuracy: 0.5115 - val_loss: 0.6937 - val_accuracy: 0.5335\n",
      "Epoch 2/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7971 - accuracy: 0.5446 - val_loss: 0.7123 - val_accuracy: 0.5335\n",
      "Epoch 3/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7607 - accuracy: 0.5671 - val_loss: 0.7543 - val_accuracy: 0.5335\n",
      "Epoch 4/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7456 - accuracy: 0.5747 - val_loss: 0.7568 - val_accuracy: 0.5335\n",
      "Epoch 5/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7289 - accuracy: 0.5842 - val_loss: 0.7277 - val_accuracy: 0.5335\n",
      "Epoch 6/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7183 - accuracy: 0.5883 - val_loss: 0.6726 - val_accuracy: 0.5335\n",
      "Epoch 7/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7087 - accuracy: 0.5908 - val_loss: 0.6567 - val_accuracy: 0.6417\n",
      "Epoch 8/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.7008 - accuracy: 0.5950 - val_loss: 0.6511 - val_accuracy: 0.6554\n",
      "Epoch 9/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6899 - accuracy: 0.5975 - val_loss: 0.6529 - val_accuracy: 0.6584\n",
      "Epoch 10/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6850 - accuracy: 0.6008 - val_loss: 0.6519 - val_accuracy: 0.6582\n",
      "Epoch 11/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6778 - accuracy: 0.6045 - val_loss: 0.6728 - val_accuracy: 0.6564\n",
      "Epoch 12/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6719 - accuracy: 0.6074 - val_loss: 0.6603 - val_accuracy: 0.6569\n",
      "Epoch 13/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6698 - accuracy: 0.6041 - val_loss: 0.7441 - val_accuracy: 0.6348\n",
      "Epoch 14/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6674 - accuracy: 0.6034 - val_loss: 0.8445 - val_accuracy: 0.6348\n",
      "Epoch 15/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6580 - accuracy: 0.6156 - val_loss: 0.9081 - val_accuracy: 0.6361\n",
      "Epoch 16/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6524 - accuracy: 0.6180 - val_loss: 1.0663 - val_accuracy: 0.6323\n",
      "Epoch 17/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6500 - accuracy: 0.6194 - val_loss: 0.9573 - val_accuracy: 0.6372\n",
      "Epoch 18/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6473 - accuracy: 0.6211 - val_loss: 0.7888 - val_accuracy: 0.6474\n",
      "Epoch 19/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6427 - accuracy: 0.6237 - val_loss: 0.8411 - val_accuracy: 0.6451\n",
      "Epoch 20/20\n",
      "101/101 [==============================] - 1s 7ms/step - loss: 0.6406 - accuracy: 0.6259 - val_loss: 0.7977 - val_accuracy: 0.6481\n"
     ]
    }
   ],
   "source": [
    "# # 定义训练历史；\n",
    "# train_history = model_DNN.fit(X_need_train, y_need_train, batch_size = 1000, epochs=6)\n",
    "# history_frame = pd.DataFrame(train_history.history)\n",
    "# history_frame['epoch'] = train_history.epoch\n",
    "# history_frame['epoch'] = history_frame['epoch'] + 1\n",
    "# def plot_history(hist):\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.plot(hist['epoch'], hist['accuracy'],label='accuracy')\n",
    "#     plt.legend()\n",
    "# plot_history(history_frame)    \n",
    "model_DNN.compile(\n",
    "             loss = \"sparse_categorical_crossentropy\",  # 稀疏分类交叉熵损失函数\n",
    "             optimizer = keras.optimizers.Adam(learning_rate = 0.0001),    # 优化函数为随机梯度下降 ，学习率为0.01\n",
    "             metrics = [\"accuracy\"])                     # 优化指标为准确度\n",
    "# 记录训练历史\n",
    "model_DNN_train_history = model_DNN.fit(X_train_dnn, y_train_dnn,             # 训练数据\n",
    "                                        batch_size=3000,                       # 每一次迭代传入5000样本；\n",
    "                                        epochs = 20,                           # 训练周期，数据分为10次进行训练\n",
    "                                        validation_data = (X_val_dnn, y_val_dnn),) # 验证集要用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe90d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAEjCAYAAADngN85AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAktUlEQVR4nO3deZwdZZ3v8c+vl9AhTQKEFi9EZDEG2SI7cQKezIDbuHBZlBnH3YkKV507mxu+VEQZccbxpTOiUS4qg8yNzlWcuexeexIUFTLsyKoBgyxZgNBAhyy/+0dVk0Onl9N01+nu9Of9mnqlzlNPVT3nicP55qmnqiIzkSRJUnVaxrsBkiRJ2zsDlyRJUsUMXJIkSRUzcEmSJFXMwCVJklQxA5ckSVLFDFySJEkVGzZwRcSsiLgsIq6MiB9GxLRB6p0fEddGxJlDlUmSJE01jYxwvRX4Uma+CngIeE3/ChFxEtCamQuAfSNi7kBlY9lwSZKkyaJtuAqZ+bW6j13AIwNUqwFLy/UrgYXAoQOU3V2/U0QsBhYDdHR0HL7XXnuNoOkarS1bttDS4lXlZrLPm88+bz77vPns8+a766671mRmV6P1hw1cfSJiAbBLZv5igM0zgAfK9XXAYYOUPUdmLgGWAMybNy/vvPPORpujMdDd3U2tVhvvZkwp9nnz2efNZ583n33efBFx30jqNxS4ImJX4KvAyYNU6QGml+udFJcqByqTJEmachqZND8N+D7wscwcLM2toLhkCDAfWDlImSRJ0pTTyAjXeyguB34iIj4B/BRoz8z6Ow9/BCyPiD2A1wLHADlAmSRJ0pTTyKT584DzhqmzPiJqwAnAuZn5OMBAZZIkaWQ2btzIqlWr6O3tHXD7rFmz+PWvf93kVk0NHR0dzJkzh/b29lEdp+FJ88PJzEfZelfioGWSJGlkVq1axU477cTee+9NRGyz/YknnmCnnXYah5Zt3zKTtWvXsmrVKvbZZ59RHcuJ7JIkTXC9vb3Mnj17wLCl6kQEs2fPHnRkcSQMXJIkTQKGrfExVv1u4JIkSaqYgUuSJKliYzZpXpIkVe8z/34bt/9+/XPKNm/eTGtr6/M+5gF7zORTbzhwtE17Vq1Wo7u7e8yOtz1whEuSJKlijnBJkjSJDDQS1YzHQnzuc5/jwAMP5MQTT+Scc85hzpw5XHTRRTz55JO85CUv4YILLmj4WD09PZxyyinP2be3t5d3vvOdrFq1ip133pmlS5fS0tKyTdm5555LrVajVqvx7W9/G4B3vvOd1Go1jjzySG6++WauuOKKhs/xhS98gZe97GWcdtppfPrTn2b//ffntNNOG/P+c4RLkiQN69RTT+Wyyy4DYNmyZRxyyCF88IMf5Oqrr2blypU8/PDDDR/rwQcf3GbfJUuWMH/+fK655hpOPvlkbr311gHLBvOLX/yCBQsWcMUVV4zoHG9/+9v53ve+B8AVV1zBm970plH00uAMXJIkaVgvfelLWbVqFevXr2fnnXdm1qxZfOtb3+Ktb30r69at4+mnn274WO3t7dvse8cdd3DUUUcBxYjVkUceOWBZvfpzHnTQQZx00kkjPsd+++3HE088QXd3NwcddBDTp09/3n00FAOXJElqyFFHHcWXv/xl3vjGN3L++edzyimncPHFFzNjxowRHWegfffff3+uu+46AD7/+c/zrW99a8CyadOmsXr1agAuv/zyZ4/Z2dn5vM4BcNppp/Hud7+bt7/97SPtkoY5h0uSJDXk1FNPZeHChdx3333sueeenH766Xz9618H4IEHHmDvvfdu6DgnnHDCNvv++Z//Oe94xzuo1WrMnj2biy66iMzcpuyee+7h9NNP5yc/+QmzZ88e9TkATjnlFM4991wWLlw4it4ZmoFLkiQ15IADDmDdunUAHHfccYPOqRrukRCD7bt06bavX+5fdtBBB7Fs2bJhz9noOW677Tbe9a538fGPf7zSp/kbuCRJUmVqtdpzPs+aNYtLLrlkfBozgAMPPJBf/epXlZ/HwCVJ0iSQmZPyfYqT/QGomTkmx3HSvCRJE1xHRwdr164dsx9/NSYzWbt2LR0dHaM+liNckiRNcHPmzGHVqlXP3p3XX29v75iEAm2ro6ODOXPmjPo4Bi5Jkia49vZ29tlnn0G3d3d3c+ihhzaxRRopLylKkiRVzMAlSZJUMQOXJElSxRoKXBGxe0QsH2L7ByKiu1xujIhvRERbRNxfV37w2DVbkiRp8hh20nxE7AJ8Bxj0RUmZeR5wXln/q2X9Q4CLM/MjY9NUSZKkySmGe6ZHRMwEArgkM2vD1N0T+MfMfHNEnA6cATwJ3AK8LzM39au/GFgM0NXVdfhAj/RXdXp6erZ52aeqZZ83n33efPZ589nnzbdo0aIVmXlEo/WHDVzPVozobiBwfR64KjN/GhFHAqsy88GI+C7wg8z88WD7zps3L++8885G260x0N3dvc0rF1Qt+7z57PPms8+bzz5vvogYUeAas0nzEdECLAK6y6KbM/PBcv16YO5YnUuSJGkyGcu7FI8Ffplbh8wujIj5EdEKnAjcNIbnkiRJmjRGHLgi4oCIOHuATa8GltV9Pgu4ELgRuDYzr35eLZQkSZrkGn61T9/8rcy8HThzgO0f7/f5Voo7FSVJkqY0H3wqSZJUMQOXJElSxQxckiRJFTNwSZIkVczAJUmSVDEDlyRJUsUMXJIkSRUzcEmSJFXMwCVJklQxA5ckSVLFDFySJEkVM3BJkiRVzMAlSZJUMQOXJElSxQxckiRJFTNwSZIkVczAJUmSVDEDlyRJUsUMXJIkSRUzcEmSJFXMwCVJklQxA5ckSVLFGgpcEbF7RCwfYntbRNwfEd3lcnBZfn5EXBsRZ45VgyVJkiabYQNXROwCfAeYMUS1Q4CLM7NWLrdExElAa2YuAPaNiLlj02RJkqTJJTJz6AoRM4EALsnM2iB1TgfOAJ4EbgHeB3wJuDwzL42I04DpmXlBv/0WA4sBurq6Dl+6dOnovo1GpKenh87OzvFuxpRinzeffd589nnz2efNt2jRohWZeUSj9duGq5CZ6wEiYqhq1wHHZ+aDEfFd4HUUI2IPlNvXAYcNcOwlwBKAefPmZa1Wa7TdGgPd3d3Y581lnzeffd589nnz2ecT37CBq0E3Z+aGcv16YC7QA0wvyzpxgr4kSZqixioEXRgR8yOiFTgRuAlYASwst88HVo7RuSRJkiaVEY9wRcQBwJ9mZv2dh2cB36OY6/XjzLy6nPu1PCL2AF4LHDMWDZYkSZpsGg5cfRPmM/N24Mx+226luFOxvmx9RNSAE4BzM/PxUbZVkiRpUhqrOVwDysxHAW89lCRJU5oT2SVJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkijUUuCJi94hYPsT2WRFxWURcGRE/jIhpEdEWEfdHRHe5HDx2zZYkSZo8hg1cEbEL8B1gxhDV3gp8KTNfBTwEvAY4BLg4M2vlcstYNFiSJGmyaWSEazPwFmD9YBUy82uZeVX5sQt4BDgGeH1E/Coizo+ItlG3VpIkaRKKzGysYkR3ZtaGqbMAODsz/ygijgRWZeaDEfFd4AeZ+eN+9RcDiwG6uroOX7p06fP5Dnqeenp66OzsHO9mTCn2efPZ581nnzeffd58ixYtWpGZRzRaf8xGnSJiV+CrwMll0c2ZuaFcvx6Y23+fzFwCLAGYN29e1mq1sWqOGtDd3Y193lz2efPZ581nnzeffT7xjcldihExDfg+8LHMvK8svjAi5kdEK3AicNNYnEuSJGmyGXHgiogDIuLsfsXvAQ4DPlHekfgW4CzgQuBG4NrMvHq0jZUkSZqMGr6k2Dd/KzNvB87st+084LwBdjtkNI2TJEnaHvjgU0mSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKtZQ4IqI3SNi+TB1zo+IayPizKHKJEmSppphA1dE7AJ8B5gxRJ2TgNbMXADsGxFzByobq0ZLkiRNJpGZQ1eImAkEcElm1gap8xXg8sy8NCJOA6YDh/Yvy8wL+u23GFgM0NXVdfjSpUtH+300Aj09PXR2do53M6YU+7z57PPms8+bzz5vvkWLFq3IzCMard82XIXMXA8QEUNVmwE8UK6vAw4bpKz/sZcASwDmzZuXtVqtwWZrLHR3d2OfN5d93nz2efPZ581nn098YzVpvodiVAugszzuQGWSJElTzliFoBXAwnJ9PrBykDJJkqQpZ9hLiv1FxAHAn2Zm/Z2HPwKWR8QewGuBY4AcoEySJGnKaXiEq2/CfGbe3i9s9c3zqgG/ABZl5uMDlY1RmyVJkiaVEY9wDSYzHwWWDlcmSZI01TiRXZIkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqWEOBKyLOj4hrI+LMQbZ/ICK6y+XGiPhGRLRFxP115QePbdMlSZImh2EDV0ScBLRm5gJg34iY279OZp6XmbXMrAHLgW8ChwAX95Vn5i1j3HZJkqRJoZERrhqwtFy/Elg4WMWI2BPYPTOvB44BXh8RvypHyNpG21hJkqTJqJEQNAN4oFxfBxw2RN0zgPPK9euA4zPzwYj4LvA64Mf1lSNiMbAYoKuri+7u7sZbrlHr6emxz5vMPm8++7z57PPms88nvkYCVw8wvVzvZJBRsYhoARYBnyiLbs7MDeX69cBAlyKXAEsA5s2bl7VareGGa/S6u7uxz5vLPm8++7z57PPms88nvkYuKa5g62XE+cDKQeodC/wyM7P8fGFEzI+IVuBE4KZRtFOSJGnSaiRw/Qh4W0R8CXgzcFtEnD1AvVcDy+o+nwVcCNwIXJuZV4+uqZIkSZPTsJcUM3N9RNSAE4BzM/MhBhitysyP9/t8K8WdipIkSVNaQ3cOZuajbL1TUZIkSSPgk+YlSZIqZuCSJEmqmIFLkiSpYj79XZImucwkE7ZksqX8c+vnoizrtm3pX3/L1s9J3/519beM7Ji3rtlEy12rB21vxNDfJxi6wvD7P9+NxbkjimoRQUv0nW+A8rKsr01B0NLS/xjFvsVx4tmyZ+sMVl6e5znr1NXvV75hU/LUM5sAePbhTKX6j9lvY7+qz913m+PkwPVGcw5gx2mt7DitlRjuL3aSM3BJ0ghs3pL0btxcLJu2sGHjZno3bqF3U1G2YeOWclv9evln+XlD37ZNW8t6646zYeMWNmzazOYtjQWo/j9gE8L1vxrvFkw9V18x3i143loCZuzQxsyOdjp3aKOzo42dOtro3KGNnTra69a3/rlTv7o77dBOR3vLhA1uBi5J26XM5L61T7Hi4U08dsMDZdDZ8pxg07e+oX7bACFoQ1+w2rSZjZuff7qZ1trCDu0t7NDWSkd7Cx3t5Z9trew4rY1dZxTb+uq0twYt5WhGSzmqUnzeut43cvLs9pYR1i+HSp5bv+9zff2yrGXb/fvXv+GGGzjssEMH+XsZ5u9tmD4cdv8hKjRy7CQp/+/Zz30BN8uDJH0BeGt5lhufLS/Xs65NfeG4vvzZP/ud8zl1+p3nufsUf957773st99+z36X/pmjftRw2BHCugr9q9bvu+22wc+xzSn7KmTy9MbNPNG76dmlZ8NGejZsYt2Tz3D/2qd4YsMmnujdSO/GLUM3HGhrCTrrg1oD4a2zY9ugt0Nb67DnGikDl6Ttxvrejfz8nrUsu3s1y+9eze/WPV1suOHGbeq2twYdba3s0N7KDm0tdQGoCEE7T2+no9y2Q3tdQKoLS8V+xecdBt1Wbm9rpbVlYv7Le6z1rGzl8BfvOt7NmFK683fUXrnf8BUnsY2bt/DkhvpgVgSxng2bWN+7iZ4yrD1RrvcFtUee6OU3q8v9NmzimU3DB7dprS1FIHtOOGsvR9aKspEycEmatDZvSW5a9RjL71rD8rtXc8PvHmPzlqRzhzYW7Debxcfuy+ZH7uW4VxxdBqKtIWiqhB9pe9He2sLOO05j5x2njeo4GzZtLsPZwOHtOSNtvVuD2u8fe5on6spGysAlaVJ54LGnWX7XapbdvZpr7l7D+t5NRMAhe87iA6/cj+Ne2sWhe+1Me2txE3Z390r27eoc51ZLmih2aGtlh85WZnfu8LyPkZm0nDOyfQxckia0p57ZxC9+s5Zl5SjWvaufBOCFMzt4zUEv5Ni5XSx8yW7sMmN0/+qVpEY9n4n5Bi5JE8qWLcntD65n+d1rWHbXaq6/bx0bNycd7S0cvc9s/uSovXjlS7t4yQs6J+zdSJLUn4FL0rh75IneZ+dhXXPPGtb0PAPA/i/ciXf/wT4cO7eLI/behY72sb9zSJKawcAlqel6N27m+pWPsvzu1fznXau546EnAJg9YxrHzt2NY+d2cezc3XjBzI5xbqkkjQ0Dl6TKZSb3PNLDf961muV3r+GXv11L78YttLcGR7x4Vz7ymv05du5uHPDfZtLi3YOStkMGLkmVePTJZ7jmnuIy4fK71/Dg470A7Ns1g9OO3IvjXrobx+w7mx2n+Z8hSds//0snaUxs3LyFG+5/jGV3FQ8dvfmBx8mEmR1tLJy7Gx+e28XCubsxZ5cdx7upktR0Bi5Jz9vKNU+y/O7VLLt7Ddfeu5aeDZtobQle/qKd+Ys/einHvnQ35s/Z2YeMSpryDFySGra+dyPX3ru2HMVaw/3rngJgzi7TeePL9+C4uV0s2G82s6a3j3NLJWlimTCB69ENyT9ceed4N2NKWXnfM6x4xj5vpsna589s3sJ/3fco/3V/8eqcGdNaWbDfbN57bPHIhr1n7+gzsSRpCBMmcD2+Ifnnn94z3s2YUjIhfmOfN9Nk7fOI4MA9ZvL+V+7LcXO7OHSvXZjW1jLezZKkSWPCBK69Z7Zw5zl/PN7NmFK6u7up1Wrj3YwpxT6XpKmpoX+iRsT5EXFtRJw5yPa2iLg/IrrL5eBG9pMkSZoKhg1cEXES0JqZC4B9I2LuANUOAS7OzFq53NLgfpIkSdu9yMyhK0R8Bbg8My+NiNOA6Zl5Qb86pwNnAE8CtwDvA77UwH6LgcUAXV1dhy9dunSMvpYa0dPTQ2dn53g3Y0qxz5vPPm8++7z57PPmW7Ro0YrMPKLR+o3M4ZoBPFCurwMOG6DOdcDxmflgRHwXeF0j+2XmEmAJwLx589K5Lc3lfKLms8+bzz5vPvu8+ezzia+RwNUDTC/XOxn4MuTNmbmhXL8emNvgfpIkSdu9RkLQCmBhuT4fWDlAnQsjYn5EtAInAjc1uJ8kSdJ2r5ERrh8ByyNiD+C1wGkRcXZm1t95eBbwPSCAH2fm1RExs99+x4xt0yVJkiaHYQNXZq6PiBpwAnBuZj5EMYJVX+dWijsVh9rv8bFpsiRJ0uTS0INPM/NRYMS3ED7f/SRJkrYnTmSXJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSapYQ4ErIs6PiGsj4sxBts+KiMsi4sqI+GFETIuItoi4PyK6y+XgsW26JEnS5DBs4IqIk4DWzFwA7BsRcweo9lbgS5n5KuAh4DXAIcDFmVkrl1vGsuGSJEmTRWTm0BUivgJcnpmXRsRpwPTMvGCI+j8A/h44DDgDeBK4BXhfZm7qV3cxsBigq6vr8KVLl47mu2iEenp66OzsHO9mTCn2efPZ581nnzeffd58ixYtWpGZRzRav62BOjOAB8r1dRRBakARsQDYJTN/ERGbgeMz88GI+C7wOuDH9fUzcwmwBGDevHlZq9UabbfGQHd3N/Z5c9nnzWefN5993nz2+cTXSODqAaaX650MchkyInYFvgqcXBbdnJkbyvXrgYEuRUqSJG33Gpk0vwJYWK7PB1b2rxAR04DvAx/LzPvK4gsjYn5EtAInAjeNurWSJEmTUCOB60fA2yLiS8Cbgdsi4ux+dd5DcanxE+UdiW8BzgIuBG4Ers3Mq8es1ZIkSZPIsJcUM3N9RNSAE4BzM/Mh+o1WZeZ5wHkD7H7IGLRRkiRpUmtkDheZ+SjgLYSSJEnPg0+alyRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIqZuCSJEmqmIFLkiSpYgYuSZKkihm4JEmSKmbgkiRJqpiBS5IkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKliBi5JkqSKGbgkSZIq1lDgiojzI+LaiDhzJHUa2U+SJGl7N2zgioiTgNbMXADsGxFzG6nTyH6SJElTQVsDdWrA0nL9SmAhcHcDdQ4dbr+IWAwsLj9uiIhbG2+6xsBuwJrxbsQUY583n33efPZ589nnzTdvJJUbCVwzgAfK9XXAYQ3WGXa/zFwCLAGIiOsz84iGW65Rs8+bzz5vPvu8+ezz5rPPmy8irh9J/UbmcPUA08v1zkH2GahOI/tJkiRt9xoJQSsoLgcCzAdWNlinkf0kSZK2e41cUvwRsDwi9gBeC5wWEWdn5plD1DkGyAHKhrJkhG3X6NnnzWefN5993nz2efPZ5803oj6PzBy+UsQuwAnAssx8qNE6jewnSZK0vWsocEmSJOn5cyK7JElSxQxcU1BEzIqIyyLiyoj4YURMG+82TRURsXtE3DDe7ZhKIuJrEfGG8W7HVBARu0TEpRFxfUR8Y7zbI4218r/hy8v1Ef2WTojA5SuAmu6twJcy81XAQ8Brxrk9U8nfs/VxKapYRBwLvDAz/3282zJFvA24qHwe1E4R4XOhKlT/419+9re0QuW89O9QPGcURvhbOu6By1cANV9mfi0zryo/dgGPjGd7poqI+EPgSYr/x1TFIqId+CawMiLeNN7tmSLWAgdFxM7Ai4DfjW9ztl/9f/z9LW2KzcBbgPUw8t/ScQ9cDPxaIDVBRCwAdsnMX4x3W7Z35VDzJ4GPjndbppC3A7cD5wJHRcQHx7k9U8E1wIuBDwG/pnjLiKrxnB9//C2tXGauz8zH+5c3+ls6EQJX/1cA7T6ObZkyImJX4KvAu8e7LVPER4GvZeZj492QKeRQYEn5SJp/ARaNc3umgk8B78/Ms4A7gHeNc3u2WwP8+PtbOg5G8ls6EQKXrwBqsnK05fvAxzLzvvFuzxRxPHBGRHQDL4+Ib41ze6aCe4B9y/UjAP+3Xr1dgIMjohU4muIB2GoOf0ubbKS/pRPhL8RXADXfeyheJv6JiOiOiLeMd4O2d5l5XGbWMrMG3JiZ7x3vNk0B5wOLImIZcDrFDQuq1jkUT99+HNgVuHh8mzOl+FvafCP6LR33B59GxExgOfATylcADXSNVJIkPVdEdGdmzd/SiW/cAxf4CiBJkkbL39KJbUIELkmSpO3ZRJjDJUmStF0zcEmSJFXMwCVJDSpfpfKK8W6HpMnHwCVJdcpnSA3mZOBnEXH6CI53REQsLNf/LCI2RcQB5eczI+LF5frHIuKSiHjRaNovaWIycElSqXwH4BUR8T8HqfJGYA3w7REc9gzg38t3220CWoENEVEDPgu8sKx3DPBKfLeptF0ycEnSVr0Ur0j5YkS8un5DOfJ0PPDPmfnUCI75XuBO4H3AM2XZRuDjwKWZ+cuy7EjgPzJzwyjaL2mC8rEQkiat8lVJe2fm3mN4zN0pntq9I3BkZt5bln8WOHOY3Z8GujLzyXKffShGxXYAHgUOAf4H8LdAB7ATxTsHfwXcAvxZZl5U15Y2oD0znx6r7ydpfBi4JE1aVQSu8rivAJZRhKBjgGnAb4GrgM8MsMtOwC+BH2XmSXXHOY7iFUMbgJlA3/ysWyguL7ZRXEK8jMFfPXRJZp44um8kaby1jXcDJGmiycyfR8Q5FEFrC/AxilD1scxcWV5e/H1mbgaIiFOAAP5Pv+MsA+aWc8N+BqyjeMfgYuBFmfn9cv8V5fa+d2zOBq4B/hq4pMKvKqlJnMMlSQPIzE9m5kcoXk7718CXM3NlufkK4NGIaC8//3eK+Vn/0f84EbEfRXhqAT5SFr8KuDgiToyIl5XneDgz78jMO4Cest7NmXnP2H87Sc1m4JI0rIj4g4i4MiLWR8SaiLg0Ig4ut+0dERkRX4iIJRHxaEQ8ERH/1vfIg37HemVEdEfEUxGxNiIujIg5A9Q7MiIuL4+1JiKuGuwZWBExMyLOL+uti4h/KV/mW1/n6Ii4IiJWl8f8VUS8sYGvvwH4N4o7CvtsBO7NzI3l59uAL2bmY/3O+SHgJoq5XTWg72XCFwNfB/6RIswBvLxu1z3KP+9voH2SJgHncEkaUkS8juKy1s+BfwWmA+8H9gSOoAgTv6W4w+83wDeAOcCHgYeBQ/qCSHnp7V+Be8p6s8t6TwDHZOb9Zb0/pJjX9BDwTxSjR+8HXgIcn5n/WdbrBuYC95XtWAr8MfAG4CuZ+eGy3l4UoehB4GvAk8ApwB8BCzLzugG+d1d5rosH2PZb4JHMPHqYvtsXOB34JMUUji8Aq4Evl9/5aOD/AbcD84EXZuYjEfFeikC2Y2Y+M8ChJU02meni4uIy4EIxL+le4AbgBcBu5bIASOCrwN7l+qPArnX7nlGW/1X5eTpF2FgJdNbVewXFPKmldWV3Ucx3ekFd2b7l8f61rqy7LLsMaCnL2imC2q119U4u672prmwmRag5fpDvfna5z8J+5TsCmylGq1qG6b/pFHO/ptW14eS67QdQXJ48qOyDt5Tl/wTcMt5//y4uLmO3OGle0lDmUgQdKEar+ptft35JZq6r+/y/KYLDMeXnV1CEta9kZt8cJbKYoP5L4PXlU973Lc/7rcx8pK7eb8rHJAw0LP83mbmlrLcxIu4C9qrbfj3FCNxHy3P8Vxbzsd4/0JcuR7c+CFydmdf027yIYjrGTIrncl050DFKnyiXej+IiPrPL8nMeyPiOuBUin5bSDHvS9J2wjlckobSVf75beCEAZa/rqv7YL9911KM2uxcfu57ovrvBjjP/RSjQbMoRtIAHuhfKTM39wWrOj2ZeWu/sufUycz7gDdRzMf6HvDbiPh9RHyubuJ7vU+V7fngANveRzHq101xqXAo/wi8mGL+FsCfUfRpF8VjJK7L8jlfwEXAGyLiVRRB9qfDHFvSJOIIl6ShrCn/fDozr67fEBEv71d3z36fuyj+Udc36tU3QrbNBPmyrJfiMt3qQY5HRHwK2D0z699luHaI9j8rM68ErixHuPYH3kbxtPenKS4f9p3jGOADwD9kccdg/flfTTE/7B0U89WWR8THMvOcQc65FlgbEV8Efg9clZlrIuJoivlbp9ZV/18UQe/fKJ7N5eMgpO2II1yShnIXxYT4EyNiVl9hROwBXMdzR3jeFBG71X3+k/LPvktjP6cIX++JiBl1xzqa4rLjpeUI1l3A3cDJEfGCunq7AH9J8QiFEYmIz0bEqojYvTzHbZn5UYqAd1RdvZ0oRvMeBs7qd4xDgH8BrgUuKi81fhP4fET8zRDn7ijP8wzwcETcTjG5/z7gx331ysus3wY6ge+lr/iRtisGLkmDysykeBVNF7AiIv42Ij4IXE0RID5XVz0oRnw+VI7ofJHi0tsF5bGeorhjby/guoj4i/J1OVdRjGr9Vd2xPkDxTsPrIuJvIuLDFJfwdmT41+sMpJviUQv/tzzveyLi+xSXMH8KEMXEqu8A84CP1M8zi4g3UDx5/lHgjVk+8JTikuMy4NyI+E5EdPY/cWb2ZubizNyH4tU+u1LMZZsD3B8Rry/PUaN48OkzwHsj4pXP43tKmqjGe9a+i4vLxF8oJnFfRfEog3UUdwUeXm7bm2Ii++cpJsk/Wtb7PrDnAMf6Q4qQ8nR5rIuAvQaodyTFHXw9FIHs2XPW1ekGVg6w7zblwGsoguIj5blvB/6ybntQhLmfsfWROXsD3y2/34pB2rkjxQNPk2Ie2+kU7z+sr9MGvJnicRi/obgrcQ/g7ygub36O4lU/V1LcNLASeAr40/H+u3dxcRmbxedwSRqViNib4rLjZzLz0+PbmtGLiI7M7C0fnHoHxWT/bwIfzszeQfYJiqfIfwa4EXh1Zj4WEQcCH6KYsN9JEUg/m1tfbv1OikuXu1OEr7Myc3P5/K5LKUbbvpmZi6v6vpKaw0nzklSnL1Rl5vqIeBMwLTN/Nsw+CfxdRFwC9ObWJ87fRXEJ8R+ACzJzTb9db6CYE/bJLOau9R3vNxFxOEUYG3BCvqTJxREuSZKkijlpXpIkqWIGLkmSpIoZuCRJkipm4JIkSaqYgUuSJKli/x8ZIePH564qggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,j in enumerate(model_DNN_train_history.history):\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(4,1,i+1)\n",
    "    plt.plot(range(len(model_DNN_train_history.history[j])),model_DNN_train_history.history[j],label = j)\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_xlim(0, 12)\n",
    "    plt.gca().set_ylim(0, 2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epochs次数\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587c590",
   "metadata": {},
   "source": [
    "- 可以看出效果很差，损失基本不变；\n",
    "- 尝试将原来特征都进行标准化；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe87c3f",
   "metadata": {},
   "source": [
    "## P3.神经网络特征标准化；\n",
    "- 所有数值型特征都标准化处理；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b5c5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "need_feature = [\"sim0\",\"time_diff0\",\"word_diff0\",\"sim_max\",\"sim_min\",\"sim_sum\",\"sim_mean\",\"sim_median\",\"score\",\"words_hbo\",\"words_count\"]\n",
    "mm_Scaler = MinMaxScaler()\n",
    "X_need_feature = mm_Scaler.fit_transform(X_train[need_feature])\n",
    "X_train_DNN_need_feature = pd.DataFrame(X_need_feature,columns = [(str(i) + \"_new\") for i in X_train[need_feature].columns])\n",
    "X_train_DNN_new = pd.concat([X_train_DNN_need_feature,X_train.drop(need_feature,axis=1)],axis=1)\n",
    "# 测试集亦如此\n",
    "X_test_need_feature = mm_Scaler.fit_transform(X_test[need_feature])\n",
    "X_test_DNN_need_feature = pd.DataFrame(X_test_need_feature,columns = [(str(i) + \"_new\") for i in X_test[need_feature].columns])\n",
    "X_test_DNN_new = pd.concat([X_test_DNN_need_feature,X_test.drop(need_feature,axis=1)],axis=1)\n",
    "X_train_DNN_new,X_val_DNN_new,Y_train_DNN_new,Y_val_DNN_new = train_test_split(X_train_DNN_new,y_train,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5579eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((343698, 26), (429623,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_DNN_new.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e491d",
   "metadata": {},
   "source": [
    "## P4.重新定义一个DNN；\n",
    "### S1.定义；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2309b787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.9432 - accuracy: 0.5012 - val_loss: 0.7068 - val_accuracy: 0.5227\n",
      "Epoch 2/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.8071 - accuracy: 0.5048 - val_loss: 0.6996 - val_accuracy: 0.5242\n",
      "Epoch 3/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.7412 - accuracy: 0.5063 - val_loss: 0.6945 - val_accuracy: 0.5247\n",
      "Epoch 4/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.7107 - accuracy: 0.5097 - val_loss: 0.6926 - val_accuracy: 0.5284\n",
      "Epoch 5/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6979 - accuracy: 0.5163 - val_loss: 0.6916 - val_accuracy: 0.5323\n",
      "Epoch 6/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6931 - accuracy: 0.5245 - val_loss: 0.6910 - val_accuracy: 0.5339\n",
      "Epoch 7/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6916 - accuracy: 0.5324 - val_loss: 0.6908 - val_accuracy: 0.5347\n",
      "Epoch 8/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6910 - accuracy: 0.5343 - val_loss: 0.6908 - val_accuracy: 0.5347\n",
      "Epoch 9/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6909 - accuracy: 0.5345 - val_loss: 0.6907 - val_accuracy: 0.5345\n",
      "Epoch 10/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5345 - val_loss: 0.6907 - val_accuracy: 0.5342\n",
      "Epoch 11/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5345 - val_loss: 0.6909 - val_accuracy: 0.5345\n",
      "Epoch 12/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5345 - val_loss: 0.6908 - val_accuracy: 0.5347\n",
      "Epoch 13/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6908 - accuracy: 0.5344 - val_loss: 0.6906 - val_accuracy: 0.5346\n",
      "Epoch 14/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6907 - accuracy: 0.5344 - val_loss: 0.6905 - val_accuracy: 0.5346\n",
      "Epoch 15/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6906 - accuracy: 0.5344 - val_loss: 0.6897 - val_accuracy: 0.5359\n",
      "Epoch 16/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6901 - accuracy: 0.5355 - val_loss: 0.6889 - val_accuracy: 0.5413\n",
      "Epoch 17/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6893 - accuracy: 0.5384 - val_loss: 0.6879 - val_accuracy: 0.5467\n",
      "Epoch 18/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6880 - accuracy: 0.5400 - val_loss: 0.6972 - val_accuracy: 0.5406\n",
      "Epoch 19/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6837 - accuracy: 0.5382 - val_loss: 0.6827 - val_accuracy: 0.5379\n",
      "Epoch 20/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6809 - accuracy: 0.5422 - val_loss: 0.7130 - val_accuracy: 0.5096\n",
      "Epoch 21/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6786 - accuracy: 0.5462 - val_loss: 0.7211 - val_accuracy: 0.5160\n",
      "Epoch 22/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6765 - accuracy: 0.5520 - val_loss: 0.6775 - val_accuracy: 0.5588\n",
      "Epoch 23/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6734 - accuracy: 0.5590 - val_loss: 0.7365 - val_accuracy: 0.5180\n",
      "Epoch 24/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6703 - accuracy: 0.5695 - val_loss: 0.6613 - val_accuracy: 0.6041\n",
      "Epoch 25/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6660 - accuracy: 0.5804 - val_loss: 0.6772 - val_accuracy: 0.5876\n",
      "Epoch 26/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6618 - accuracy: 0.5917 - val_loss: 0.7637 - val_accuracy: 0.5610\n",
      "Epoch 27/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6559 - accuracy: 0.6037 - val_loss: 0.7751 - val_accuracy: 0.5565\n",
      "Epoch 28/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6523 - accuracy: 0.6121 - val_loss: 0.8685 - val_accuracy: 0.5142\n",
      "Epoch 29/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6479 - accuracy: 0.6189 - val_loss: 0.8579 - val_accuracy: 0.5269\n",
      "Epoch 30/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6396 - accuracy: 0.6314 - val_loss: 0.8739 - val_accuracy: 0.5661\n",
      "Epoch 31/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6315 - accuracy: 0.6424 - val_loss: 1.2283 - val_accuracy: 0.5346\n",
      "Epoch 32/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6246 - accuracy: 0.6523 - val_loss: 0.8504 - val_accuracy: 0.5289\n",
      "Epoch 33/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6130 - accuracy: 0.6671 - val_loss: 0.6899 - val_accuracy: 0.6576\n",
      "Epoch 34/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.6010 - accuracy: 0.6810 - val_loss: 0.7336 - val_accuracy: 0.6482\n",
      "Epoch 35/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5952 - accuracy: 0.6887 - val_loss: 0.7803 - val_accuracy: 0.5931\n",
      "Epoch 36/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5799 - accuracy: 0.7039 - val_loss: 0.5951 - val_accuracy: 0.7305\n",
      "Epoch 37/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5735 - accuracy: 0.7095 - val_loss: 0.8074 - val_accuracy: 0.6672\n",
      "Epoch 38/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5579 - accuracy: 0.7244 - val_loss: 0.7666 - val_accuracy: 0.6813\n",
      "Epoch 39/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5511 - accuracy: 0.7299 - val_loss: 1.8614 - val_accuracy: 0.4333\n",
      "Epoch 40/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5432 - accuracy: 0.7358 - val_loss: 0.9926 - val_accuracy: 0.6215\n",
      "Epoch 41/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5326 - accuracy: 0.7449 - val_loss: 0.7527 - val_accuracy: 0.7175\n",
      "Epoch 42/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5234 - accuracy: 0.7530 - val_loss: 1.3130 - val_accuracy: 0.4927\n",
      "Epoch 43/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5177 - accuracy: 0.7556 - val_loss: 1.6975 - val_accuracy: 0.5668\n",
      "Epoch 44/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5095 - accuracy: 0.7636 - val_loss: 0.7050 - val_accuracy: 0.7556\n",
      "Epoch 45/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.5005 - accuracy: 0.7696 - val_loss: 2.5542 - val_accuracy: 0.5343\n",
      "Epoch 46/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7739 - val_loss: 0.5820 - val_accuracy: 0.8079\n",
      "Epoch 47/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4818 - accuracy: 0.7834 - val_loss: 0.8072 - val_accuracy: 0.6846\n",
      "Epoch 48/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4773 - accuracy: 0.7861 - val_loss: 1.0079 - val_accuracy: 0.6191\n",
      "Epoch 49/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4705 - accuracy: 0.7906 - val_loss: 0.8885 - val_accuracy: 0.6491\n",
      "Epoch 50/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4654 - accuracy: 0.7942 - val_loss: 1.6435 - val_accuracy: 0.5306\n",
      "Epoch 51/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.7990 - val_loss: 1.7228 - val_accuracy: 0.5588\n",
      "Epoch 52/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4521 - accuracy: 0.8032 - val_loss: 0.6055 - val_accuracy: 0.8058\n",
      "Epoch 53/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4484 - accuracy: 0.8052 - val_loss: 2.6938 - val_accuracy: 0.5419\n",
      "Epoch 54/88\n",
      "430/430 [==============================] - 2s 3ms/step - loss: 0.4398 - accuracy: 0.8113 - val_loss: 0.7674 - val_accuracy: 0.7786\n",
      "Epoch 55/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4376 - accuracy: 0.8130 - val_loss: 0.6267 - val_accuracy: 0.8195\n",
      "Epoch 56/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4305 - accuracy: 0.8173 - val_loss: 1.5968 - val_accuracy: 0.6234\n",
      "Epoch 57/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4334 - accuracy: 0.8159 - val_loss: 0.8497 - val_accuracy: 0.7702\n",
      "Epoch 58/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4242 - accuracy: 0.8218 - val_loss: 1.5808 - val_accuracy: 0.6083\n",
      "Epoch 59/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8230 - val_loss: 0.6696 - val_accuracy: 0.8046\n",
      "Epoch 60/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4146 - accuracy: 0.8275 - val_loss: 0.5767 - val_accuracy: 0.8400\n",
      "Epoch 61/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.8320 - val_loss: 0.6158 - val_accuracy: 0.8030\n",
      "Epoch 62/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8296 - val_loss: 0.6854 - val_accuracy: 0.8125\n",
      "Epoch 63/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4080 - accuracy: 0.8307 - val_loss: 1.2767 - val_accuracy: 0.5813\n",
      "Epoch 64/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4020 - accuracy: 0.8347 - val_loss: 0.6990 - val_accuracy: 0.8080\n",
      "Epoch 65/88\n",
      "430/430 [==============================] - 2s 3ms/step - loss: 0.4041 - accuracy: 0.8339 - val_loss: 1.1038 - val_accuracy: 0.5468\n",
      "Epoch 66/88\n",
      "430/430 [==============================] - 2s 3ms/step - loss: 0.3946 - accuracy: 0.8394 - val_loss: 0.7901 - val_accuracy: 0.6812\n",
      "Epoch 67/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.3980 - accuracy: 0.8366 - val_loss: 0.8502 - val_accuracy: 0.6672\n",
      "Epoch 68/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.3904 - accuracy: 0.8413 - val_loss: 1.0894 - val_accuracy: 0.6686\n",
      "Epoch 69/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8426 - val_loss: 1.6937 - val_accuracy: 0.5746\n",
      "Epoch 70/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8453 - val_loss: 1.9887 - val_accuracy: 0.5649\n",
      "Epoch 71/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3819 - accuracy: 0.8458 - val_loss: 0.8124 - val_accuracy: 0.7799\n",
      "Epoch 72/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3783 - accuracy: 0.8479 - val_loss: 1.8477 - val_accuracy: 0.5149\n",
      "Epoch 73/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3795 - accuracy: 0.8483 - val_loss: 0.8668 - val_accuracy: 0.7625\n",
      "Epoch 74/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3760 - accuracy: 0.8486 - val_loss: 0.8056 - val_accuracy: 0.7961\n",
      "Epoch 75/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3721 - accuracy: 0.8510 - val_loss: 0.6678 - val_accuracy: 0.8310\n",
      "Epoch 76/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3693 - accuracy: 0.8535 - val_loss: 3.4183 - val_accuracy: 0.5499\n",
      "Epoch 77/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8541 - val_loss: 0.5812 - val_accuracy: 0.8496\n",
      "Epoch 78/88\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.3666 - accuracy: 0.8542 - val_loss: 0.6988 - val_accuracy: 0.8110\n",
      "Epoch 79/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8528 - val_loss: 0.5678 - val_accuracy: 0.8552\n",
      "Epoch 80/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3647 - accuracy: 0.8556 - val_loss: 0.7240 - val_accuracy: 0.7562\n",
      "Epoch 81/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3597 - accuracy: 0.8583 - val_loss: 0.6024 - val_accuracy: 0.8480\n",
      "Epoch 82/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3617 - accuracy: 0.8566 - val_loss: 2.9852 - val_accuracy: 0.5670\n",
      "Epoch 83/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3581 - accuracy: 0.8589 - val_loss: 0.8474 - val_accuracy: 0.7790\n",
      "Epoch 84/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8610 - val_loss: 2.0396 - val_accuracy: 0.5838\n",
      "Epoch 85/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8631 - val_loss: 0.5539 - val_accuracy: 0.8640\n",
      "Epoch 86/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3518 - accuracy: 0.8621 - val_loss: 2.0952 - val_accuracy: 0.5984\n",
      "Epoch 87/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8628 - val_loss: 3.5527 - val_accuracy: 0.5246\n",
      "Epoch 88/88\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3494 - accuracy: 0.8631 - val_loss: 0.5610 - val_accuracy: 0.8536\n"
     ]
    }
   ],
   "source": [
    "model_DNN_new = keras.models.Sequential()\n",
    "model_DNN_new.add(keras.layers.Flatten(input_shape = [26, 1]))  # flatten层的作用是将28*28维度的输入数据展平成一层，输入层；虽然本就是一维\n",
    "for _ in range(4):\n",
    "    model_DNN_new.add(keras.layers.Dense(26, activation = \"relu\"))\n",
    "    # 隐藏层加入标准化模块加速训练速度，将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1；\n",
    "    model_DNN_new.add(keras.layers.BatchNormalization()) \n",
    "model_DNN_new.add(keras.layers.AlphaDropout(rate=0.5))  # 正则化层；\n",
    "model_DNN_new.add(keras.layers.Dense(len(pd.Series(Y_val_DNN_new).unique()), activation = \"softmax\")) # 输出层别忘。。。\n",
    "model_DNN_new.compile(\n",
    "             loss = \"sparse_categorical_crossentropy\",  # 稀疏分类交叉熵损失函数\n",
    "             optimizer = keras.optimizers.Adam(learning_rate = 0.0002),    # 优化函数为随机梯度下降 ，学习率为0.01\n",
    "             metrics = [\"accuracy\"])                     # 优化指标为准确度\n",
    "# 记录训练历史\n",
    "model_DNN__new_train_history = model_DNN_new.fit(X_train_DNN_new, Y_train_DNN_new,             # 训练数据\n",
    "                                        batch_size = 800,                       # 每一次迭代传入样本；\n",
    "                                        epochs = 88,                           # 训练周期\n",
    "                                        validation_data = (X_val_DNN_new, Y_val_DNN_new),) # 验证集要用；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5127536",
   "metadata": {},
   "source": [
    "### S2.训练结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "130ea4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,j in enumerate(model_DNN__new_train_history.history):\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(4,1,i+1)\n",
    "    if j == \"val_loss\":\n",
    "        plt.grid(True)\n",
    "        plt.plot(range(len(model_DNN__new_train_history.history[j])),model_DNN__new_train_history.history[j],label = j)\n",
    "        plt.gca().set_xlim(0, 80)\n",
    "        plt.gca().set_ylim(0, 20)\n",
    "    else :\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.plot(range(len(model_DNN__new_train_history.history[j])),model_DNN__new_train_history.history[j],label = j)\n",
    "        plt.gca().set_xlim(0, 80)\n",
    "        plt.gca().set_ylim(0, 1.01)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epochs次数\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b04254",
   "metadata": {},
   "source": [
    "### S3.验证集表现；——差强人意\n",
    "- 精准率85%；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5dcde897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2686/2686 [==============================] - 2s 721us/step - loss: 0.5610 - accuracy: 0.8536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5610210299491882, 0.8535816073417664]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DNN_new.evaluate(X_val_DNN_new,Y_val_DNN_new)\n",
    "# model_DNN_new.evaluate(X_test_DNN_new, y_test)# 测试集没有标签无法判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f76de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_proba = model_DNN_new.predict(X_test_DNN_new)\n",
    "# classes_x=np.argmax(X_test_proba,axis=1)\n",
    "# pd.Series(classes_x).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10273082",
   "metadata": {},
   "source": [
    "### S4.将测试集的预测结果也保存到本地；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a0e434d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_DNN_new[\"pred_score_DNN\"] = model_DNN_new.predict(X_test_DNN_new)[:,1]\n",
    "tst_user_item_feats_df_DNN = pd.concat([tst_user_item_feats_df,X_test_DNN_new[\"pred_score_DNN\"]],axis=1)\n",
    "tst_user_item_feats_df_DNN_new = pd.DataFrame(tst_user_item_feats_df_DNN[['user_id', 'click_article_id', 'pred_score_DNN']])\n",
    "tst_user_item_feats_df_DNN_new.columns = ['user_id', 'click_article_id', 'pred_score']\n",
    "tst_user_item_feats_df_DNN_new.to_csv(save_dir + 'dnn_classifier_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afcf9c0",
   "metadata": {},
   "source": [
    "# C4.模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccada6c3",
   "metadata": {},
   "source": [
    "## P1.读取多个模型的排序结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6f08e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别读取在排序阶段和分类阶段各自得到的排序结果；\n",
    "lgb_ranker = pd.read_csv(save_dir + 'lgb_ranker_score.csv')\n",
    "lgb_cls = pd.read_csv(save_dir + 'lgb_classfier_score.csv')\n",
    "dnn_cls = pd.read_csv(save_dir + 'dnn_classifier_score.csv')\n",
    "# 建立融合字典包；\n",
    "rank_model = {'lgb_ranker': lgb_ranker, 'lgb_cls': lgb_cls, 'dnn_cls': dnn_cls}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e4ea9",
   "metadata": {},
   "source": [
    "## P2.融合过程；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d5adf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初步融合的结果已经生成！也可以参考！\n"
     ]
    }
   ],
   "source": [
    "# final_recall[final_recall[\"user_id\"]==200000]\n",
    "# final_recall[final_recall[\"user_id\"]==200000].groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "# 不加DNN的版本；\n",
    "# def get_blend_predict_topk(rank_model, topk=5):\n",
    "#     # 将ranker模型中的分数标准归一化\n",
    "#     rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "#     # 把lgb_classifier结果和lgb_ranker结果归一化后的结果先堆到一起；\n",
    "#     final_recall = rank_model[\"lgb_cls\"].append(rank_model['lgb_ranker'])\n",
    "#     # 堆到一起后，按照用户,文章物品，groupby预测的分数，这里就明白了为什么分数要最终都命名为pred_score；\n",
    "#     final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "#     submit_sequence_result(final_recall, '排序和分类融合',topk=topk, model_name='blend_fuse_model')\n",
    "def get_blend_predict_topk(rank_model, topk=5):\n",
    "    final_recall = rank_model['lgb_cls'].append(rank_model['dnn_cls'])\n",
    "    # 将ranker模型中的分数标准归一化\n",
    "    rank_model['dnn_cls']['pred_score'] = rank_model['dnn_cls']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    # 把lgb_classifier结果和lgb_ranker结果归一化后的结果先堆到一起；\n",
    "    final_recall = rank_model[\"lgb_cls\"].append(rank_model['lgb_ranker'])\n",
    "    # 堆到一起后，按照用户,文章物品，groupby预测的分数，这里就明白了为什么分数要最终都命名为pred_score；\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    submit_sequence_result(final_recall, '排序和分类融合',topk=topk, model_name='blend_fuse_model')\n",
    "get_blend_predict_topk(rank_model)\n",
    "print(\"初步融合的结果已经生成！也可以参考！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ea204",
   "metadata": {},
   "source": [
    "# C5.模型Staking\n",
    "- 思想是将上述两个模型的结果，分数排序，当做新的特征！，再借助另外一个线性模型比如，逻辑回归等进行最终分数输出；\n",
    "- DNN部分就暂时不考虑了；感觉有些过拟合；所以为了避免干扰先不考虑了；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8a280cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取多个模型的交叉验证生成的结果文件\n",
    "# 训练集；上面Ranker模型&Classifier模型交叉验证得到的结果；\n",
    "trn_lgb_ranker_feats = pd.read_csv(save_dir + 'trn_lgb_ranker_feats_result.csv')\n",
    "trn_lgb_cls_feats = pd.read_csv(save_dir + 'trn_lgb_classifier_feats_result.csv')\n",
    "# 测试集；上面Ranker模型&Classifier模型交叉验证得到的结果；\n",
    "tst_lgb_ranker_feats = pd.read_csv(save_dir + 'tst_lgb_ranker_feats_result.csv')\n",
    "tst_lgb_cls_feats = pd.read_csv(save_dir + 'tst_lgb_classifier_feats_result.csv')\n",
    "# 将多个模型输出的特征进行拼接，准备两个拼接的母体，一个测试集的finall_tst_ranker_feats，一个训练集的finall_trn_ranker_feats；\n",
    "# 只留下['user_id', 'click_article_id', 'label']，后续分数和排名往上拼接；\n",
    "# 为啥叫ranker，因为排序主题！！！！！！\n",
    "finall_trn_ranker_feats = trn_lgb_ranker_feats[['user_id', 'click_article_id', 'label']]\n",
    "finall_tst_ranker_feats = tst_lgb_ranker_feats[['user_id', 'click_article_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "05679e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集母体：user_id,click_article_id,label+ pred_score_rank，其中要根据上面定义的融合字典包含的模型和后面的训练测试集顺序相对应；\n",
    "# [*zip(list(rank_model.keys()),[trn_lgb_ranker_feats, trn_lgb_cls_feats])]字典定义的顺序和后面的列表要对应；\n",
    "for model_name,trn_model in [*zip(list(rank_model.keys()),[trn_lgb_ranker_feats, trn_lgb_cls_feats, ])]:\n",
    "    for feat_col in ['pred_score', 'pred_rank']:\n",
    "        col_name = feat_col + '_' + str(model_name)\n",
    "        finall_trn_ranker_feats[col_name] = trn_model[feat_col]\n",
    "for model_name,trn_model in [*zip(list(rank_model.keys()),[tst_lgb_ranker_feats, tst_lgb_cls_feats])]:\n",
    "    for feat_col in ['pred_score', 'pred_rank']:\n",
    "        col_name = feat_col + '_' + str(model_name)\n",
    "        finall_tst_ranker_feats[col_name] = trn_model[feat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2472f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测\n",
    "# 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "feat_cols = ['pred_score_lgb_ranker', 'pred_rank_lgb_ranker', 'pred_score_lgb_cls', 'pred_rank_lgb_cls']\n",
    "trn_x = finall_trn_ranker_feats[feat_cols]\n",
    "trn_y = finall_trn_ranker_feats['label']\n",
    "tst_x = finall_tst_ranker_feats[feat_cols]\n",
    "# 定义模型\n",
    "lr = LogisticRegression(C=1.6,class_weight=\"balanced\",max_iter=200)\n",
    "# 模型训练\n",
    "lr.fit(trn_x, trn_y)\n",
    "# 模型预测\n",
    "finall_tst_ranker_feats['pred_score'] = lr.predict_proba(tst_x)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "aded3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = finall_tst_ranker_feats[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit_sequence_result(rank_results, '配合逻辑回归拟合结果',topk=5, model_name='blend_fuse_model_LogiRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93191f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00629bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f9ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81190a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65448407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b927616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e52848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b8d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10d350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67479f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ef214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa58515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce79843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3d84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
