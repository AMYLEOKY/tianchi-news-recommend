{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d77a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc, os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus']=False #中文\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x) #避免显示问题，设置不显示科学计数法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfeb271",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0839051",
   "metadata": {},
   "source": [
    "- 目录：\n",
    "- 序章：文件相关路径定义&读取源自特征工程后的结果：\n",
    ">  trn_user_item_feats_df——训练用 + tst_user_item_feats_df——测试用；\n",
    "- 预备流程：\n",
    "> 1. 将排序结果处理成规定格式的函数；submit_sequence_result()；\n",
    "——即将user_id,article_id,score返回成user_id,article_id12345的格式；\n",
    "> 2. 将得分score标准化的函数；norm_sim()；\n",
    "——即将ranker的score归一化到0-1区间，以便和classifier预测得到的proba可以融合；\n",
    "- C1.LightGBM-Ranker做排序：——关键环节；\n",
    "> 1. P1.数据准备：——拷一份儿保险；特征列要先制定好，不包含user_id,article_id；\n",
    ">> 1. trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()；\n",
    ">> 2. tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()；\n",
    "> 2. P2.排序模型分组流程：\n",
    ">> 1. trn_user_item_feats_df_rank_model：按照用户排序；其实是针对每一个用户的点击数据信息分组，组内就只包含该用户的几条数据信息；\n",
    ">> 2.group_train每个用户有几条数据变成np.array——其实就是count(label)也就是数据条数；此参数，lgb_ranker里面要用一般都叫做g_train,g_val,g_test；这里为了强化记忆先这么写；\n",
    "> 3. P3. 定义排序器lgb_ranker；\n",
    "> 4. P4. 模型训练；\n",
    ">> 1. 再解释一下ranker里面,fit时参数group的含义：就是该场景下因为是对每一个用户最后点击的一个物品进行预测，基础单位是用户，所以这个时候，每一个用户可以视为一个组；\n",
    "> 5. P5.对测试集tst_user_item_feats_df_rank_model相关部分进行预测得分；\n",
    "> 6. P6.将这里Ranker排序结果保存于本地； 在原始数据集tst_user_item_feats_df上增加predict_score字段；保存到指定路径；lgb_ranker_score.csv——后续模型融合会用；\n",
    "> 7. P7.预测结果按照pred_score重新排序, 调用之前的submit_sequence_result()函数；生成模型标准推荐排序结果保留到本地相应路径；也可以将此结果命名为rank_results_seq_uncross，经过排序处理函数处理成要求格式，保存到本地指定：lgb_ranker_未交叉验证_日期.csv，可以参考结果；\n",
    "> 8. P8.交叉验证看分数；——关键步骤：\n",
    ">> 1. 将用户分为k_fold个样本群体，一份单独用来做验证集，另外k_fold-1份用来做训练；\n",
    ">> 2. 建立模型后，每一轮的训练都会将其中当成验证集的那一部分——这里是按用户分组，所以就是对应用户的点击行为数据，模型根据这一部分会预测出这一部分用户对于每个文章物品的点击分数，排名；\n",
    ">> 3. 最终所有的训练集用户相关都会得到自己的'user_id', 'click_article_id', 'pred_score', 'pred_rank'DF信息，拼接到一起，最终就是训练集+pred_score,rank；将[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']]信息保存到本地指定路径：trn_lgb_ranker_feats_result.csv；后续模型融合要使用；\n",
    ">> 4. 与此同时，交叉验证过程中，每一轮都会模型再预测一下测试及对应数据的分数，最终所有次训练取平均值，最终得到一个测试集上pred_score，\n",
    "保存到本地指定路径：tst_lgb_ranker_feats_result.csv，后续模型融合要使用；相比于上面得到的结果只少了一列label（废话。。。）；\n",
    "> 9. P9.交叉验证后推荐排序结果也可以生成一份文件；保存到指定路径：lgb_ranker_交叉验证后_日期.csv\n",
    "- C2.LightGBM-Classsifier做分类；从预测最终发生点击的概率大小角度来进行一个所谓的排序；\n",
    "> 1. P1.定义一个LGBM分类器；\n",
    "> 2. P2.训练模型；trn_user_item_feats_df_rank_model；\n",
    "> 3. P3.分类器预测结果：对测试集tst_user_item_feats_df_rank_model相关部分进行预测得分；\n",
    "> 4. P4.将分类0-1概率结果保存到本地指定路径；分别取属于正样本1类的概率；\n",
    "> 5. P5.交叉验证使用！思路过程同上面的Ranker环节；\n",
    "本地生成训练集结果：trn_lgb_classifier_feats_result.csv\n",
    "本地生成测试集结果：tst_lgb_classifier_feats_result.csv\n",
    "> 6. P6.交叉验证后推荐排序结果也可以生成一份文件；保存到指定路径：lgb_classifier_交叉验证后_日期.csv\n",
    "- C3. 建设一个DNN神经网络试试；\n",
    "> 1. P1.从训练集中拿出一部分作为验证用；\n",
    "> 2. P2.建立DNN网络；\n",
    ">> \n",
    "### S1.输入层和中间层；\n",
    "- C4.模型融合；\n",
    "> 1. P1.读取多个模型的排序结果文件；\n",
    "> 2. P2.融合模型；\n",
    "> 3. P3.神经网络特征标准化；\n",
    "> 4. P4.重新定义一个DNN；生成新的预测结果保存到本地；\n",
    "- C5.模型得分叠加处理；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb7081",
   "metadata": {},
   "source": [
    "# 序章.文件相关路径定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6252ac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data_path/'            # 其实无用\n",
    "save_path = './feature_project_path/' # 源于上次特征工程结果\n",
    "save_dir = './sequence_result_path/'    # 最终排序结果存放位置\n",
    "offline = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c8974",
   "metadata": {},
   "source": [
    "# 序章.读取特征工程后的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37d39978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新读取数据的时候，发现click_article_id是一个浮点数，所以将其转换成int类型\n",
    "trn_user_item_feats_df = pd.read_csv(save_path + 'trn_user_item_feats_df_final_sample.csv')\n",
    "trn_user_item_feats_df['click_article_id'] = trn_user_item_feats_df['click_article_id'].astype(int)\n",
    "if offline:\n",
    "    val_user_item_feats_df = pd.read_csv(save_path + 'val_user_item_feats_df.csv')\n",
    "    val_user_item_feats_df['click_article_id'] = val_user_item_feats_df['click_article_id'].astype(int)\n",
    "else:\n",
    "    val_user_item_feats_df = None\n",
    "    \n",
    "tst_user_item_feats_df = pd.read_csv(save_path + 'tst_user_item_feats_df_final_sample.csv')\n",
    "tst_user_item_feats_df['click_article_id'] = tst_user_item_feats_df['click_article_id'].astype(int)\n",
    "\n",
    "# 做特征的时候为了方便，给测试集也打上了一个无效的标签，这里直接删掉就行\n",
    "del tst_user_item_feats_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be61b55",
   "metadata": {},
   "source": [
    "# 预备工具I.定义排序结果的函数：\n",
    "- 后面交叉验证用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a4bf99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 返回排序结果处理函数\n",
    "def submit_sequence_result(recall_df, filename, topk=5, model_name=None):\n",
    "    '''\n",
    "    recall_df:已经取出来的user_id,article_id,pred_score数据表df格式；\n",
    "    filename：指定文件叫啥名，比如，未验证的排序，验证好的排序等；\n",
    "    topk；得分前几名；\n",
    "    model_name：用那个模型跑的；\n",
    "    '''\n",
    "    # 按照user_id,score排好序；\n",
    "    recall_df = recall_df.sort_values(by=['user_id', 'pred_score'])\n",
    "    # 按照score值生成排序字段rank的值；\n",
    "    recall_df['rank'] = recall_df.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 判断是不是每个用户都有5篇文章及以上，就是看每个用户下，rank值最大是多少；\n",
    "    tmp = recall_df.groupby('user_id').apply(lambda x: x['rank'].max())\n",
    "    # 保证判断结果为True的时候正常执行；\n",
    "    assert tmp.min() >= topk\n",
    "    # 分数拿掉；\n",
    "    del recall_df['pred_score']\n",
    "    # 把每个用户前五名的文章物品id拿出来设置用户id和rank排序值为联合索引；\n",
    "    # 再使用unstack(-1)将rank排序rank转换成列，reset_index()，恢复索引\n",
    "    submit_df = recall_df[recall_df['rank'] <= topk].set_index(['user_id', 'rank']).unstack(-1).reset_index()\n",
    "    # 取消联合索引user_id、click_article_id、pred_score，MultiIndex形式，改为只留下1，2，3，4，5排序的信息\n",
    "    submit_df.columns = [int(col) if isinstance(col, int) else col for col in submit_df.columns.droplevel(0)]\n",
    "    # 按照提交格式定义列名\n",
    "    submit_df = submit_df.rename(columns={'': 'user_id', 1: 'article_1', 2: 'article_2', 3: 'article_3', 4: 'article_4', 5: 'article_5'})\n",
    "    save_name = save_dir + model_name + '_' + filename + '_'+ datetime.today().strftime('%Y-%m-%d') + '.csv'\n",
    "    submit_df.to_csv(save_name, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1e177",
   "metadata": {},
   "source": [
    "# 预备工具II.排序结果分数归一化函数\n",
    "- 后面模型融合时要用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0ba4fbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排序结果分数归一化函数\n",
    "def norm_sim(sim_df, weight=0.0):\n",
    "    # print(sim_df.head())\n",
    "    min_sim = sim_df.min()\n",
    "    max_sim = sim_df.max()\n",
    "    if max_sim == min_sim:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0)\n",
    "    else:\n",
    "        sim_df = sim_df.apply(lambda sim: 1.0 * (sim - min_sim) / (max_sim - min_sim))\n",
    "\n",
    "    sim_df = sim_df.apply(lambda sim: sim + weight)  # plus one\n",
    "    return sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9a8263",
   "metadata": {},
   "source": [
    "# C1.LightGBM-Ranker做排序！\n",
    "- 1.得到根据召回分数，模型训练预测出的分数score进行排序；\n",
    "- 2.根据分数最终对测试集返回对应的排序结果；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c2106a",
   "metadata": {},
   "source": [
    "## P1.数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1c03898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 复制一份训练测试的数据\n",
    "trn_user_item_feats_df_rank_model = trn_user_item_feats_df.copy()\n",
    "if offline:\n",
    "    val_user_item_feats_df_rank_model = val_user_item_feats_df.copy() \n",
    "tst_user_item_feats_df_rank_model = tst_user_item_feats_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0bc92239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要用到的特征列；\n",
    "lgb_ranker_need_cols = ['sim0', 'time_diff0', 'word_diff0',\n",
    "       'sim_max', 'sim_min', 'sim_sum', 'sim_mean', 'sim_median', 'score',\n",
    "       'rank', 'click_size', 'time_diff_mean', 'active_level_parameter',\n",
    "       'click_environment', 'click_deviceGroup', 'click_os', 'click_country',\n",
    "       'click_region', 'click_referrer_type', 'click_weekday', 'click_hour',\n",
    "       'article_crt_weekday', 'article_crt_hour', 'words_hbo', 'category_id',\n",
    "       'words_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c03dd66",
   "metadata": {},
   "source": [
    "## P2.排序模型分组流程：\n",
    "- 1.trn_user_item_feats_df_rank_model：按照用户排序；\n",
    "- 2.group_train每个用户有几条数据变成np.array——其实就是count(label)也就是数据条数；此参数，lgb_ranker里面要用\n",
    "- 一般都叫做g_train,g_val,g_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dfccf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_item_feats_df_rank_model.sort_values(by=['user_id'], inplace=True)\n",
    "group_train = trn_user_item_feats_df_rank_model.groupby(['user_id'], as_index=False).count()[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678e70f3",
   "metadata": {},
   "source": [
    "## P3.定义LGBM排序器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c080f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1, max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=50, random_state=0, n_jobs= -1) \n",
    "# min_child_weight代表的意思是，儅一個節點下的樣本數小於給定的閾值时，停止生长，会被剪枝；太高会欠拟合，太低容易过拟合；\n",
    "# 这个值定的高，则每个叶子节点越容易被剪枝掉，过高就产生欠拟合状态；过低，好多叶子结点就不会被剪掉，叶子生长过多，容易过拟合；\n",
    "# 树的生长，越浅，叶子包含样本越不纯，被剪枝得厉害，越欠拟合；越深，叶子包含样本越纯，剪枝少，容易过拟合；\n",
    "# colsample_bytree：构建每一弱评估器的子采样比例；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd97a75",
   "metadata": {},
   "source": [
    "## P4.初次训练\n",
    "- 实例化保存结果；lgb_ranker_re\n",
    "- 解释一下参数group的含义：\n",
    "> 1. 就是该场景下因为是对每一个用户最后点击的一个物品进行预测，基础单位是用户，所以这个时候，每一个用户可以视为一个组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31a6dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分测试集和训练集\n",
    "X_train = trn_user_item_feats_df_rank_model[lgb_ranker_need_cols]\n",
    "y_train = trn_user_item_feats_df_rank_model['label']\n",
    "X_test  = tst_user_item_feats_df_rank_model[lgb_ranker_need_cols]# 不推荐这么写，后面你就知道了；还得往回重新粘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "888b8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_ranker_re = lgb_ranker.fit(trn_user_item_feats_df_rank_model[lgb_ranker_need_cols], trn_user_item_feats_df_rank_model['label'], group=group_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02aff26",
   "metadata": {},
   "source": [
    "## P5.模型预测得分；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "be798da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测，\n",
    "# X_test['pred_score'] = lgb_ranker_re.predict(X_test, num_iteration=lgb_ranker_re.best_iteration_) # 省得还得重新网上拼接\n",
    "# 这个pred_score字段名不要瞎改！\n",
    "tst_user_item_feats_df['pred_score'] = lgb_ranker_re.predict(tst_user_item_feats_df[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3b5cb2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>sim0</th>\n",
       "      <th>time_diff0</th>\n",
       "      <th>word_diff0</th>\n",
       "      <th>sim_max</th>\n",
       "      <th>sim_min</th>\n",
       "      <th>sim_sum</th>\n",
       "      <th>sim_mean</th>\n",
       "      <th>sim_median</th>\n",
       "      <th>...</th>\n",
       "      <th>click_referrer_type</th>\n",
       "      <th>click_weekday</th>\n",
       "      <th>click_hour</th>\n",
       "      <th>article_crt_weekday</th>\n",
       "      <th>article_crt_hour</th>\n",
       "      <th>words_hbo</th>\n",
       "      <th>category_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>is_cat_hab</th>\n",
       "      <th>pred_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000</td>\n",
       "      <td>191916</td>\n",
       "      <td>0.809</td>\n",
       "      <td>657135000</td>\n",
       "      <td>46</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.809</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>200.333</td>\n",
       "      <td>309</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200642</td>\n",
       "      <td>191916</td>\n",
       "      <td>0.888</td>\n",
       "      <td>32373000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>177.000</td>\n",
       "      <td>309</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203147</td>\n",
       "      <td>191916</td>\n",
       "      <td>0.703</td>\n",
       "      <td>22131000</td>\n",
       "      <td>46</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.703</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>194.000</td>\n",
       "      <td>309</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>203448</td>\n",
       "      <td>191916</td>\n",
       "      <td>0.888</td>\n",
       "      <td>32373000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>177.000</td>\n",
       "      <td>309</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203655</td>\n",
       "      <td>191916</td>\n",
       "      <td>0.888</td>\n",
       "      <td>32373000</td>\n",
       "      <td>21</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.888</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>165.000</td>\n",
       "      <td>309</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>249872</td>\n",
       "      <td>206624</td>\n",
       "      <td>0.787</td>\n",
       "      <td>6015658000</td>\n",
       "      <td>104</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>224.370</td>\n",
       "      <td>331</td>\n",
       "      <td>201</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>249872</td>\n",
       "      <td>106213</td>\n",
       "      <td>0.730</td>\n",
       "      <td>11025659000</td>\n",
       "      <td>180</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.730</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>224.370</td>\n",
       "      <td>228</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>249933</td>\n",
       "      <td>355995</td>\n",
       "      <td>0.406</td>\n",
       "      <td>167018369000</td>\n",
       "      <td>42</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.406</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>198.156</td>\n",
       "      <td>450</td>\n",
       "      <td>167</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>249961</td>\n",
       "      <td>326992</td>\n",
       "      <td>0.071</td>\n",
       "      <td>1094791000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.071</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>201.333</td>\n",
       "      <td>435</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>249961</td>\n",
       "      <td>327401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1441887000</td>\n",
       "      <td>29</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.401</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>201.333</td>\n",
       "      <td>435</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  click_article_id  sim0    time_diff0  word_diff0  sim_max  \\\n",
       "0        200000            191916 0.809     657135000          46    0.809   \n",
       "1        200642            191916 0.888      32373000          21    0.888   \n",
       "2        203147            191916 0.703      22131000          46    0.703   \n",
       "3        203448            191916 0.888      32373000          21    0.888   \n",
       "4        203655            191916 0.888      32373000          21    0.888   \n",
       "...         ...               ...   ...           ...         ...      ...   \n",
       "999995   249872            206624 0.787    6015658000         104    0.787   \n",
       "999996   249872            106213 0.730   11025659000         180    0.730   \n",
       "999997   249933            355995 0.406  167018369000          42    0.406   \n",
       "999998   249961            326992 0.071    1094791000          14    0.071   \n",
       "999999   249961            327401 0.401    1441887000          29    0.401   \n",
       "\n",
       "        sim_min  sim_sum  sim_mean  sim_median  ...  click_referrer_type  \\\n",
       "0         0.809    0.809     0.809       0.809  ...                    1   \n",
       "1         0.888    0.888     0.888       0.888  ...                    1   \n",
       "2         0.703    0.703     0.703       0.703  ...                    1   \n",
       "3         0.888    0.888     0.888       0.888  ...                    1   \n",
       "4         0.888    0.888     0.888       0.888  ...                    1   \n",
       "...         ...      ...       ...         ...  ...                  ...   \n",
       "999995    0.787    0.787     0.787       0.787  ...                    1   \n",
       "999996    0.730    0.730     0.730       0.730  ...                    1   \n",
       "999997    0.406    0.406     0.406       0.406  ...                    2   \n",
       "999998    0.071    0.071     0.071       0.071  ...                    1   \n",
       "999999    0.401    0.401     0.401       0.401  ...                    1   \n",
       "\n",
       "        click_weekday  click_hour  article_crt_weekday  article_crt_hour  \\\n",
       "0                   2          11                    2                 6   \n",
       "1                   2          11                    2                 6   \n",
       "2                   2           9                    1                15   \n",
       "3                   2           9                    2                 6   \n",
       "4                   2           9                    2                 6   \n",
       "...               ...         ...                  ...               ...   \n",
       "999995              3          16                    2                10   \n",
       "999996              3          16                    2                10   \n",
       "999997              3          17                    3                12   \n",
       "999998              1          15                    3                 4   \n",
       "999999              1          15                    3                 4   \n",
       "\n",
       "        words_hbo  category_id  words_count  is_cat_hab  pred_score  \n",
       "0         200.333          309          156           1       0.886  \n",
       "1         177.000          309          156           0      -1.884  \n",
       "2         194.000          309          156           0      -1.869  \n",
       "3         177.000          309          156           0      -1.884  \n",
       "4         165.000          309          156           0      -1.860  \n",
       "...           ...          ...          ...         ...         ...  \n",
       "999995    224.370          331          201           1      -1.881  \n",
       "999996    224.370          228          125           1      -1.914  \n",
       "999997    198.156          450          167           0      -1.779  \n",
       "999998    201.333          435          148           1      -1.839  \n",
       "999999    201.333          435          191           1      -1.851  \n",
       "\n",
       "[1000000 rows x 30 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_user_item_feats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66d50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_user_item_feats_df[tst_user_item_feats_df[\"user_id\"]==200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374df965",
   "metadata": {},
   "source": [
    "## P6.将这里Ranker排序结果保存于本地；——后续模型融合要用到；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b90d3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_dir + 'lgb_ranker_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4935ba",
   "metadata": {},
   "source": [
    "## P7.预测结果按照pred_score重新排序, 调用之前的submit 函数；生成模型标准排序结果保留到本地相应路径；\n",
    "- 1.模型预测出的结果pred_score和user,article_id,pred_score取出单独拿出来；\n",
    "- 2.文章id字段需要转换成整数型；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7a76814",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_results_seq_uncross = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_seq_uncross['click_article_id'] = rank_results_seq_uncross['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_seq_uncross,'未交叉验证', topk=5, model_name='lgb_ranker') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c66e7f",
   "metadata": {},
   "source": [
    "## P8.使用交叉验证看分数；——关键步骤；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1dd1d87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3723\n",
      "[LightGBM] [Info] Number of data points in the train set: 342100, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3716\n",
      "[LightGBM] [Info] Number of data points in the train set: 342055, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3719\n",
      "[LightGBM] [Info] Number of data points in the train set: 342151, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3723\n",
      "[LightGBM] [Info] Number of data points in the train set: 342093, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3719\n",
      "[LightGBM] [Info] Number of data points in the train set: 342093, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.035770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3717\n",
      "[LightGBM] [Info] Number of data points in the train set: 341998, number of used features: 26\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[2]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[5]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[11]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[12]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[13]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[14]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[15]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[16]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[17]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[18]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[19]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[20]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[21]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[22]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[23]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[24]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[25]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[26]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[27]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[28]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[29]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[30]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[31]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[32]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[33]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[34]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[35]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[36]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[37]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[38]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[39]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[40]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[41]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[42]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[43]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[44]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[45]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[46]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[47]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[48]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[50]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[51]\tvalid_0's ndcg@1: 1\tvalid_0's ndcg@2: 1\tvalid_0's ndcg@3: 1\tvalid_0's ndcg@4: 1\tvalid_0's ndcg@5: 1\n"
     ]
    }
   ],
   "source": [
    "# 原版五折交叉验证，这里的六折交叉是以用户为目标进行六折划分\n",
    "# 这一部分与前面的单独训练和验证是分开的\n",
    "# 交叉验证次数6；k_fold\n",
    "k_fold = 6\n",
    "# 一份训练用的数据copy一下；trn_df\n",
    "trn_df_ranker = trn_user_item_feats_df_rank_model\n",
    "# 把训练集用户单独拿出来；user_ids\n",
    "user_ids_ranker = trn_df_ranker['user_id'].unique()\n",
    "# 定义用户训练分组函数，思想就是每隔n个取一个，[0,6,12......]，[1,7,13......]\n",
    "def get_kfold_users(trn_df_ranker, n = 6):\n",
    "    user_ids_ranker = trn_df_ranker['user_id'].unique()\n",
    "    user_set_ranker = [user_ids_ranker[i::n] for i in range(n)]\n",
    "    return user_set_ranker\n",
    "# 使用分组函数得到几组用户；\n",
    "user_set_ranker = get_kfold_users(trn_df_ranker, n=k_fold)\n",
    "# 生成空列表，为了储存训练集的交叉验证分数、排序结果；\n",
    "score_list_ranker = []\n",
    "# 目标三列拿来，所有user_id,click_article_id,label\n",
    "score_df_ranker = trn_df_ranker[['user_id', 'click_article_id','label']]\n",
    "# 最终测试集分数准备，先都默认用np.zeros打0；sub_preds_points_ranker\n",
    "sub_preds_points_ranker = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "# n折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set_ranker):\n",
    "    '''\n",
    "    n_fold：交叉验证划分用户组的组序号；\n",
    "    valid_user：每组的用户列表array；\n",
    "    '''\n",
    "    # 遍历该组用户时，该组用户的相关数据信息作为测试集用来验证分数，剩下的都是训练集；再啰嗦一遍；\n",
    "    train_idx = trn_df_ranker[~trn_df_ranker['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df_ranker[trn_df_ranker['user_id'].isin(valid_user)]\n",
    "    # 训练集与验证集的用户分组排序：\n",
    "    train_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_train = train_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    # 验证集：\n",
    "    valid_idx.sort_values(by=['user_id'], inplace=True)\n",
    "    g_val = valid_idx.groupby(['user_id'], as_index=False).count()[\"label\"].values\n",
    "    # 定义模型，简单设置一下框架先；\n",
    "    lgb_ranker = lgb.LGBMRanker(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,max_depth=-1, n_estimators=163, \n",
    "                                subsample=0.8, colsample_bytree=0.7, subsample_freq=1,learning_rate=0.01, min_child_weight=50, \n",
    "                                random_state=0, n_jobs= -1, silent = False) \n",
    "    # 训练模型\n",
    "    lgb_ranker_re = lgb_ranker.fit(train_idx[lgb_ranker_need_cols], train_idx['label'], group=g_train,\n",
    "                                   eval_set=[(valid_idx[lgb_ranker_need_cols], valid_idx['label'])], eval_group= [g_val], \n",
    "                                   eval_at=[1, 2, 3, 4, 5], eval_metric=['ndcg', ], early_stopping_rounds=50)\n",
    "    # 对验证集预测结果\n",
    "    # 留一行注释警示作用——为什么pred_score不要重新命名了；\n",
    "    # valid_idx['pred_score_ranker'] = lgb_ranker_re.predict(valid_idx[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)\n",
    "    valid_idx['pred_score'] = lgb_ranker_re.predict(valid_idx[lgb_ranker_need_cols], num_iteration=lgb_ranker_re.best_iteration_)\n",
    "    # num_iteration参数：如果在训练期间启用了早期停止，可以通过best_iteration方式从最佳迭代中获得预测\n",
    "    # 对验证集按照用户，分数排序，并生成排序结果字段rank；\n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接叠加；每一次得到的都是用户平均分组的群体信息\n",
    "    score_list_ranker.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    # 验证集的分数每一条数据，就是user_id-article_id-label-得到一个predict_score，一共k_fold轮，每一轮进行自叠加运算\n",
    "    # k_fold轮以后添加到sub_preds_points：\n",
    "    # 实际记录的是所有k_fold轮交叉验证以后,验证集中每一条就是每一个用户对于一个文章物品的分数（类似于概率），\n",
    "    # 所有轮加起来，最终就是所有训练集所包含的所有每个用户user_id,article_id的pred_score,pred_rank信息；\n",
    "    if not offline:\n",
    "        sub_preds_points_ranker += lgb_ranker_re.predict(tst_user_item_feats_df_rank_model[lgb_ranker_need_cols], lgb_ranker_re.best_iteration_)\n",
    "# k_fold次划分的用户，这回都有了得分信息，把所有的纵向叠加起来合并形成score_df；\n",
    "score_df_ranker_ = pd.concat(score_list_ranker, axis=0)\n",
    "score_df_ranker = score_df_ranker.merge(score_df_ranker_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新信息——pred_score，pred_rank保存，后续会有用\n",
    "# 将交叉验证对于训练集的结果保存下来；——后续模型融合要用；\n",
    "score_df_ranker[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_dir + 'trn_lgb_ranker_feats_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c3878",
   "metadata": {},
   "source": [
    "## P9.测试集，基于先前交叉验证的多次结果进行平均化；本保存到本地一份结果；\n",
    "- 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于模型融合后面的操作。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "284563a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刚才交叉验证环节中，对于最终测试集预测的分数取平均值；为什么要取平均值？——废话再说一遍，泛化验证的思想；\n",
    "# 再按照user_id,分数排序；再按照分数高低，生成排序字段pred_rank；\n",
    "# 测试集由于数据要提交，保持和前面submit_sequence_result函数要求的字段一致；\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds_points_ranker/k_fold\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_dir + 'tst_lgb_ranker_feats_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29f65727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "# 单模型生成提交结果\n",
    "# 与P7提交的结果相比有差别！\n",
    "rank_results_seq_crossed = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_seq_crossed['click_article_id'] = rank_results_seq_crossed['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_seq_crossed,'交叉验证后', topk=5, model_name='lgb_ranker') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31301dd3",
   "metadata": {},
   "source": [
    "# C2.LightGBM-Classsifier做分类！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb102fa",
   "metadata": {},
   "source": [
    "## P1.定义一个LGBM分类器；\n",
    "- 1.得到根据召回分数等特征，模型训练预测出的概率proba进行排序；\n",
    "- 2.根据概率大小最终对测试集返回对应的排序结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7680d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型及参数的定义，随便定义一个\n",
    "lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=63, random_state=0, n_jobs= -1, verbose=10, silent=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46057f",
   "metadata": {},
   "source": [
    "## P2.训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1b47b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 197496, number of negative: 213002\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071776\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000010 seconds, init for row-wise cost 0.036396 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3720\n",
      "[LightGBM] [Info] Number of data points in the train set: 410498, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481113 -> initscore=-0.075583\n",
      "[LightGBM] [Info] Start training from score -0.075583\n",
      "[LightGBM] [Debug] Re-bagging, using 328542 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[LightGBM] [Debug] Re-bagging, using 328102 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[LightGBM] [Debug] Re-bagging, using 328565 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328386 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 328472 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328420 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328461 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328255 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328479 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328309 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328173 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328236 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328053 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328186 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328467 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 328418 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327823 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328419 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328451 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328722 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328343 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328558 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328665 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328766 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328159 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328187 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328388 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328599 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328253 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328019 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328765 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328081 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328557 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328533 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328192 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328468 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328154 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328323 data to train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 7\n",
      "[LightGBM] [Debug] Re-bagging, using 328081 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328551 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328378 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328868 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328342 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328363 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328534 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328819 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 328140 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[LightGBM] [Debug] Re-bagging, using 328630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328348 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328806 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328445 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328271 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328325 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 328458 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328162 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328520 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328413 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327710 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328759 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328484 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328615 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328314 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 328300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328266 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328379 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328700 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328536 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327607 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328398 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328439 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328659 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328449 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328220 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 328498 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327766 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328766 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328167 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 10\n",
      "[LightGBM] [Debug] Re-bagging, using 328147 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328631 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328327 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328310 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 6\n",
      "[LightGBM] [Debug] Re-bagging, using 328607 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328498 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328673 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328697 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328373 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328392 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328652 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328345 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328459 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328593 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328588 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328137 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328725 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328143 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 328368 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328064 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328499 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328053 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328636 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328484 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328692 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328795 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 328265 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328453 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328834 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328244 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 328220 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328527 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328096 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328121 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328393 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[LightGBM] [Debug] Re-bagging, using 328455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328170 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328345 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328267 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328073 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328199 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328525 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328241 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328268 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328279 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328172 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327748 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328476 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328433 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328282 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 328571 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[LightGBM] [Debug] Re-bagging, using 328585 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[LightGBM] [Debug] Re-bagging, using 328465 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328720 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328775 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 5\n",
      "[LightGBM] [Debug] Re-bagging, using 328381 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328570 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 327908 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328719 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[LightGBM] [Debug] Re-bagging, using 328558 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n"
     ]
    }
   ],
   "source": [
    "lgb_Classfication_re = lgb_Classfication.fit(trn_user_item_feats_df_rank_model[lgb_ranker_need_cols], trn_user_item_feats_df_rank_model['label']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dea825",
   "metadata": {},
   "source": [
    "## P3.分类器预测结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc8552c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测，返回概率；\n",
    "tst_user_item_feats_df['pred_score'] = lgb_Classfication_re.predict_proba(tst_user_item_feats_df[lgb_ranker_need_cols])[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a9c91",
   "metadata": {},
   "source": [
    "## P4.将分类0-1概率结果保存到本地指定路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32fd518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将这里的按照分类概率结果结果保存一份\n",
    "tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']].to_csv(save_dir + 'lgb_classfier_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73cd5d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果；\n",
    "rank_results_classifier_uncross = tst_user_item_feats_df[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_classifier_uncross['click_article_id'] = rank_results_classifier_uncross['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_classifier_uncross,'未交叉验证', topk=5, model_name='lgb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a57c",
   "metadata": {},
   "source": [
    "## P5.交叉验证仍然！同时处理测试集的交叉验证分数；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6781fc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177520\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071684\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000014 seconds, init for row-wise cost 0.028860 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3724\n",
      "[LightGBM] [Info] Number of data points in the train set: 342100, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481087 -> initscore=-0.075687\n",
      "[LightGBM] [Info] Start training from score -0.075687\n",
      "[LightGBM] [Debug] Re-bagging, using 273746 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.682493\n",
      "[LightGBM] [Debug] Re-bagging, using 273382 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 14\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.67949\n",
      "[LightGBM] [Debug] Re-bagging, using 273827 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669797\n",
      "[LightGBM] [Debug] Re-bagging, using 273543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660347\n",
      "[LightGBM] [Debug] Re-bagging, using 273882 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.656486\n",
      "[LightGBM] [Debug] Re-bagging, using 273764 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647292\n",
      "[LightGBM] [Debug] Re-bagging, using 273835 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638222\n",
      "[LightGBM] [Debug] Re-bagging, using 273625 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629325\n",
      "[LightGBM] [Debug] Re-bagging, using 273528 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620595\n",
      "[LightGBM] [Debug] Re-bagging, using 273857 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612075\n",
      "[LightGBM] [Debug] Re-bagging, using 273795 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.603714\n",
      "[LightGBM] [Debug] Re-bagging, using 273839 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.595505\n",
      "[LightGBM] [Debug] Re-bagging, using 273410 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587398\n",
      "[LightGBM] [Debug] Re-bagging, using 273497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.579486\n",
      "[LightGBM] [Debug] Re-bagging, using 273313 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.571666\n",
      "[LightGBM] [Debug] Re-bagging, using 273476 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.563985\n",
      "[LightGBM] [Debug] Re-bagging, using 273674 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.561856\n",
      "[LightGBM] [Debug] Re-bagging, using 273583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.554347\n",
      "[LightGBM] [Debug] Re-bagging, using 273130 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.546969\n",
      "[LightGBM] [Debug] Re-bagging, using 273731 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.539718\n",
      "[LightGBM] [Debug] Re-bagging, using 273761 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532592\n",
      "[LightGBM] [Debug] Re-bagging, using 273795 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525587\n",
      "[LightGBM] [Debug] Re-bagging, using 273487 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.518701\n",
      "[LightGBM] [Debug] Re-bagging, using 273894 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.51193\n",
      "[LightGBM] [Debug] Re-bagging, using 273784 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505314\n",
      "[LightGBM] [Debug] Re-bagging, using 274072 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.498766\n",
      "[LightGBM] [Debug] Re-bagging, using 273921 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492326\n",
      "[LightGBM] [Debug] Re-bagging, using 273556 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.485991\n",
      "[LightGBM] [Debug] Re-bagging, using 273518 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.479799\n",
      "[LightGBM] [Debug] Re-bagging, using 273477 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473667\n",
      "[LightGBM] [Debug] Re-bagging, using 273588 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467634\n",
      "[LightGBM] [Debug] Re-bagging, using 273860 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461698\n",
      "[LightGBM] [Debug] Re-bagging, using 273511 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.455855\n",
      "[LightGBM] [Debug] Re-bagging, using 273631 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.45014\n",
      "[LightGBM] [Debug] Re-bagging, using 273539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.444516\n",
      "[LightGBM] [Debug] Re-bagging, using 273231 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.438943\n",
      "[LightGBM] [Debug] Re-bagging, using 274047 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.433493\n",
      "[LightGBM] [Debug] Re-bagging, using 273585 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.42809\n",
      "[LightGBM] [Debug] Re-bagging, using 273781 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.42277\n",
      "[LightGBM] [Debug] Re-bagging, using 273654 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417531\n",
      "[LightGBM] [Debug] Re-bagging, using 274044 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.412372\n",
      "[LightGBM] [Debug] Re-bagging, using 273373 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 273762 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402285\n",
      "[LightGBM] [Debug] Re-bagging, using 273312 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397355\n",
      "[LightGBM] [Debug] Re-bagging, using 273632 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392532\n",
      "[LightGBM] [Debug] Re-bagging, using 273425 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.387746\n",
      "[LightGBM] [Debug] Re-bagging, using 273876 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.38303\n",
      "[LightGBM] [Debug] Re-bagging, using 273649 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.378384\n",
      "[LightGBM] [Debug] Re-bagging, using 273969 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.373805\n",
      "[LightGBM] [Debug] Re-bagging, using 273735 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369293\n",
      "[LightGBM] [Debug] Re-bagging, using 273735 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.364846\n",
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177475\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071733\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000016 seconds, init for row-wise cost 0.032159 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3716\n",
      "[LightGBM] [Info] Number of data points in the train set: 342055, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481151 -> initscore=-0.075433\n",
      "[LightGBM] [Info] Start training from score -0.075433\n",
      "[LightGBM] [Debug] Re-bagging, using 273706 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.68247\n",
      "[LightGBM] [Debug] Re-bagging, using 273344 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.679611\n",
      "[LightGBM] [Debug] Re-bagging, using 273793 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669916\n",
      "[LightGBM] [Debug] Re-bagging, using 273506 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660466\n",
      "[LightGBM] [Debug] Re-bagging, using 273849 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.656633\n",
      "[LightGBM] [Debug] Re-bagging, using 273719 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647445\n",
      "[LightGBM] [Debug] Re-bagging, using 273807 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638373\n",
      "[LightGBM] [Debug] Re-bagging, using 273594 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629473\n",
      "[LightGBM] [Debug] Re-bagging, using 273488 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620741\n",
      "[LightGBM] [Debug] Re-bagging, using 273822 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612227\n",
      "[LightGBM] [Debug] Re-bagging, using 273758 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.603871\n",
      "[LightGBM] [Debug] Re-bagging, using 273801 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.595669\n",
      "[LightGBM] [Debug] Re-bagging, using 273375 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587559\n",
      "[LightGBM] [Debug] Re-bagging, using 273465 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.57965\n",
      "[LightGBM] [Debug] Re-bagging, using 273273 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.571828\n",
      "[LightGBM] [Debug] Re-bagging, using 273438 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564144\n",
      "[LightGBM] [Debug] Re-bagging, using 273641 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.562053\n",
      "[LightGBM] [Debug] Re-bagging, using 273541 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.554541\n",
      "[LightGBM] [Debug] Re-bagging, using 273094 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.547159\n",
      "[LightGBM] [Debug] Re-bagging, using 273694 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.539906\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532777\n",
      "[LightGBM] [Debug] Re-bagging, using 273769 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525769\n",
      "[LightGBM] [Debug] Re-bagging, using 273455 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.51888\n",
      "[LightGBM] [Debug] Re-bagging, using 273859 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.512108\n",
      "[LightGBM] [Debug] Re-bagging, using 273762 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505495\n",
      "[LightGBM] [Debug] Re-bagging, using 274042 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.498945\n",
      "[LightGBM] [Debug] Re-bagging, using 273880 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492502\n",
      "[LightGBM] [Debug] Re-bagging, using 273523 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.486165\n",
      "[LightGBM] [Debug] Re-bagging, using 273476 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.479977\n",
      "[LightGBM] [Debug] Re-bagging, using 273435 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473843\n",
      "[LightGBM] [Debug] Re-bagging, using 273553 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 273823 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461869\n",
      "[LightGBM] [Debug] Re-bagging, using 273475 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.456024\n",
      "[LightGBM] [Debug] Re-bagging, using 273596 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.450312\n",
      "[LightGBM] [Debug] Re-bagging, using 273501 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.444692\n",
      "[LightGBM] [Debug] Re-bagging, using 273191 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.439117\n",
      "[LightGBM] [Debug] Re-bagging, using 274009 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.43367\n",
      "[LightGBM] [Debug] Re-bagging, using 273555 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.428265\n",
      "[LightGBM] [Debug] Re-bagging, using 273745 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.422942\n",
      "[LightGBM] [Debug] Re-bagging, using 273619 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417701\n",
      "[LightGBM] [Debug] Re-bagging, using 274005 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.41254\n",
      "[LightGBM] [Debug] Re-bagging, using 273339 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407456\n",
      "[LightGBM] [Debug] Re-bagging, using 273726 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402449\n",
      "[LightGBM] [Debug] Re-bagging, using 273275 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397516\n",
      "[LightGBM] [Debug] Re-bagging, using 273604 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392694\n",
      "[LightGBM] [Debug] Re-bagging, using 273385 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.387906\n",
      "[LightGBM] [Debug] Re-bagging, using 273836 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.383189\n",
      "[LightGBM] [Debug] Re-bagging, using 273615 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.37854\n",
      "[LightGBM] [Debug] Re-bagging, using 273927 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.37396\n",
      "[LightGBM] [Debug] Re-bagging, using 273700 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369446\n",
      "[LightGBM] [Debug] Re-bagging, using 273696 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.364997\n",
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177571\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071733\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000013 seconds, init for row-wise cost 0.024366 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.030217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3718\n",
      "[LightGBM] [Info] Number of data points in the train set: 342151, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481016 -> initscore=-0.075974\n",
      "[LightGBM] [Info] Start training from score -0.075974\n",
      "[LightGBM] [Debug] Re-bagging, using 273791 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.68252\n",
      "[LightGBM] [Debug] Re-bagging, using 273421 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.679669\n",
      "[LightGBM] [Debug] Re-bagging, using 273867 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669972\n",
      "[LightGBM] [Debug] Re-bagging, using 273587 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660525\n",
      "[LightGBM] [Debug] Re-bagging, using 273918 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 9\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.65682\n",
      "[LightGBM] [Debug] Re-bagging, using 273796 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647623\n",
      "[LightGBM] [Debug] Re-bagging, using 273884 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638548\n",
      "[LightGBM] [Debug] Re-bagging, using 273675 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629645\n",
      "[LightGBM] [Debug] Re-bagging, using 273568 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620909\n",
      "[LightGBM] [Debug] Re-bagging, using 273898 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 6\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612389\n",
      "[LightGBM] [Debug] Re-bagging, using 273832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.604027\n",
      "[LightGBM] [Debug] Re-bagging, using 273874 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.59582\n",
      "[LightGBM] [Debug] Re-bagging, using 273452 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587707\n",
      "[LightGBM] [Debug] Re-bagging, using 273536 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.579795\n",
      "[LightGBM] [Debug] Re-bagging, using 273347 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.57197\n",
      "[LightGBM] [Debug] Re-bagging, using 273501 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564284\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.562196\n",
      "[LightGBM] [Debug] Re-bagging, using 273621 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.554682\n",
      "[LightGBM] [Debug] Re-bagging, using 273173 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.547298\n",
      "[LightGBM] [Debug] Re-bagging, using 273772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.540042\n",
      "[LightGBM] [Debug] Re-bagging, using 273802 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532911\n",
      "[LightGBM] [Debug] Re-bagging, using 273847 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525901\n",
      "[LightGBM] [Debug] Re-bagging, using 273533 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.51901\n",
      "[LightGBM] [Debug] Re-bagging, using 273934 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.512235\n",
      "[LightGBM] [Debug] Re-bagging, using 273838 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505618\n",
      "[LightGBM] [Debug] Re-bagging, using 274113 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.499066\n",
      "[LightGBM] [Debug] Re-bagging, using 273962 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492621\n",
      "[LightGBM] [Debug] Re-bagging, using 273589 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.486282\n",
      "[LightGBM] [Debug] Re-bagging, using 273552 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.480089\n",
      "[LightGBM] [Debug] Re-bagging, using 273516 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473953\n",
      "[LightGBM] [Debug] Re-bagging, using 273633 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467916\n",
      "[LightGBM] [Debug] Re-bagging, using 273900 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461975\n",
      "[LightGBM] [Debug] Re-bagging, using 273543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.456129\n",
      "[LightGBM] [Debug] Re-bagging, using 273670 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.450414\n",
      "[LightGBM] [Debug] Re-bagging, using 273573 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.44479\n",
      "[LightGBM] [Debug] Re-bagging, using 273269 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.439213\n",
      "[LightGBM] [Debug] Re-bagging, using 274087 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.433761\n",
      "[LightGBM] [Debug] Re-bagging, using 273631 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.428355\n",
      "[LightGBM] [Debug] Re-bagging, using 273832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.423031\n",
      "[LightGBM] [Debug] Re-bagging, using 273692 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417789\n",
      "[LightGBM] [Debug] Re-bagging, using 274089 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.412626\n",
      "[LightGBM] [Debug] Re-bagging, using 273411 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407541\n",
      "[LightGBM] [Debug] Re-bagging, using 273803 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402532\n",
      "[LightGBM] [Debug] Re-bagging, using 273357 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397598\n",
      "[LightGBM] [Debug] Re-bagging, using 273682 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392775\n",
      "[LightGBM] [Debug] Re-bagging, using 273469 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.387986\n",
      "[LightGBM] [Debug] Re-bagging, using 273925 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.383267\n",
      "[LightGBM] [Debug] Re-bagging, using 273688 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.378618\n",
      "[LightGBM] [Debug] Re-bagging, using 274010 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.374036\n",
      "[LightGBM] [Debug] Re-bagging, using 273770 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369521\n",
      "[LightGBM] [Debug] Re-bagging, using 273774 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.365071\n",
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177513\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071776\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000018 seconds, init for row-wise cost 0.025562 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.033558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3726\n",
      "[LightGBM] [Info] Number of data points in the train set: 342093, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481097 -> initscore=-0.075647\n",
      "[LightGBM] [Info] Start training from score -0.075647\n",
      "[LightGBM] [Debug] Re-bagging, using 273741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.68249\n",
      "[LightGBM] [Debug] Re-bagging, using 273375 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.679577\n",
      "[LightGBM] [Debug] Re-bagging, using 273821 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669883\n",
      "[LightGBM] [Debug] Re-bagging, using 273539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 6\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660429\n",
      "[LightGBM] [Debug] Re-bagging, using 273873 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.656625\n",
      "[LightGBM] [Debug] Re-bagging, using 273756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647428\n",
      "[LightGBM] [Debug] Re-bagging, using 273839 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638356\n",
      "[LightGBM] [Debug] Re-bagging, using 273618 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629456\n",
      "[LightGBM] [Debug] Re-bagging, using 273520 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620724\n",
      "[LightGBM] [Debug] Re-bagging, using 273851 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612201\n",
      "[LightGBM] [Debug] Re-bagging, using 273786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.603836\n",
      "[LightGBM] [Debug] Re-bagging, using 273832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.595625\n",
      "[LightGBM] [Debug] Re-bagging, using 273408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587515\n",
      "[LightGBM] [Debug] Re-bagging, using 273497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.579598\n",
      "[LightGBM] [Debug] Re-bagging, using 273306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.571776\n",
      "[LightGBM] [Debug] Re-bagging, using 273467 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564093\n",
      "[LightGBM] [Debug] Re-bagging, using 273673 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 11\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.562001\n",
      "[LightGBM] [Debug] Re-bagging, using 273569 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.55449\n",
      "[LightGBM] [Debug] Re-bagging, using 273127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.547109\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.539856\n",
      "[LightGBM] [Debug] Re-bagging, using 273756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532728\n",
      "[LightGBM] [Debug] Re-bagging, using 273798 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525721\n",
      "[LightGBM] [Debug] Re-bagging, using 273486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.518833\n",
      "[LightGBM] [Debug] Re-bagging, using 273881 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.512061\n",
      "[LightGBM] [Debug] Re-bagging, using 273786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505443\n",
      "[LightGBM] [Debug] Re-bagging, using 274071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.498894\n",
      "[LightGBM] [Debug] Re-bagging, using 273902 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492452\n",
      "[LightGBM] [Debug] Re-bagging, using 273543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.486116\n",
      "[LightGBM] [Debug] Re-bagging, using 273514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.479921\n",
      "[LightGBM] [Debug] Re-bagging, using 273469 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473787\n",
      "[LightGBM] [Debug] Re-bagging, using 273583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467753\n",
      "[LightGBM] [Debug] Re-bagging, using 273858 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461814\n",
      "[LightGBM] [Debug] Re-bagging, using 273502 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.45597\n",
      "[LightGBM] [Debug] Re-bagging, using 273630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.450255\n",
      "[LightGBM] [Debug] Re-bagging, using 273532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.444629\n",
      "[LightGBM] [Debug] Re-bagging, using 273227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.439055\n",
      "[LightGBM] [Debug] Re-bagging, using 274038 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.433601\n",
      "[LightGBM] [Debug] Re-bagging, using 273580 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.428197\n",
      "[LightGBM] [Debug] Re-bagging, using 273779 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.422875\n",
      "[LightGBM] [Debug] Re-bagging, using 273651 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417635\n",
      "[LightGBM] [Debug] Re-bagging, using 274032 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.412474\n",
      "[LightGBM] [Debug] Re-bagging, using 273370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407391\n",
      "[LightGBM] [Debug] Re-bagging, using 273753 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402385\n",
      "[LightGBM] [Debug] Re-bagging, using 273311 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 273629 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392626\n",
      "[LightGBM] [Debug] Re-bagging, using 273422 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.387839\n",
      "[LightGBM] [Debug] Re-bagging, using 273872 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.383122\n",
      "[LightGBM] [Debug] Re-bagging, using 273647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.378475\n",
      "[LightGBM] [Debug] Re-bagging, using 273954 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.373895\n",
      "[LightGBM] [Debug] Re-bagging, using 273728 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369381\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.364933\n",
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177513\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071640\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000015 seconds, init for row-wise cost 0.029017 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036426 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3723\n",
      "[LightGBM] [Info] Number of data points in the train set: 342093, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481097 -> initscore=-0.075647\n",
      "[LightGBM] [Info] Start training from score -0.075647\n",
      "[LightGBM] [Debug] Re-bagging, using 273741 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.68249\n",
      "[LightGBM] [Debug] Re-bagging, using 273375 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.67968\n",
      "[LightGBM] [Debug] Re-bagging, using 273821 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669983\n",
      "[LightGBM] [Debug] Re-bagging, using 273539 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 5\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660518\n",
      "[LightGBM] [Debug] Re-bagging, using 273873 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.656683\n",
      "[LightGBM] [Debug] Re-bagging, using 273756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647474\n",
      "[LightGBM] [Debug] Re-bagging, using 273839 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638401\n",
      "[LightGBM] [Debug] Re-bagging, using 273618 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629501\n",
      "[LightGBM] [Debug] Re-bagging, using 273520 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620768\n",
      "[LightGBM] [Debug] Re-bagging, using 273851 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612236\n",
      "[LightGBM] [Debug] Re-bagging, using 273786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.603862\n",
      "[LightGBM] [Debug] Re-bagging, using 273832 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.595641\n",
      "[LightGBM] [Debug] Re-bagging, using 273408 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587532\n",
      "[LightGBM] [Debug] Re-bagging, using 273497 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.579605\n",
      "[LightGBM] [Debug] Re-bagging, using 273306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.571784\n",
      "[LightGBM] [Debug] Re-bagging, using 273467 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.564101\n",
      "[LightGBM] [Debug] Re-bagging, using 273673 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.561994\n",
      "[LightGBM] [Debug] Re-bagging, using 273569 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.554483\n",
      "[LightGBM] [Debug] Re-bagging, using 273127 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.547103\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.53985\n",
      "[LightGBM] [Debug] Re-bagging, using 273756 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532722\n",
      "[LightGBM] [Debug] Re-bagging, using 273798 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525716\n",
      "[LightGBM] [Debug] Re-bagging, using 273486 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.518828\n",
      "[LightGBM] [Debug] Re-bagging, using 273881 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.512056\n",
      "[LightGBM] [Debug] Re-bagging, using 273786 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505429\n",
      "[LightGBM] [Debug] Re-bagging, using 274071 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.49888\n",
      "[LightGBM] [Debug] Re-bagging, using 273902 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492439\n",
      "[LightGBM] [Debug] Re-bagging, using 273543 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.486103\n",
      "[LightGBM] [Debug] Re-bagging, using 273514 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 5\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.4799\n",
      "[LightGBM] [Debug] Re-bagging, using 273469 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473767\n",
      "[LightGBM] [Debug] Re-bagging, using 273583 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467733\n",
      "[LightGBM] [Debug] Re-bagging, using 273858 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461795\n",
      "[LightGBM] [Debug] Re-bagging, using 273502 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.455952\n",
      "[LightGBM] [Debug] Re-bagging, using 273630 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.450229\n",
      "[LightGBM] [Debug] Re-bagging, using 273532 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.444596\n",
      "[LightGBM] [Debug] Re-bagging, using 273227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.439022\n",
      "[LightGBM] [Debug] Re-bagging, using 274038 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.433562\n",
      "[LightGBM] [Debug] Re-bagging, using 273580 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.428159\n",
      "[LightGBM] [Debug] Re-bagging, using 273779 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.422838\n",
      "[LightGBM] [Debug] Re-bagging, using 273651 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417599\n",
      "[LightGBM] [Debug] Re-bagging, using 274032 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.412439\n",
      "[LightGBM] [Debug] Re-bagging, using 273370 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407357\n",
      "[LightGBM] [Debug] Re-bagging, using 273753 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402351\n",
      "[LightGBM] [Debug] Re-bagging, using 273311 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397419\n",
      "[LightGBM] [Debug] Re-bagging, using 273629 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392588\n",
      "[LightGBM] [Debug] Re-bagging, using 273422 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.387801\n",
      "[LightGBM] [Debug] Re-bagging, using 273872 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.383085\n",
      "[LightGBM] [Debug] Re-bagging, using 273647 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.378438\n",
      "[LightGBM] [Debug] Re-bagging, using 273954 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.373859\n",
      "[LightGBM] [Debug] Re-bagging, using 273728 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369346\n",
      "[LightGBM] [Debug] Re-bagging, using 273724 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.364899\n",
      "[LightGBM] [Info] Number of positive: 164580, number of negative: 177418\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.071741\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000197 seconds, init for row-wise cost 0.031831 seconds\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3719\n",
      "[LightGBM] [Info] Number of data points in the train set: 341998, number of used features: 26\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.481231 -> initscore=-0.075112\n",
      "[LightGBM] [Info] Start training from score -0.075112\n",
      "[LightGBM] [Debug] Re-bagging, using 273662 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[1]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.682441\n",
      "[LightGBM] [Debug] Re-bagging, using 273292 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 13\n",
      "[2]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.679444\n",
      "[LightGBM] [Debug] Re-bagging, using 273750 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 2 and depth = 1\n",
      "[3]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.669752\n",
      "[LightGBM] [Debug] Re-bagging, using 273459 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 6\n",
      "[4]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.660302\n",
      "[LightGBM] [Debug] Re-bagging, using 273796 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 8\n",
      "[5]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.65644\n",
      "[LightGBM] [Debug] Re-bagging, using 273674 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 5\n",
      "[6]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.647245\n",
      "[LightGBM] [Debug] Re-bagging, using 273763 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[7]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.638177\n",
      "[LightGBM] [Debug] Re-bagging, using 273540 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[8]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.629281\n",
      "[LightGBM] [Debug] Re-bagging, using 273446 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[9]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.620552\n",
      "[LightGBM] [Debug] Re-bagging, using 273787 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 5\n",
      "[10]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.612031\n",
      "[LightGBM] [Debug] Re-bagging, using 273713 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[11]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.603669\n",
      "[LightGBM] [Debug] Re-bagging, using 273738 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[12]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.595461\n",
      "[LightGBM] [Debug] Re-bagging, using 273336 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[13]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.587354\n",
      "[LightGBM] [Debug] Re-bagging, using 273414 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[14]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.579439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Debug] Re-bagging, using 273237 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[15]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.571621\n",
      "[LightGBM] [Debug] Re-bagging, using 273383 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[16]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.563941\n",
      "[LightGBM] [Debug] Re-bagging, using 273607 data to train\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 31 and depth = 12\n",
      "[17]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.561815\n",
      "[LightGBM] [Debug] Re-bagging, using 273493 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[18]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.554307\n",
      "[LightGBM] [Debug] Re-bagging, using 273051 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[19]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.54693\n",
      "[LightGBM] [Debug] Re-bagging, using 273638 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[20]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.53968\n",
      "[LightGBM] [Debug] Re-bagging, using 273690 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[21]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.532555\n",
      "[LightGBM] [Debug] Re-bagging, using 273739 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[22]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.525551\n",
      "[LightGBM] [Debug] Re-bagging, using 273387 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[23]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.518666\n",
      "[LightGBM] [Debug] Re-bagging, using 273836 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[24]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.511896\n",
      "[LightGBM] [Debug] Re-bagging, using 273686 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 6\n",
      "[25]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.505279\n",
      "[LightGBM] [Debug] Re-bagging, using 273995 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[26]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.498732\n",
      "[LightGBM] [Debug] Re-bagging, using 273851 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[27]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.492293\n",
      "[LightGBM] [Debug] Re-bagging, using 273464 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[28]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.485959\n",
      "[LightGBM] [Debug] Re-bagging, using 273440 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[29]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.479766\n",
      "[LightGBM] [Debug] Re-bagging, using 273389 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[30]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.473635\n",
      "[LightGBM] [Debug] Re-bagging, using 273504 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[31]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.467603\n",
      "[LightGBM] [Debug] Re-bagging, using 273772 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[32]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.461667\n",
      "[LightGBM] [Debug] Re-bagging, using 273427 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[33]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.455825\n",
      "[LightGBM] [Debug] Re-bagging, using 273552 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[34]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.450111\n",
      "[LightGBM] [Debug] Re-bagging, using 273481 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[35]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.444486\n",
      "[LightGBM] [Debug] Re-bagging, using 273138 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[36]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.438914\n",
      "[LightGBM] [Debug] Re-bagging, using 273971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 5\n",
      "[37]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.433462\n",
      "[LightGBM] [Debug] Re-bagging, using 273468 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[38]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.42806\n",
      "[LightGBM] [Debug] Re-bagging, using 273722 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[39]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.422741\n",
      "[LightGBM] [Debug] Re-bagging, using 273559 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[40]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.417503\n",
      "[LightGBM] [Debug] Re-bagging, using 273971 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[41]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.412344\n",
      "[LightGBM] [Debug] Re-bagging, using 273283 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[42]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.407263\n",
      "[LightGBM] [Debug] Re-bagging, using 273687 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[43]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.402259\n",
      "[LightGBM] [Debug] Re-bagging, using 273218 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[44]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.397329\n",
      "[LightGBM] [Debug] Re-bagging, using 273572 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 5\n",
      "[45]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.392505\n",
      "[LightGBM] [Debug] Re-bagging, using 273343 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[46]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.38772\n",
      "[LightGBM] [Debug] Re-bagging, using 273784 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[47]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.383005\n",
      "[LightGBM] [Debug] Re-bagging, using 273596 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[48]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.378359\n",
      "[LightGBM] [Debug] Re-bagging, using 273846 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[49]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.373781\n",
      "[LightGBM] [Debug] Re-bagging, using 273681 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[50]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.369269\n",
      "[LightGBM] [Debug] Re-bagging, using 273643 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 3 and depth = 2\n",
      "[51]\tvalid_0's auc: 1\tvalid_0's binary_logloss: 0.364823\n"
     ]
    }
   ],
   "source": [
    "# 交叉验证次数6；k_fold\n",
    "k_fold = 6\n",
    "# 一份训练用的数据copy一下；\n",
    "trn_df_classifier = trn_user_item_feats_df_rank_model\n",
    "# 把训练集用户单独拿出来；user_ids\n",
    "user_ids_classifier = trn_df_classifier['user_id'].unique()\n",
    "#  与前面排序阶段是类似的，这里函数不再重新说明\n",
    "def get_kfold_users(trn_df, n = 6):\n",
    "    user_ids_classifier = trn_df_classifier['user_id'].unique()\n",
    "    user_set_classifier = [user_ids_classifier[i::n] for i in range(n)]\n",
    "    return user_set_classifier\n",
    "user_set_classifier = get_kfold_users(trn_df_classifier, n=k_fold)\n",
    "# 生成空列表，为了储存交叉验证分数；\n",
    "score_list_classifier = []\n",
    "score_df_classifier = trn_df_classifier[['user_id', 'click_article_id', 'label']]\n",
    "# 定义测试集分类器分数收集数组\n",
    "sub_preds_points_classifier = np.zeros(tst_user_item_feats_df_rank_model.shape[0])\n",
    "# 五折交叉验证，并将中间结果保存用于staking\n",
    "for n_fold, valid_user in enumerate(user_set_classifier):\n",
    "    train_idx = trn_df_classifier[~trn_df_classifier['user_id'].isin(valid_user)] # add slide user\n",
    "    valid_idx = trn_df_classifier[trn_df_classifier['user_id'].isin(valid_user)]\n",
    "    \n",
    "    # 模型及参数的定义\n",
    "    lgb_Classfication = lgb.LGBMClassifier(boosting_type='gbdt', num_leaves=31, reg_alpha=0.0, reg_lambda=1,\n",
    "                            max_depth=-1, n_estimators=163, subsample=0.8, colsample_bytree=0.7, subsample_freq=1,\n",
    "                            learning_rate=0.01, min_child_weight=52, random_state=0, n_jobs= 16, verbose=10)  \n",
    "    # 训练模型\n",
    "    lgb_Classfication_re = lgb_Classfication.fit(train_idx[lgb_ranker_need_cols], train_idx['label'],eval_set=[(valid_idx[lgb_ranker_need_cols], valid_idx['label'])], \n",
    "                          eval_metric=['auc', ],early_stopping_rounds=50, )\n",
    "    \n",
    "    # 预测验证集结果\n",
    "    valid_idx['pred_score'] = lgb_Classfication_re.predict_proba(valid_idx[lgb_ranker_need_cols], \n",
    "                                                              num_iteration=lgb_Classfication.best_iteration_)[:,1]\n",
    "    valid_idx.sort_values(by=['user_id', 'pred_score'])\n",
    "    valid_idx['pred_rank'] = valid_idx.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "    # 将验证集的预测结果放到一个列表中，后面进行拼接\n",
    "    score_list_classifier.append(valid_idx[['user_id', 'click_article_id', 'pred_score', 'pred_rank']])\n",
    "    # 如果是线上测试，需要计算每次交叉验证的结果相加，最后求平均\n",
    "    if not offline:\n",
    "        sub_preds_points_classifier += lgb_Classfication.predict_proba(tst_user_item_feats_df_rank_model[lgb_ranker_need_cols], \n",
    "                                                     num_iteration=lgb_Classfication_re.best_iteration_)[:,1]\n",
    "score_df_classifier_ = pd.concat(score_list_classifier, axis=0)\n",
    "score_df_classifier = score_df_classifier.merge(score_df_classifier_, how='left', on=['user_id', 'click_article_id'])\n",
    "# 保存训练集交叉验证产生的新特征\n",
    "score_df_classifier[['user_id', 'click_article_id', 'pred_score', 'pred_rank', 'label']].to_csv(save_dir + 'trn_lgb_classifier_feats_result.csv', index=False)\n",
    "\n",
    "\n",
    "# 测试集的预测结果，多次交叉验证求平均,将预测的score和对应的rank特征保存，可以用于后面的staking，这里还可以构造其他更多的特征\n",
    "tst_user_item_feats_df_rank_model['pred_score'] = sub_preds_points_classifier / k_fold\n",
    "tst_user_item_feats_df_rank_model.sort_values(by=['user_id', 'pred_score'])\n",
    "tst_user_item_feats_df_rank_model['pred_rank'] = tst_user_item_feats_df_rank_model.groupby(['user_id'])['pred_score'].rank(ascending=False, method='first')\n",
    "\n",
    "# 保存测试集交叉验证的新特征\n",
    "tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score', 'pred_rank']].to_csv(save_dir + 'tst_lgb_classifier_feats_result.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68e3cf",
   "metadata": {},
   "source": [
    "## P6.再生成结果到本地！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2f91d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再次预测结果重新排序, 及生成提交结果\n",
    "rank_results_classifier_crossed = tst_user_item_feats_df_rank_model[['user_id', 'click_article_id', 'pred_score']]\n",
    "rank_results_classifier_crossed['click_article_id'] = rank_results_classifier_crossed['click_article_id'].astype(int)\n",
    "submit_sequence_result(rank_results_classifier_crossed,'交叉验证后', topk=5, model_name='lgb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b48cd7",
   "metadata": {},
   "source": [
    "# C3.建设一个DNN神经网络试试；\n",
    "利用keras中的DNN建立一个神经网络看一下结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "726a5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f07dd2",
   "metadata": {},
   "source": [
    "## P1.从训练集中拿出一部分作为验证用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf284090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((287348, 26), (287348,), (123150, 26), (123150,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "X_need_train = trn_user_item_feats_df_rank_model[lgb_ranker_need_cols]\n",
    "y_need_train = trn_user_item_feats_df_rank_model['label']\n",
    "# y_need_train = to_categorical(trn_user_item_feats_df_rank_model['label'])# Tensor要转一下\n",
    "X_train_dnn, X_val_dnn, y_train_dnn, y_val_dnn = train_test_split(X_need_train,y_need_train,test_size=0.3,random_state=0)\n",
    "X_train_dnn.shape,y_train_dnn.shape,X_val_dnn.shape,y_val_dnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80bef1",
   "metadata": {},
   "source": [
    "## P2.建立DNN网络；\n",
    "### S1.输入层和中间层；\n",
    "- 先设置三层隐藏层，每一层10个神经元；激活函数选用relu；\n",
    "- 每一层隐藏层后面加一个标准化层；\n",
    "- 最终加一个Alpha正则化层；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55851fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个DNN\n",
    "model_DNN = keras.models.Sequential()\n",
    "model_DNN.add(keras.layers.Flatten(input_shape = [26, 1]))  # flatten层的作用是将28*28维度的输入数据展平成一层，输入层；虽然本就是一维\n",
    "for _ in range(4):\n",
    "    # 隐藏层的激活函数都选用relu，如果选用selu自带归一化功能；\n",
    "    model_DNN.add(keras.layers.Dense(30, activation = \"relu\"))\n",
    "    # 隐藏层加入标准化模块加速训练速度，将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1；\n",
    "    model_DNN.add(keras.layers.BatchNormalization()) \n",
    "model_DNN.add(keras.layers.AlphaDropout(rate=0.5))  # 正则化层；\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1cd26",
   "metadata": {},
   "source": [
    "### S2.输出层；\n",
    "- len(pd.Series(y_val_dnn).unique())这样写就不用了写2了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3a20ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 30)                810       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 30)                120       \n",
      "_________________________________________________________________\n",
      "alpha_dropout (AlphaDropout) (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 62        \n",
      "=================================================================\n",
      "Total params: 4,142\n",
      "Trainable params: 3,902\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_DNN.add(keras.layers.Dense(len(pd.Series(y_val_dnn).unique()), activation = \"softmax\")) \n",
    "model_DNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd7b52a",
   "metadata": {},
   "source": [
    "## P2.定义模型训练器，训练数据；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b6c498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 3s 9ms/step - loss: 0.8514 - accuracy: 0.5596 - val_loss: 0.6268 - val_accuracy: 0.5029\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.7708 - accuracy: 0.5949 - val_loss: 0.6099 - val_accuracy: 0.5086\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.7401 - accuracy: 0.6073 - val_loss: 0.5890 - val_accuracy: 0.5242\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.7147 - accuracy: 0.6152 - val_loss: 0.5675 - val_accuracy: 0.6765\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6976 - accuracy: 0.6173 - val_loss: 0.5789 - val_accuracy: 0.6782\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6854 - accuracy: 0.6178 - val_loss: 0.6045 - val_accuracy: 0.6726\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6745 - accuracy: 0.6213 - val_loss: 0.6201 - val_accuracy: 0.6782\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6634 - accuracy: 0.6239 - val_loss: 0.6632 - val_accuracy: 0.6782\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6535 - accuracy: 0.6253 - val_loss: 0.6556 - val_accuracy: 0.6782\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6429 - accuracy: 0.6284 - val_loss: 0.6573 - val_accuracy: 0.6782\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6358 - accuracy: 0.6294 - val_loss: 0.6349 - val_accuracy: 0.6782\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6288 - accuracy: 0.6308 - val_loss: 0.6306 - val_accuracy: 0.6782\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6274 - accuracy: 0.6274 - val_loss: 0.5977 - val_accuracy: 0.6782\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6199 - accuracy: 0.6315 - val_loss: 0.6082 - val_accuracy: 0.6782\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6151 - accuracy: 0.6332 - val_loss: 0.6300 - val_accuracy: 0.6782\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6104 - accuracy: 0.6356 - val_loss: 0.6332 - val_accuracy: 0.6782\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6061 - accuracy: 0.6363 - val_loss: 0.6367 - val_accuracy: 0.6782\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.6015 - accuracy: 0.6391 - val_loss: 0.6341 - val_accuracy: 0.6782\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.5998 - accuracy: 0.6398 - val_loss: 0.6290 - val_accuracy: 0.6782\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 1s 7ms/step - loss: 0.5969 - accuracy: 0.6407 - val_loss: 0.6219 - val_accuracy: 0.6782\n"
     ]
    }
   ],
   "source": [
    "# # 定义训练历史；\n",
    "# train_history = model_DNN.fit(X_need_train, y_need_train, batch_size = 1000, epochs=6)\n",
    "# history_frame = pd.DataFrame(train_history.history)\n",
    "# history_frame['epoch'] = train_history.epoch\n",
    "# history_frame['epoch'] = history_frame['epoch'] + 1\n",
    "# def plot_history(hist):\n",
    "#     plt.figure(figsize=(10,5))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.plot(hist['epoch'], hist['accuracy'],label='accuracy')\n",
    "#     plt.legend()\n",
    "# plot_history(history_frame)    \n",
    "model_DNN.compile(\n",
    "             loss = \"sparse_categorical_crossentropy\",  # 稀疏分类交叉熵损失函数\n",
    "             optimizer = keras.optimizers.Adam(learning_rate = 0.0001),    # 优化函数为随机梯度下降 ，学习率为0.01\n",
    "             metrics = [\"accuracy\"])                     # 优化指标为准确度\n",
    "# 记录训练历史\n",
    "model_DNN_train_history = model_DNN.fit(X_train_dnn, y_train_dnn,             # 训练数据\n",
    "                                        batch_size=3000,                       # 每一次迭代传入5000样本；\n",
    "                                        epochs = 20,                           # 训练周期，数据分为10次进行训练\n",
    "                                        validation_data = (X_val_dnn, y_val_dnn),) # 验证集要用；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbe90d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,j in enumerate(model_DNN_train_history.history):\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(4,1,i+1)\n",
    "    plt.plot(range(len(model_DNN_train_history.history[j])),model_DNN_train_history.history[j],label = j)\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_xlim(0, 12)\n",
    "    plt.gca().set_ylim(0, 2)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epochs次数\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587c590",
   "metadata": {},
   "source": [
    "- 可以看出效果很差，损失基本不变；\n",
    "- 尝试将原来特征都进行标准化；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe87c3f",
   "metadata": {},
   "source": [
    "## P3.神经网络特征标准化；\n",
    "- 所有数值型特征都标准化处理；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b5c5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "need_feature = [\"sim0\",\"time_diff0\",\"word_diff0\",\"sim_max\",\"sim_min\",\"sim_sum\",\"sim_mean\",\"sim_median\",\"score\",\"words_hbo\",\"words_count\"]\n",
    "mm_Scaler = MinMaxScaler()\n",
    "X_need_feature = mm_Scaler.fit_transform(X_train[need_feature])\n",
    "X_train_DNN_need_feature = pd.DataFrame(X_need_feature,columns = [(str(i) + \"_new\") for i in X_train[need_feature].columns])\n",
    "X_train_DNN_new = pd.concat([X_train_DNN_need_feature,X_train.drop(need_feature,axis=1)],axis=1)\n",
    "# 测试集亦如此\n",
    "X_test_need_feature = mm_Scaler.fit_transform(X_test[need_feature])\n",
    "X_test_DNN_need_feature = pd.DataFrame(X_test_need_feature,columns = [(str(i) + \"_new\") for i in X_test[need_feature].columns])\n",
    "X_test_DNN_new = pd.concat([X_test_DNN_need_feature,X_test.drop(need_feature,axis=1)],axis=1)\n",
    "X_train_DNN_new,X_val_DNN_new,Y_train_DNN_new,Y_val_DNN_new = train_test_split(X_train_DNN_new,y_train,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5579eac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((328398, 26), (410498,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_DNN_new.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e491d",
   "metadata": {},
   "source": [
    "## P4.重新定义一个DNN；\n",
    "### S1.定义；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2309b787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "470/470 [==============================] - 3s 3ms/step - loss: 0.8622 - accuracy: 0.5042 - val_loss: 0.7034 - val_accuracy: 0.5266\n",
      "Epoch 2/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.7226 - accuracy: 0.5348 - val_loss: 0.7901 - val_accuracy: 0.5179\n",
      "Epoch 3/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.6269 - accuracy: 0.6298 - val_loss: 0.8319 - val_accuracy: 0.5334\n",
      "Epoch 4/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.6030 - accuracy: 0.6520 - val_loss: 0.8612 - val_accuracy: 0.5335\n",
      "Epoch 5/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5948 - accuracy: 0.6587 - val_loss: 0.6722 - val_accuracy: 0.6682\n",
      "Epoch 6/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5876 - accuracy: 0.6643 - val_loss: 0.8350 - val_accuracy: 0.5733\n",
      "Epoch 7/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.6668 - val_loss: 0.7002 - val_accuracy: 0.6702\n",
      "Epoch 8/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5814 - accuracy: 0.6689 - val_loss: 0.7205 - val_accuracy: 0.6719\n",
      "Epoch 9/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5791 - accuracy: 0.6713 - val_loss: 0.7568 - val_accuracy: 0.6692\n",
      "Epoch 10/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5773 - accuracy: 0.6720 - val_loss: 0.7752 - val_accuracy: 0.6601\n",
      "Epoch 11/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.6731 - val_loss: 0.7609 - val_accuracy: 0.6724\n",
      "Epoch 12/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5750 - accuracy: 0.6732 - val_loss: 0.7651 - val_accuracy: 0.6728\n",
      "Epoch 13/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5730 - accuracy: 0.6739 - val_loss: 0.7715 - val_accuracy: 0.6724\n",
      "Epoch 14/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5719 - accuracy: 0.6742 - val_loss: 0.8626 - val_accuracy: 0.6674\n",
      "Epoch 15/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.6747 - val_loss: 0.8020 - val_accuracy: 0.6728\n",
      "Epoch 16/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5708 - accuracy: 0.6742 - val_loss: 0.8385 - val_accuracy: 0.6707\n",
      "Epoch 17/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5700 - accuracy: 0.6747 - val_loss: 0.8422 - val_accuracy: 0.6717\n",
      "Epoch 18/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5690 - accuracy: 0.6749 - val_loss: 0.8610 - val_accuracy: 0.6716\n",
      "Epoch 19/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5691 - accuracy: 0.6748 - val_loss: 0.8442 - val_accuracy: 0.6728\n",
      "Epoch 20/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5681 - accuracy: 0.6751 - val_loss: 0.8867 - val_accuracy: 0.6725\n",
      "Epoch 21/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5681 - accuracy: 0.6751 - val_loss: 0.8631 - val_accuracy: 0.6731\n",
      "Epoch 22/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5675 - accuracy: 0.6752 - val_loss: 0.8888 - val_accuracy: 0.6728\n",
      "Epoch 23/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5673 - accuracy: 0.6754 - val_loss: 0.9056 - val_accuracy: 0.6727\n",
      "Epoch 24/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.6757 - val_loss: 0.8951 - val_accuracy: 0.6729\n",
      "Epoch 25/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.6756 - val_loss: 0.9208 - val_accuracy: 0.6719\n",
      "Epoch 26/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5669 - accuracy: 0.6756 - val_loss: 1.0960 - val_accuracy: 0.5438\n",
      "Epoch 27/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5664 - accuracy: 0.6758 - val_loss: 1.2362 - val_accuracy: 0.5413\n",
      "Epoch 28/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5660 - accuracy: 0.6759 - val_loss: 0.9996 - val_accuracy: 0.6706\n",
      "Epoch 29/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5661 - accuracy: 0.6759 - val_loss: 0.9392 - val_accuracy: 0.6720\n",
      "Epoch 30/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5655 - accuracy: 0.6762 - val_loss: 1.1573 - val_accuracy: 0.5362\n",
      "Epoch 31/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5653 - accuracy: 0.6764 - val_loss: 0.9188 - val_accuracy: 0.6736\n",
      "Epoch 32/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5651 - accuracy: 0.6765 - val_loss: 0.9520 - val_accuracy: 0.6736\n",
      "Epoch 33/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5651 - accuracy: 0.6766 - val_loss: 1.1312 - val_accuracy: 0.5640\n",
      "Epoch 34/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5649 - accuracy: 0.6766 - val_loss: 0.9403 - val_accuracy: 0.6741\n",
      "Epoch 35/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5652 - accuracy: 0.6767 - val_loss: 0.9594 - val_accuracy: 0.6731\n",
      "Epoch 36/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5648 - accuracy: 0.6767 - val_loss: 0.9627 - val_accuracy: 0.6734\n",
      "Epoch 37/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.6772 - val_loss: 0.9930 - val_accuracy: 0.6726\n",
      "Epoch 38/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.6771 - val_loss: 0.9653 - val_accuracy: 0.6751\n",
      "Epoch 39/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5645 - accuracy: 0.6771 - val_loss: 0.9716 - val_accuracy: 0.6701\n",
      "Epoch 40/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5642 - accuracy: 0.6771 - val_loss: 0.9716 - val_accuracy: 0.6748\n",
      "Epoch 41/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.6774 - val_loss: 0.9833 - val_accuracy: 0.6738\n",
      "Epoch 42/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5640 - accuracy: 0.6773 - val_loss: 1.0381 - val_accuracy: 0.6374\n",
      "Epoch 43/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5639 - accuracy: 0.6776 - val_loss: 1.1121 - val_accuracy: 0.6064\n",
      "Epoch 44/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5637 - accuracy: 0.6777 - val_loss: 1.0075 - val_accuracy: 0.6738\n",
      "Epoch 45/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5638 - accuracy: 0.6779 - val_loss: 0.9884 - val_accuracy: 0.6742\n",
      "Epoch 46/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5633 - accuracy: 0.6779 - val_loss: 1.0013 - val_accuracy: 0.6758\n",
      "Epoch 47/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5632 - accuracy: 0.6782 - val_loss: 0.9959 - val_accuracy: 0.6752\n",
      "Epoch 48/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5635 - accuracy: 0.6780 - val_loss: 0.9942 - val_accuracy: 0.6709\n",
      "Epoch 49/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5633 - accuracy: 0.6782 - val_loss: 0.9818 - val_accuracy: 0.6763\n",
      "Epoch 50/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5632 - accuracy: 0.6783 - val_loss: 1.0103 - val_accuracy: 0.6767\n",
      "Epoch 51/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.6786 - val_loss: 1.0139 - val_accuracy: 0.6745\n",
      "Epoch 52/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5628 - accuracy: 0.6784 - val_loss: 0.9968 - val_accuracy: 0.6732\n",
      "Epoch 53/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5626 - accuracy: 0.6787 - val_loss: 0.9926 - val_accuracy: 0.6740\n",
      "Epoch 54/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5623 - accuracy: 0.6787 - val_loss: 0.9731 - val_accuracy: 0.6773\n",
      "Epoch 55/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5631 - accuracy: 0.6781 - val_loss: 0.9934 - val_accuracy: 0.6750\n",
      "Epoch 56/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5626 - accuracy: 0.6787 - val_loss: 1.0744 - val_accuracy: 0.6759\n",
      "Epoch 57/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5625 - accuracy: 0.6788 - val_loss: 1.0151 - val_accuracy: 0.6762\n",
      "Epoch 58/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5616 - accuracy: 0.6787 - val_loss: 0.9021 - val_accuracy: 0.6741\n",
      "Epoch 59/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.5274 - accuracy: 0.7125 - val_loss: 2.7107 - val_accuracy: 0.6754\n",
      "Epoch 60/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.4635 - accuracy: 0.7791 - val_loss: 3.8817 - val_accuracy: 0.6728\n",
      "Epoch 61/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8214 - val_loss: 3.9644 - val_accuracy: 0.6743\n",
      "Epoch 62/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8578 - val_loss: 4.1829 - val_accuracy: 0.6783\n",
      "Epoch 63/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.3067 - accuracy: 0.8847 - val_loss: 4.1238 - val_accuracy: 0.6862\n",
      "Epoch 64/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2812 - accuracy: 0.8978 - val_loss: 1.2709 - val_accuracy: 0.5299\n",
      "Epoch 65/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2624 - accuracy: 0.9060 - val_loss: 0.2293 - val_accuracy: 0.9313\n",
      "Epoch 66/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2487 - accuracy: 0.9108 - val_loss: 0.8825 - val_accuracy: 0.6986\n",
      "Epoch 67/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9173 - val_loss: 0.3499 - val_accuracy: 0.8731\n",
      "Epoch 68/80\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.2162 - accuracy: 0.9211 - val_loss: 1.4384 - val_accuracy: 0.5412\n",
      "Epoch 69/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2069 - accuracy: 0.9250 - val_loss: 0.9929 - val_accuracy: 0.6630\n",
      "Epoch 70/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.2033 - accuracy: 0.9257 - val_loss: 0.1945 - val_accuracy: 0.9374\n",
      "Epoch 71/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1980 - accuracy: 0.9291 - val_loss: 0.4318 - val_accuracy: 0.8496\n",
      "Epoch 72/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1909 - accuracy: 0.9320 - val_loss: 0.5115 - val_accuracy: 0.8361\n",
      "Epoch 73/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1886 - accuracy: 0.9329 - val_loss: 0.8271 - val_accuracy: 0.7513\n",
      "Epoch 74/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1884 - accuracy: 0.9321 - val_loss: 0.6422 - val_accuracy: 0.7953\n",
      "Epoch 75/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9338 - val_loss: 1.7666 - val_accuracy: 0.5081\n",
      "Epoch 76/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1801 - accuracy: 0.9358 - val_loss: 0.1591 - val_accuracy: 0.9513\n",
      "Epoch 77/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1781 - accuracy: 0.9363 - val_loss: 3.6784 - val_accuracy: 0.6632\n",
      "Epoch 78/80\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.9380 - val_loss: 2.2375 - val_accuracy: 0.7374\n",
      "Epoch 79/80\n",
      "470/470 [==============================] - 2s 3ms/step - loss: 0.1771 - accuracy: 0.9367 - val_loss: 1.5582 - val_accuracy: 0.8090\n",
      "Epoch 80/80\n",
      "470/470 [==============================] - 1s 3ms/step - loss: 0.1783 - accuracy: 0.9354 - val_loss: 1.4462 - val_accuracy: 0.8376\n"
     ]
    }
   ],
   "source": [
    "model_DNN_new = keras.models.Sequential()\n",
    "model_DNN_new.add(keras.layers.Flatten(input_shape = [26, 1]))  # flatten层的作用是将28*28维度的输入数据展平成一层，输入层；虽然本就是一维\n",
    "for _ in range(4):\n",
    "    model_DNN_new.add(keras.layers.Dense(26, activation = \"relu\"))\n",
    "    # 隐藏层加入标准化模块加速训练速度，将前一层的激活值重新规范化，即使得其输出数据的均值接近0，其标准差接近1；\n",
    "    model_DNN_new.add(keras.layers.BatchNormalization()) \n",
    "model_DNN_new.add(keras.layers.AlphaDropout(rate=0.5))  # 正则化层；\n",
    "model_DNN_new.add(keras.layers.Dense(len(pd.Series(Y_val_DNN_new).unique()), activation = \"softmax\")) # 输出层别忘。。。\n",
    "model_DNN_new.compile(\n",
    "             loss = \"sparse_categorical_crossentropy\",  # 稀疏分类交叉熵损失函数\n",
    "             optimizer = keras.optimizers.Adam(learning_rate = 0.0003),    # 优化函数为随机梯度下降 ，学习率为0.01\n",
    "             metrics = [\"accuracy\"])                     # 优化指标为准确度\n",
    "# 记录训练历史\n",
    "model_DNN__new_train_history = model_DNN_new.fit(X_train_DNN_new, Y_train_DNN_new,             # 训练数据\n",
    "                                        batch_size = 700,                       # 每一次迭代传入样本；\n",
    "                                        epochs = 80,                           # 训练周期\n",
    "                                        validation_data = (X_val_DNN_new, Y_val_DNN_new),) # 验证集要用；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5127536",
   "metadata": {},
   "source": [
    "### S2.训练结果；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "130ea4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,j in enumerate(model_DNN__new_train_history.history):\n",
    "    plt.figure(figsize=(10,20))\n",
    "    plt.subplot(4,1,i+1)\n",
    "    if j == \"val_loss\":\n",
    "        plt.grid(True)\n",
    "        plt.plot(range(len(model_DNN__new_train_history.history[j])),model_DNN__new_train_history.history[j],label = j)\n",
    "        plt.gca().set_xlim(0, 80)\n",
    "        plt.gca().set_ylim(0, 20)\n",
    "    else :\n",
    "        \n",
    "        plt.grid(True)\n",
    "        plt.plot(range(len(model_DNN__new_train_history.history[j])),model_DNN__new_train_history.history[j],label = j)\n",
    "        plt.gca().set_xlim(0, 80)\n",
    "        plt.gca().set_ylim(0, 1.01)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epochs次数\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b04254",
   "metadata": {},
   "source": [
    "### S3.验证集表现；——差强人意\n",
    "- 精准率84%；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5dcde897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10263/10263 [==============================] - 7s 674us/step - loss: 1.4110 - accuracy: 0.8403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4110333919525146, 0.8402791619300842]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DNN_new.evaluate(X_train_DNN_new,Y_train_DNN_new)\n",
    "# model_DNN_new.evaluate(X_test_DNN_new, y_test)# 测试集没有标签无法判断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f76de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_proba = model_DNN_new.predict(X_test_DNN_new)\n",
    "# classes_x=np.argmax(X_test_proba,axis=1)\n",
    "# pd.Series(classes_x).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10273082",
   "metadata": {},
   "source": [
    "### S4.将测试集的预测结果也保存到本地；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0e434d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_DNN_new[\"pred_score_DNN\"] = model_DNN_new.predict(X_test_DNN_new)[:,1]\n",
    "# tst_user_item_feats_df_DNN = pd.concat([tst_user_item_feats_df,X_test_DNN_new[\"pred_score_DNN\"]],axis=1)\n",
    "# tst_user_item_feats_df_DNN_new = pd.DataFrame(tst_user_item_feats_df_DNN[['user_id', 'click_article_id', 'pred_score_DNN']])\n",
    "# tst_user_item_feats_df_DNN_new.columns = ['user_id', 'click_article_id', 'pred_score']\n",
    "# tst_user_item_feats_df_DNN_new.to_csv(save_dir + 'dnn_classifier_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afcf9c0",
   "metadata": {},
   "source": [
    "# C4.模型融合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccada6c3",
   "metadata": {},
   "source": [
    "## P1.读取多个模型的排序结果文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f08e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别读取在排序阶段和分类阶段各自得到的排序结果；\n",
    "lgb_ranker = pd.read_csv(save_dir + 'lgb_ranker_score.csv')\n",
    "lgb_cls = pd.read_csv(save_dir + 'lgb_classfier_score.csv')\n",
    "dnn_cls = pd.read_csv(save_dir + 'dnn_classifier_score.csv')\n",
    "# 建立融合字典包；\n",
    "rank_model = {'lgb_ranker': lgb_ranker, 'lgb_cls': lgb_cls, 'dnn_cls': dnn_cls}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e4ea9",
   "metadata": {},
   "source": [
    "## P2.融合过程；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d5adf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初步融合的结果已经生成！也可以参考！\n"
     ]
    }
   ],
   "source": [
    "# final_recall[final_recall[\"user_id\"]==200000]\n",
    "# final_recall[final_recall[\"user_id\"]==200000].groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "# 不加DNN的版本；\n",
    "# def get_blend_predict_topk(rank_model, topk=5):\n",
    "#     # 将ranker模型中的分数标准归一化\n",
    "#     rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "#     # 把lgb_classifier结果和lgb_ranker结果归一化后的结果先堆到一起；\n",
    "#     final_recall = rank_model[\"lgb_cls\"].append(rank_model['lgb_ranker'])\n",
    "#     # 堆到一起后，按照用户,文章物品，groupby预测的分数，这里就明白了为什么分数要最终都命名为pred_score；\n",
    "#     final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "#     submit_sequence_result(final_recall, '排序和分类融合',topk=topk, model_name='blend_fuse_model')\n",
    "def get_blend_predict_topk(rank_model, topk=5):\n",
    "    final_recall = rank_model['lgb_cls'].append(rank_model['dnn_cls'])\n",
    "    # 将ranker模型中的分数标准归一化\n",
    "    rank_model['dnn_cls']['pred_score'] = rank_model['dnn_cls']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    rank_model['lgb_ranker']['pred_score'] = rank_model['lgb_ranker']['pred_score'].transform(lambda x: norm_sim(x))\n",
    "    # 把lgb_classifier结果和lgb_ranker结果归一化后的结果先堆到一起；\n",
    "    final_recall = rank_model[\"lgb_cls\"].append(rank_model['lgb_ranker'])\n",
    "    # 堆到一起后，按照用户,文章物品，groupby预测的分数，这里就明白了为什么分数要最终都命名为pred_score；\n",
    "    final_recall = final_recall.groupby(['user_id', 'click_article_id'])['pred_score'].sum().reset_index()\n",
    "    submit_sequence_result(final_recall, '排序和分类融合',topk=topk, model_name='blend_fuse_model')\n",
    "get_blend_predict_topk(rank_model)\n",
    "print(\"初步融合的结果已经生成！也可以参考！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205ea204",
   "metadata": {},
   "source": [
    "# C5.模型Staking\n",
    "- 思想是将上述两个模型的结果，分数排序，当做新的特征！，再借助另外一个线性模型比如，逻辑回归等进行最终分数输出；\n",
    "- DNN部分就暂时不考虑了；感觉有些过拟合；所以为了避免干扰先不考虑了；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a280cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取多个模型的交叉验证生成的结果文件\n",
    "# 训练集；上面Ranker模型&Classifier模型交叉验证得到的结果；\n",
    "trn_lgb_ranker_feats = pd.read_csv(save_dir + 'trn_lgb_ranker_feats_result.csv')\n",
    "trn_lgb_cls_feats = pd.read_csv(save_dir + 'trn_lgb_classifier_feats_result.csv')\n",
    "# 测试集；上面Ranker模型&Classifier模型交叉验证得到的结果；\n",
    "tst_lgb_ranker_feats = pd.read_csv(save_dir + 'tst_lgb_ranker_feats_result.csv')\n",
    "tst_lgb_cls_feats = pd.read_csv(save_dir + 'tst_lgb_classifier_feats_result.csv')\n",
    "# 将多个模型输出的特征进行拼接，准备两个拼接的母体，一个测试集的finall_tst_ranker_feats，一个训练集的finall_trn_ranker_feats；\n",
    "# 只留下['user_id', 'click_article_id', 'label']，后续分数和排名往上拼接；\n",
    "# 为啥叫ranker，因为排序主题！！！！！！\n",
    "finall_trn_ranker_feats = trn_lgb_ranker_feats[['user_id', 'click_article_id', 'label']]\n",
    "finall_tst_ranker_feats = tst_lgb_ranker_feats[['user_id', 'click_article_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05679e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集母体：user_id,click_article_id,label+ pred_score_rank，其中要根据上面定义的融合字典包含的模型和后面的训练测试集顺序相对应；\n",
    "# [*zip(list(rank_model.keys()),[trn_lgb_ranker_feats, trn_lgb_cls_feats])]字典定义的顺序和后面的列表要对应；\n",
    "for model_name,trn_model in [*zip(list(rank_model.keys()),[trn_lgb_ranker_feats, trn_lgb_cls_feats, ])]:\n",
    "    for feat_col in ['pred_score', 'pred_rank']:\n",
    "        col_name = feat_col + '_' + str(model_name)\n",
    "        finall_trn_ranker_feats[col_name] = trn_model[feat_col]\n",
    "for model_name,trn_model in [*zip(list(rank_model.keys()),[tst_lgb_ranker_feats, tst_lgb_cls_feats])]:\n",
    "    for feat_col in ['pred_score', 'pred_rank']:\n",
    "        col_name = feat_col + '_' + str(model_name)\n",
    "        finall_tst_ranker_feats[col_name] = trn_model[feat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2472f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个逻辑回归模型再次拟合交叉验证产生的特征对测试集进行预测\n",
    "# 这里需要注意的是，在做交叉验证的时候可以构造多一些与输出预测值相关的特征，来丰富这里简单模型的特征\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "feat_cols = ['pred_score_lgb_ranker', 'pred_rank_lgb_ranker', 'pred_score_lgb_cls', 'pred_rank_lgb_cls']\n",
    "trn_x = finall_trn_ranker_feats[feat_cols]\n",
    "trn_y = finall_trn_ranker_feats['label']\n",
    "tst_x = finall_tst_ranker_feats[feat_cols]\n",
    "# 定义模型\n",
    "lr = LogisticRegression(C=1.6,class_weight=\"balanced\",max_iter=200)\n",
    "# 模型训练\n",
    "lr.fit(trn_x, trn_y)\n",
    "# 模型预测\n",
    "finall_tst_ranker_feats['pred_score'] = lr.predict_proba(tst_x)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aded3126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测结果重新排序, 及生成提交结果\n",
    "rank_results = finall_tst_ranker_feats[['user_id', 'click_article_id', 'pred_score']]\n",
    "submit_sequence_result(rank_results, '配合逻辑回归拟合结果',topk=5, model_name='blend_fuse_model_LogiRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a93191f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00629bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4f9ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81190a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65448407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b927616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e52848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e41be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b8d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10d350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67479f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ef214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa58515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce79843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3d84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
